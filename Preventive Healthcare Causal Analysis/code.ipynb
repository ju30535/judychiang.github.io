{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rytgRFLngk8E"
      },
      "source": [
        "# Data Sources\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "518v6iXCyYSF"
      },
      "source": [
        "## Dietary Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9MByZdByb7U",
        "outputId": "728d14f2-fad6-42e6-d419-275152e88357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          SEQN      WTDRD1_x      WTDR2D_x  DRABF  DRDINT_x  DR1DBIH_x  \\\n",
            "0      93703.0  5.397605e-79           NaN    NaN       NaN        NaN   \n",
            "1      93704.0  8.171401e+04  8.244287e+04    2.0       2.0        7.0   \n",
            "2      93705.0  7.185561e+03  5.640391e+03    2.0       2.0        5.0   \n",
            "3      93706.0  6.463883e+03  5.397605e-79    2.0       1.0        NaN   \n",
            "4      93707.0  1.533378e+04  2.270707e+04    2.0       2.0       14.0   \n",
            "...        ...           ...           ...    ...       ...        ...   \n",
            "8699  102952.0  1.381296e+04  2.868593e+04    2.0       2.0       22.0   \n",
            "8700  102953.0  5.063236e+04  5.397605e-79    2.0       1.0        2.0   \n",
            "8701  102954.0  1.108127e+04  8.924895e+03    2.0       2.0        2.0   \n",
            "8702  102955.0  2.752985e+04  3.629955e+04    2.0       2.0       15.0   \n",
            "8703  102956.0  6.944741e+04  9.275688e+04    2.0       2.0       10.0   \n",
            "\n",
            "      DR1DAY_x  DBQ095Z  DBD100  DRQSPREP  ...  DS1TPHOS  DS1TMAGN  DS1TIRON  \\\n",
            "0          NaN      NaN     NaN       NaN  ...       NaN       NaN       NaN   \n",
            "1          2.0      4.0     NaN       2.0  ...       NaN       NaN       NaN   \n",
            "2          1.0      4.0     NaN       3.0  ...      48.0     100.0      2.19   \n",
            "3          6.0      1.0     1.0       3.0  ...       NaN       NaN       NaN   \n",
            "4          2.0      1.0     9.0       2.0  ...       NaN       NaN       NaN   \n",
            "...        ...      ...     ...       ...  ...       ...       ...       ...   \n",
            "8699       7.0      1.0     1.0       2.0  ...      50.0      40.0      8.00   \n",
            "8700       7.0      4.0     NaN       3.0  ...       NaN       NaN       NaN   \n",
            "8701       6.0      1.0     2.0       3.0  ...       NaN       NaN       NaN   \n",
            "8702       2.0      4.0     NaN       4.0  ...       NaN       NaN       NaN   \n",
            "8703       5.0      1.0     1.0       2.0  ...       NaN       NaN       NaN   \n",
            "\n",
            "      DS1TZINC  DS1TCOPP  DS1TSODI  DS1TPOTA  DS1TSELE  DS1TCAFF  DS1TIODI  \n",
            "0          NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
            "1          NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
            "2       17.475       2.0      15.0     170.0      24.0       NaN     150.0  \n",
            "3          NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
            "4          NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
            "...        ...       ...       ...       ...       ...       ...       ...  \n",
            "8699    15.000       2.0       NaN       NaN       NaN       NaN     150.0  \n",
            "8700       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
            "8701       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
            "8702       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
            "8703       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
            "\n",
            "[8704 rows x 206 columns]\n"
          ]
        }
      ],
      "source": [
        "# Load necessary libraries\n",
        "import pandas as pd\n",
        "import requests\n",
        "import tempfile\n",
        "from io import BytesIO\n",
        "\n",
        "# Function to download and read XPT file into a DataFrame\n",
        "def download_and_read_xpt(url):\n",
        "    response = requests.get(url)\n",
        "    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n",
        "        tmp_file.write(response.content)\n",
        "        tmp_file_path = tmp_file.name\n",
        "    return pd.read_sas(tmp_file_path, format='xport')\n",
        "\n",
        "# Download and read the first XPT file\n",
        "url1 = \"https://wwwn.cdc.gov/nchs/nhanes/2017-2018/DR1TOT_J.XPT\"\n",
        "df1 = download_and_read_xpt(url1)\n",
        "\n",
        "# List of columns to be removed\n",
        "columns_to_remove = ['DR1DRSTZ', 'DR1EXMER', 'DR1LANG', 'DR1MRESP', 'DR1HELP']  # Replace these with your specific column names\n",
        "\n",
        "# Drop the specified columns\n",
        "df1 = df1.drop(columns=columns_to_remove)\n",
        "\n",
        "# Save the modified DataFrame to a new CSV file\n",
        "df1.to_csv('TotalNutrientIntakes.csv', index=False)\n",
        "\n",
        "# Download and read the second XPT file\n",
        "url2 = \"https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/DS1TOT_J.XPT\"\n",
        "df2 = download_and_read_xpt(url2)\n",
        "\n",
        "# Drop the specified columns\n",
        "df2 = df2.drop(columns=columns_to_remove)\n",
        "\n",
        "# Save the modified DataFrame to a new CSV file\n",
        "df2.to_csv('DietarySupplementUse24Hour.csv', index=False)\n",
        "\n",
        "# Load the CSV files\n",
        "df1 = pd.read_csv('TotalNutrientIntakes.csv')\n",
        "df2 = pd.read_csv('DietarySupplementUse24Hour.csv')\n",
        "\n",
        "# Perform left joins\n",
        "merged_df = df1.merge(df2, on='SEQN', how='left')\n",
        "\n",
        "# Print the resulting dataframe to verify the changes\n",
        "print(merged_df)\n",
        "\n",
        "# Save the merged DataFrame to a new CSV file\n",
        "merged_df.to_csv('mergedDietary.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXniwZTNY8cB"
      },
      "source": [
        "##Questionnaire Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmTeTRUfVjcg"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import tempfile\n",
        "\n",
        "dic = {\n",
        "    # \"DEMO_J.XPT\": [\"SEQN\"],\n",
        "    \"ALQ_J.XPT\": ['ALQ111',\"ALQ121\"],\n",
        "    \"BPQ_J.XPT\": [\"BPQ040A\"],\n",
        "    'HSQ_J.XPT': ['HSD010'],\n",
        "    'DIQ_J.XPT': ['DIQ010'],\n",
        "    'DBQ_J.XPT': ['DBQ700','DBD900','DBD905', 'DBD910'],\n",
        "    'DPQ_J.XPT': ['DPQ020'],\n",
        "    'PAQ_J.XPT': ['PAQ605', 'PAQ610', 'PAD615', 'PAQ620', 'PAQ625',\n",
        "                  'PAD630', 'PAQ635', 'PAQ640', 'PAD645', 'PAQ650', 'PAQ655',\n",
        "                  'PAD660', 'PAQ665', 'PAQ670', 'PAD675', 'PAD680' ],\n",
        "    # 'RXQ_RX_J.XPT': [''],\n",
        "    'SLQ_J.XPT': ['SLD012', 'SLQ050'],\n",
        "    'SMQ_J.XPT': ['SMQ020', 'SMQ040'],\n",
        "    # 'WHQ_J.XPT': ['WHD010', 'WHD020', 'WHQ030']\n",
        "}\n",
        "\n",
        "def getdata(url, collist):\n",
        "    with tempfile.NamedTemporaryFile(delete=False) as tf:\n",
        "        # Download the file\n",
        "        response = requests.get(url)\n",
        "        tf.write(response.content)\n",
        "        temp_file_path = tf.name\n",
        "\n",
        "    # Read the XPT file\n",
        "    df = pd.read_sas(temp_file_path, format='xport', encoding='latin1')\n",
        "\n",
        "    # # check if col exists\n",
        "    # if col in df.columns:\n",
        "    #   print(col + ' good')\n",
        "    # else:\n",
        "    #   print(col + ' not found')\n",
        "\n",
        "    # Extract specified columns\n",
        "    collist.append('SEQN')\n",
        "    extracted_columns = df[collist]\n",
        "    return extracted_columns\n",
        "\n",
        "# get base - demographic\n",
        "with tempfile.NamedTemporaryFile(delete=False) as tf:\n",
        "  response = requests.get('https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/DEMO_J.XPT')\n",
        "  tf.write(response.content)\n",
        "  temp_file_path = tf.name\n",
        "\n",
        "df = pd.read_sas(temp_file_path, format='xport', encoding='latin1')\n",
        "\n",
        "df = df[['SEQN']]\n",
        "# print(df.shape)\n",
        "\n",
        "# Iterate over the dictionary and print keys and values\n",
        "for key, value in dic.items():\n",
        "    url = 'https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/' + key\n",
        "    edf = getdata(url, value)\n",
        "    # # check for unique id - all passed\n",
        "    # if edf['SEQN'].is_unique:\n",
        "    #   print(key +' is unique')\n",
        "    # else:\n",
        "    #   print (key +' need check')\n",
        "\n",
        "    df = pd.merge(df, edf, on='SEQN', how='left')\n",
        "\n",
        "df.to_csv('questionnaire_combine.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pn71MZLF_964"
      },
      "source": [
        "## Demographic Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFKo_dwZ9-KO",
        "outputId": "7c7dbdee-feb5-4bee-f1c0-0c88d9ebda56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyreadstat in /usr/local/lib/python3.10/dist-packages (1.2.7)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyreadstat) (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadstat) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadstat) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadstat) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadstat) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadstat) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyreadstat\n",
        "import pandas as pd\n",
        "import pyreadstat\n",
        "import requests\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "# URL of the .xpt file\n",
        "url = 'https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/DEMO_J.XPT'\n",
        "# Fetch the file from the URL\n",
        "response = requests.get(url)\n",
        "response.raise_for_status()  # Check that the request was successful\n",
        "\n",
        "# Create a temporary file\n",
        "with tempfile.NamedTemporaryFile(delete=False, suffix='.xpt') as tmp_file:\n",
        "    tmp_file.write(response.content)\n",
        "    tmp_file_path = tmp_file.name\n",
        "\n",
        "# Read the .xpt file\n",
        "df, meta = pyreadstat.read_xport(tmp_file_path)\n",
        "\n",
        "# Remove the temporary file\n",
        "os.unlink(tmp_file_path)\n",
        "\n",
        "demo_df = df[['SEQN','DMDBORN4', 'DMDCITZN', 'DMDEDUC2', 'DMDEDUC3', 'DMDFMSIZ', 'DMDHHSIZ', 'DMDHHSZA', 'DMDHHSZB', 'DMDHHSZE', 'DMDMARTL', 'DMDYRSUS', 'DMQADFC', 'DMQMILIZ', 'INDFMIN2', 'INDFMPIR', 'INDHHIN2', 'RIAGENDR', 'RIDAGEMN', 'RIDAGEYR', 'RIDEXAGM', 'RIDEXPRG', 'RIDRETH3', 'RIDSTATR']]\n",
        "\n",
        "demo_df.to_csv(\"demo.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "no01SWa07Uuh"
      },
      "source": [
        "##Examination Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAxCxRJ07aO3"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import tempfile\n",
        "\n",
        "dic = {\n",
        "    # \"DEMO_J.XPT\": [\"SEQN\"],\n",
        "    \"BPX_J.XPT\": ['BPXPLS','BPXPULS', 'BPXPTY','BPXML1','BPXSY1','BPXDI1','BPXSY2', 'BPXDI2','BPXSY3','BPXDI3'],\n",
        "    \"BMX_J.XPT\": ['BMXWT',\t'BMXHT',\t'BMXBMI',\t'BMXLEG',\t'BMXARML',\t'BMXARMC',\t'BMXWAIST',\t'BMXHIP'],\n",
        "    'DXXAG_J.XPT': ['DXXANFM','DXXANLM', 'DXXANTOM', 'DXXGYFM','DXXGYLM','DXXGYTOM','DXXAGRAT','DXXAPFAT', 'DXXGPFAT', 'DXXSATA','DXXSATM','DXXSATV','DXXTATA','DXXTATM','DXXTATV','DXXVFATA','DXXVFATM','DXXVFATV'],\n",
        "    'DXXSPN_J.XPT': ['DXXOSBMD', 'DXXOSBMC'],\n",
        "    'DXX_J.XPT': ['DXDTOBMD', 'DXDTOFAT','DXXTRFAT'],\n",
        "    'OHXREF_J.XPT': ['OHAROCDT', 'OHAROCGP','OHAROCDE']\n",
        "}\n",
        "\n",
        "def getdata(url, collist):\n",
        "    with tempfile.NamedTemporaryFile(delete=False) as tf:\n",
        "        # Download the file\n",
        "        response = requests.get(url)\n",
        "        tf.write(response.content)\n",
        "        temp_file_path = tf.name\n",
        "\n",
        "    # Read the XPT file\n",
        "    df = pd.read_sas(temp_file_path, format='xport', encoding='latin1')\n",
        "\n",
        "    # # check if col exists\n",
        "    # if col in df.columns:\n",
        "    #   print(col + ' good')\n",
        "    # else:\n",
        "    #   print(col + ' not found')\n",
        "\n",
        "    # Extract specified columns\n",
        "    collist.append('SEQN')\n",
        "    extracted_columns = df[collist]\n",
        "    return extracted_columns\n",
        "\n",
        "# get base - demographic\n",
        "with tempfile.NamedTemporaryFile(delete=False) as tf:\n",
        "  response = requests.get('https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/DEMO_J.XPT')\n",
        "  tf.write(response.content)\n",
        "  temp_file_path = tf.name\n",
        "\n",
        "df = pd.read_sas(temp_file_path, format='xport', encoding='latin1')\n",
        "\n",
        "df = df[['SEQN']]\n",
        "# print(df.shape)\n",
        "\n",
        "# Iterate over the dictionary and print keys and values\n",
        "for key, value in dic.items():\n",
        "    url = 'https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/' + key\n",
        "    edf = getdata(url, value)\n",
        "    # # check for unique id - all passed\n",
        "    # if edf['SEQN'].is_unique:\n",
        "    #   print(key +' is unique')\n",
        "    # else:\n",
        "    #   print (key +' need check')\n",
        "\n",
        "    df = pd.merge(df, edf, on='SEQN', how='left')\n",
        "\n",
        "df.to_csv('examination.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sYubQNHxzVE"
      },
      "source": [
        "##Laboratory Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygF7GyWbxyJU",
        "outputId": "4c306d1c-ddd5-44f1-9e1d-b230f0def80c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      SEQN  LBDHDD  LBXCOT\n",
            "0  93705.0    60.0   0.028\n",
            "1  93706.0    47.0   0.138\n",
            "2  93707.0    68.0   0.555\n",
            "3  93708.0    88.0   0.011\n",
            "4  93709.0    65.0  54.300\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "# Function to download and read xpt files\n",
        "def download_xpt(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Check if the download was successful\n",
        "    with io.BytesIO(response.content) as tf:\n",
        "        df = pd.read_sas(tf, format='xport')\n",
        "    return df\n",
        "\n",
        "# URLs of the files\n",
        "urls = {\n",
        "    \"demo\": \"https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/DEMO_J.xpt\",\n",
        "    \"albumin\": \"https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/ALB_CR_J.xpt\",\n",
        "    \"cholesterol\": \"https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/HDL_J.xpt\",\n",
        "    \"continine\": \"https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/COT_J.xpt\"\n",
        "}\n",
        "\n",
        "# Download and process the files\n",
        "pre_demo = download_xpt(urls[\"demo\"])\n",
        "demo = pre_demo[[\"SEQN\"]]\n",
        "\n",
        "pre_cholesterol = download_xpt(urls[\"cholesterol\"])\n",
        "cholesterol = pre_cholesterol[[\"SEQN\", \"LBDHDD\"]]\n",
        "\n",
        "pre_continine = download_xpt(urls[\"continine\"])\n",
        "continine = pre_continine[[\"SEQN\", \"LBXCOT\"]]\n",
        "\n",
        "# Merge the DataFrames on 'SEQN'\n",
        "merged_df = pd.merge(demo, cholesterol, on=\"SEQN\", how=\"inner\")\n",
        "merged_df = pd.merge(merged_df, continine, on=\"SEQN\", how=\"inner\")\n",
        "\n",
        "print(merged_df.head())\n",
        "\n",
        "# Save the result to a CSV file\n",
        "merged_df.to_csv(\"lab_data.csv\", index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBnf1t0SEe3f"
      },
      "source": [
        "# Data Import & Merge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rf2hgOExEe3h",
        "outputId": "4219e263-4cc8-47ca-ab67-fc08928c5c8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                SEQN     DMDBORN4     DMDCITZN     DMDEDUC2     DMDEDUC3  \\\n",
              "count    9254.000000  9254.000000  9251.000000  5569.000000  2306.000000   \n",
              "mean    98329.500000     1.237519     1.118582     3.525768     6.349523   \n",
              "std      2671.544029     1.562210     0.466721     1.240231     5.843226   \n",
              "min     93703.000000     1.000000     1.000000     1.000000     0.000000   \n",
              "25%     96016.250000     1.000000     1.000000     3.000000     3.000000   \n",
              "50%     98329.500000     1.000000     1.000000     4.000000     6.000000   \n",
              "75%    100642.750000     1.000000     1.000000     4.000000     9.000000   \n",
              "max    102956.000000    99.000000     9.000000     9.000000    66.000000   \n",
              "\n",
              "          DMDFMSIZ     DMDHHSIZ     DMDHHSZA     DMDHHSZB     DMDHHSZE  ...  \\\n",
              "count  9254.000000  9254.000000  9254.000000  9254.000000  9254.000000  ...   \n",
              "mean      3.592609     3.717419     0.498163     0.878647     0.490707  ...   \n",
              "std       1.758527     1.712127     0.803878     1.061327     0.755305  ...   \n",
              "min       1.000000     1.000000     0.000000     0.000000     0.000000  ...   \n",
              "25%       2.000000     2.000000     0.000000     0.000000     0.000000  ...   \n",
              "50%       4.000000     4.000000     0.000000     0.000000     0.000000  ...   \n",
              "75%       5.000000     5.000000     1.000000     2.000000     1.000000  ...   \n",
              "max       7.000000     7.000000     3.000000     3.000000     3.000000  ...   \n",
              "\n",
              "            PAQ655       PAD660       PAQ665       PAQ670       PAD675  \\\n",
              "count  1434.000000  1431.000000  5856.000000  2308.000000  2301.000000   \n",
              "mean      3.479079    83.176101     1.605874     3.649480    68.284659   \n",
              "std       2.978859   267.651485     0.488704     3.871216   215.166165   \n",
              "min       1.000000    10.000000     1.000000     1.000000    10.000000   \n",
              "25%       2.000000    42.500000     1.000000     2.000000    30.000000   \n",
              "50%       3.000000    60.000000     2.000000     3.000000    60.000000   \n",
              "75%       4.000000   120.000000     2.000000     5.000000    60.000000   \n",
              "max      99.000000  9999.000000     2.000000    99.000000  9999.000000   \n",
              "\n",
              "             PAD680       SLD012       SLQ050       SMQ020       SMQ040  \n",
              "count  5.846000e+03  6113.000000  6161.000000  5856.000000  2359.000000  \n",
              "mean   3.895582e+02     7.658842     1.742574     1.597165     2.225943  \n",
              "std    7.718131e+02     1.669706     0.486460     0.490510     0.926147  \n",
              "min    5.397605e-79     2.000000     1.000000     1.000000     1.000000  \n",
              "25%    1.800000e+02     7.000000     1.000000     1.000000     1.000000  \n",
              "50%    3.000000e+02     8.000000     2.000000     2.000000     3.000000  \n",
              "75%    4.800000e+02     8.500000     2.000000     2.000000     3.000000  \n",
              "max    9.999000e+03    14.000000     9.000000     2.000000     3.000000  \n",
              "\n",
              "[8 rows x 305 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-565884b5-1be2-42a2-850b-b20efa490f1e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SEQN</th>\n",
              "      <th>DMDBORN4</th>\n",
              "      <th>DMDCITZN</th>\n",
              "      <th>DMDEDUC2</th>\n",
              "      <th>DMDEDUC3</th>\n",
              "      <th>DMDFMSIZ</th>\n",
              "      <th>DMDHHSIZ</th>\n",
              "      <th>DMDHHSZA</th>\n",
              "      <th>DMDHHSZB</th>\n",
              "      <th>DMDHHSZE</th>\n",
              "      <th>...</th>\n",
              "      <th>PAQ655</th>\n",
              "      <th>PAD660</th>\n",
              "      <th>PAQ665</th>\n",
              "      <th>PAQ670</th>\n",
              "      <th>PAD675</th>\n",
              "      <th>PAD680</th>\n",
              "      <th>SLD012</th>\n",
              "      <th>SLQ050</th>\n",
              "      <th>SMQ020</th>\n",
              "      <th>SMQ040</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>9254.000000</td>\n",
              "      <td>9254.000000</td>\n",
              "      <td>9251.000000</td>\n",
              "      <td>5569.000000</td>\n",
              "      <td>2306.000000</td>\n",
              "      <td>9254.000000</td>\n",
              "      <td>9254.000000</td>\n",
              "      <td>9254.000000</td>\n",
              "      <td>9254.000000</td>\n",
              "      <td>9254.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1434.000000</td>\n",
              "      <td>1431.000000</td>\n",
              "      <td>5856.000000</td>\n",
              "      <td>2308.000000</td>\n",
              "      <td>2301.000000</td>\n",
              "      <td>5.846000e+03</td>\n",
              "      <td>6113.000000</td>\n",
              "      <td>6161.000000</td>\n",
              "      <td>5856.000000</td>\n",
              "      <td>2359.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>98329.500000</td>\n",
              "      <td>1.237519</td>\n",
              "      <td>1.118582</td>\n",
              "      <td>3.525768</td>\n",
              "      <td>6.349523</td>\n",
              "      <td>3.592609</td>\n",
              "      <td>3.717419</td>\n",
              "      <td>0.498163</td>\n",
              "      <td>0.878647</td>\n",
              "      <td>0.490707</td>\n",
              "      <td>...</td>\n",
              "      <td>3.479079</td>\n",
              "      <td>83.176101</td>\n",
              "      <td>1.605874</td>\n",
              "      <td>3.649480</td>\n",
              "      <td>68.284659</td>\n",
              "      <td>3.895582e+02</td>\n",
              "      <td>7.658842</td>\n",
              "      <td>1.742574</td>\n",
              "      <td>1.597165</td>\n",
              "      <td>2.225943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2671.544029</td>\n",
              "      <td>1.562210</td>\n",
              "      <td>0.466721</td>\n",
              "      <td>1.240231</td>\n",
              "      <td>5.843226</td>\n",
              "      <td>1.758527</td>\n",
              "      <td>1.712127</td>\n",
              "      <td>0.803878</td>\n",
              "      <td>1.061327</td>\n",
              "      <td>0.755305</td>\n",
              "      <td>...</td>\n",
              "      <td>2.978859</td>\n",
              "      <td>267.651485</td>\n",
              "      <td>0.488704</td>\n",
              "      <td>3.871216</td>\n",
              "      <td>215.166165</td>\n",
              "      <td>7.718131e+02</td>\n",
              "      <td>1.669706</td>\n",
              "      <td>0.486460</td>\n",
              "      <td>0.490510</td>\n",
              "      <td>0.926147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>93703.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>5.397605e-79</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>96016.250000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>42.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>1.800000e+02</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>98329.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>3.000000e+02</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>100642.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>4.800000e+02</td>\n",
              "      <td>8.500000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>102956.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>9999.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>9999.000000</td>\n",
              "      <td>9.999000e+03</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 305 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-565884b5-1be2-42a2-850b-b20efa490f1e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-565884b5-1be2-42a2-850b-b20efa490f1e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-565884b5-1be2-42a2-850b-b20efa490f1e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-22aad588-78c5-4fd1-9c39-6e90cfc8bf03\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-22aad588-78c5-4fd1-9c39-6e90cfc8bf03')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-22aad588-78c5-4fd1-9c39-6e90cfc8bf03 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV files into DataFrames\n",
        "df1 = pd.read_csv('demo.csv', index_col=0)\n",
        "df2 = pd.read_csv('examination.csv', index_col=0)\n",
        "df3 = pd.read_csv('lab_data.csv', index_col=0)\n",
        "df4 = pd.read_csv('mergedDietary.csv',index_col=0)\n",
        "df5 = pd.read_csv('questionnaire_combine.csv', index_col=0)\n",
        "\n",
        "# Perform the left join on the 'id' column\n",
        "df1 = df1.merge(df2, on='SEQN', how='left')\n",
        "df1 = df1.merge(df3, on='SEQN', how='left')\n",
        "df1 = df1.merge(df4, on='SEQN', how='left')\n",
        "df1 = df1.merge(df5, on='SEQN', how='left')\n",
        "\n",
        "df1.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK0qqVJyEe3i"
      },
      "source": [
        "# Variable Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8Z12vkQzGoS"
      },
      "source": [
        "## Dietary Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9N5BF99asOl"
      },
      "outputs": [],
      "source": [
        "# Dietary preprocessing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Change the value 2 to 0 in the specified columns DS1DS and DS1AN\n",
        "df1['DS1DS'] = df1['DS1DS'].apply(lambda x: 0 if x == 2 else x)\n",
        "df1['DS1AN'] = df1['DS1AN'].apply(lambda x: 0 if x == 2 else x)\n",
        "\n",
        "# List of columns to be modified\n",
        "columns_to_modify = [\n",
        "    \"DRABF\", \"DR1STY\", \"DRQSDIET\",\n",
        "    \"DRD340\", \"DRD350A\", \"DRD350B\", \"DRD350C\", \"DRD350D\", \"DRD350E\", \"DRD350F\", \"DRD350G\",\n",
        "    \"DRD350H\", \"DRD350I\", \"DRD350J\", \"DRD350K\", \"DRD360\", \"DRD370A\", \"DRD370B\", \"DRD370C\",\n",
        "    \"DRD370D\", \"DRD370E\", \"DRD370F\", \"DRD370G\", \"DRD370H\", \"DRD370I\", \"DRD370J\", \"DRD370K\",\n",
        "    \"DRD370L\", \"DRD370M\", \"DRD370N\", \"DRD370O\", \"DRD370P\", \"DRD370Q\", \"DRD370R\", \"DRD370S\",\n",
        "    \"DRD370T\", \"DRD370U\", \"DRD370V\"\n",
        "]\n",
        "\n",
        "# Function to change values in the columns to be modified\n",
        "def change_values(x):\n",
        "    if x == 2:\n",
        "        return 0\n",
        "    elif x in [7, 9]:\n",
        "        return np.nan\n",
        "    return x\n",
        "\n",
        "# Apply the function to the specified columns\n",
        "for column in columns_to_modify:\n",
        "    df1[column] = df1[column].apply(change_values)\n",
        "\n",
        "# List of columns to be dropped\n",
        "columns_to_drop = [\n",
        "    \"DRQSDT1\", \"DRQSDT2\", \"DRQSDT3\", \"DRQSDT4\", \"DRQSDT5\", \"DRQSDT6\", \"DRQSDT7\", \"DRQSDT8\",\n",
        "    \"DRQSDT9\", \"DRQSDT10\", \"DRQSDT11\", \"DRQSDT12\", \"DRQSDT91\", \"DR1SKY\", \"DR1TWSZ\"\n",
        "]\n",
        "\n",
        "# Drop the specified columns\n",
        "df1 = df1.drop(columns=columns_to_drop)\n",
        "\n",
        "# Modify additional specified columns\n",
        "df1['DBQ095Z'] = df1['DBQ095Z'].apply(lambda x: 1 if x in [2, 3] else (0 if x == 4 else (np.nan if x in [91, 99] else x)))\n",
        "df1['DBD100'] = df1['DBD100'].apply(lambda x: 1 if x in [2, 3] else (0 if x == 1 else (np.nan if x in [7, 9] else x)))\n",
        "df1['DRQSPREP'] = df1['DRQSPREP'].apply(lambda x: 0 if x in [1, 2] else (1 if x in [3, 4] else (np.nan if x == 9 else x)))\n",
        "df1['DR1_300'] = df1['DR1_300'].apply(lambda x: 1 if x in [1, 2] else (0 if x in [3, 7] else (np.nan if x == 9 else x)))\n",
        "\n",
        "# Create new columns based on the criteria\n",
        "df1['DR1TSFAT_criteria'] = df1['DR1TSFAT'].apply(lambda x: 1 if x <= 20 else 0)\n",
        "df1['DR1TSUGR_criteria'] = df1['DR1TSUGR'].apply(lambda x: 1 if x <= 50 else 0)\n",
        "df1['DR1TSODI_criteria'] = df1['DR1TSODI'].apply(lambda x: 1 if x <= 2000 else 0)\n",
        "df1['DR1TFIBE_criteria'] = df1['DR1TFIBE'].apply(lambda x: 1 if x >= 31 else 0)\n",
        "\n",
        "# Create the \"unhealthy condition\" column\n",
        "df1['unhealthy_condition'] = df1[['DR1TSFAT_criteria', 'DR1TSUGR_criteria', 'DR1TSODI_criteria', 'DR1TFIBE_criteria']].sum(axis=1).apply(lambda x: 1 if x <= 2 else 0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiABjIRXzLcI"
      },
      "source": [
        "## Questionnaire Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EV0L6B4fThrk",
        "outputId": "4eefdd94-78bd-499d-bfb8-98cc4152f815"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SMQ040\n",
            "3.0    1338\n",
            "1.0     805\n",
            "2.0     216\n",
            "Name: count, dtype: int64\n",
            "SMQ_everyday\n",
            "0    9254\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-109-d9e535bd84d8>:121: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df1['exercise'] = df1.apply(lambda row: 1 if row['PAQ650'] == 1 or row['PAQ665'] == 1 else 0, axis=1)\n",
            "<ipython-input-109-d9e535bd84d8>:131: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df1['sleep_well'] = (df1['SLD012'] >= 7).astype(int)\n",
            "<ipython-input-109-d9e535bd84d8>:146: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df1['SMQ_everyday'] = df1['SMQ040']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Questionnaire Preprocessing\n",
        "\n",
        "cd1 = {2:0, 7:np.nan, 9: np.nan, '.':np.nan} # for q that has no continuous value\n",
        "td = {1: 'Excellent', 0: 'Very Good', 3: 'Good', 4: 'Fair', 5: 'Poor'} # combination use with cd1: 2>0>very good\n",
        "cd2 = {7777:np.nan, 9999:np.nan, '.':np.nan}\n",
        "\n",
        "\n",
        "# Alcohol\n",
        "## ALQ111 - Ever had a drink of any kind of alcohol\n",
        "df1['ALQ111'] = df1['ALQ111'].replace(cd1)\n",
        "\n",
        "## ALQ121 - Past 12 mo how often have alcohol drink\n",
        "# tdp = {0: 'never', 1: 'everyday', 2:'nearly everyday', 3:'3-4time/week',\n",
        "#        4:'2/week', 5:'1/week', 6:'2-3/month', 7:'1/month',\n",
        "#        8:'7-11/year', 9:'3-6/year', 10:'1-2/year',\n",
        "#        77:np.nan, 99:np.nan, '.':np.nan}\n",
        "# 1: drink a lot 0: no drinking\n",
        "tdp = {2:1, 3:1, 4:0, 5:0, 6:0, 7:0, 8:0,9:0, 10:0, 77:np.nan, 99:np.nan, '.':np.nan}\n",
        "df1['ALQ121'] = df1['ALQ121'].replace(tdp)\n",
        "df1['ALQ121'] = df1['ALQ121'].apply(lambda x: int(x) if not pd.isna(x) else x)\n",
        "\n",
        "# Hypertension\n",
        "## BPQ040A - Taking prescription for hypertension\n",
        "## !!!!!Note: high missing value\n",
        "df1['BPQ040A'] = df1['BPQ040A'].replace(cd1)\n",
        "\n",
        "# Health conditon\n",
        "## HSD010 - General health condition\n",
        "df1['HSD010'] = df1['HSD010'].replace(cd1)\n",
        "df1['HSD010'] = df1['HSD010'].replace(td)\n",
        "\n",
        "\n",
        "# Diabetes\n",
        "## DIQ010 - Doctor told you have diabetes\n",
        "df1['DIQ010'] = df1['DIQ010'].replace(3, 1)\n",
        "df1['DIQ010'] = df1['DIQ010'].replace(cd1)\n",
        "\n",
        "# Diet\n",
        "## [Categorical]DBQ700 - How healthy is the diet\n",
        "df1['DBQ700'] = df1['DBQ700'].replace(cd1)\n",
        "df1['DBQ700'] = df1['DBQ700'].replace(td)\n",
        "\n",
        "# DBD900 - # of meals from fast food or pizza place\n",
        "df1['DBD900'] = df1['DBD900'].replace(cd2)\n",
        "df1['DBD900'] = df1['DBD900'].replace(5555, 22)\n",
        "\n",
        "# DBD905 - # of ready-to-eat foods in past 30 days\n",
        "df1['DBD905'] = df1['DBD905'].replace(cd2)\n",
        "df1['DBD905'] = df1['DBD905'].replace(6666, 91)\n",
        "\n",
        "# DBD910 - # of frozen meals/pizza in past 30 days\n",
        "df1['DBD910'] = df1['DBD910'].replace(cd2)\n",
        "df1['DBD910'] = df1['DBD910'].replace(6666, 91)\n",
        "\n",
        "# Mental\n",
        "## DPQ020 - Feeling down, depressed, or hopeless (over 2 week period)\n",
        "tdp = {0: 'No', 1: 'sometimes', 2: 'more than half', 3:'almost everyday',\n",
        "       7:np.nan, 9:np.nan, '.':np.nan}\n",
        "df1['DPQ020'] = df1['DPQ020'].replace(tdp)\n",
        "\n",
        "# Physical Activity (time period -  week)\n",
        "## PAQ605 - Vigorous work activity\n",
        "df1['PAQ605'] = df1['PAQ605'].replace(cd1)\n",
        "\n",
        "## PAQ610 - Number of days vigorous work\n",
        "tdp = {77:np.nan, 99:np.nan, '.':np.nan}\n",
        "df1['PAQ610'] = df1['PAQ610'].replace(tdp)\n",
        "\n",
        "## PAD615 - Minutes vigorous-intensity work\n",
        "df1['PAD615'] = df1['PAD615'].replace(cd2)\n",
        "\n",
        "## PAQ620 - Moderate work activity\n",
        "df1['PAQ620'] = df1['PAQ620'].replace(cd1)\n",
        "\n",
        "## PAQ625 - Number of days moderate work\n",
        "tdp = {77:np.nan, 99:np.nan, '.':np.nan}\n",
        "df1['PAQ625'] = df1['PAQ625'].replace(tdp)\n",
        "\n",
        "## PAD630 - Minutes moderate-intensity work\n",
        "df1['PAD630'] = df1['PAD630'].replace(cd2)\n",
        "\n",
        "## PAQ635 - Walk or bicycle\n",
        "df1['PAQ635'] = df1['PAQ635'].replace(cd1)\n",
        "\n",
        "## PAQ640 - Number of days walk or bicycle\n",
        "tdp = {77:np.nan, 99:np.nan, '.':np.nan}\n",
        "df1['PAQ640'] = df1['PAQ640'].replace(tdp)\n",
        "\n",
        "## PAD645 - Minutes walk/bicycle for transportation\n",
        "df1['PAD645'] = df1['PAD645'].replace(cd2)\n",
        "\n",
        "## PAQ650 - Vigorous recreational activities\n",
        "df1['PAQ650'] = df1['PAQ650'].replace(cd1)\n",
        "\n",
        "## PAQ655 - Days vigorous recreational activities\n",
        "tdp = {77:np.nan, 99:np.nan, '.':np.nan}\n",
        "df1['PAQ655'] = df1['PAQ655'].replace(tdp)\n",
        "\n",
        "## PAD660 - Minutes vigorous recreational activities\n",
        "df1['PAD660'] = df1['PAD660'].replace(cd2)\n",
        "\n",
        "# PAQ665 - Moderate recreational activities\n",
        "df1['PAQ665'] = df1['PAQ665'].replace(cd1)\n",
        "\n",
        "## PAQ670 - Days moderate recreational activities\n",
        "tdp = {77:np.nan, 99:np.nan, '.':np.nan}\n",
        "df1['PAQ670'] = df1['PAQ670'].replace(tdp)\n",
        "\n",
        "## PAD675 - Minutes moderate recreational activities\n",
        "df1['PAD675'] = df1['PAD675'].replace(cd2)\n",
        "\n",
        "## PAD680 - Minutes sedentary activity\n",
        "df1['PAD680'] = df1['PAD680'].replace(cd2)\n",
        "\n",
        "\n",
        "# create exercise\n",
        "# (PAQ665 or PAQ650 = 1 -> 1)\n",
        "df1['exercise'] = df1.apply(lambda row: 1 if row['PAQ650'] == 1 or row['PAQ665'] == 1 else 0, axis=1)\n",
        "\n",
        "# Sleep disorder\n",
        "## SLD012 - Sleep hours - weekdays or workdays\n",
        "df1['SLD012'] = df1['SLD012'].replace('.', np.nan)\n",
        "\n",
        "## SLQ050 - Ever told doctor had trouble sleeping?\n",
        "df1['SLQ050'] = df1['SLQ050'].replace(cd1)\n",
        "\n",
        "## create sleep_well\n",
        "df1['sleep_well'] = (df1['SLD012'] >= 7).astype(int)\n",
        "\n",
        "\n",
        "# Smoking\n",
        "# SMQ020 - Smoked at least 100 cigarettes in life\n",
        "df1['SMQ020'] = df1['SMQ020'].replace(cd1)\n",
        "\n",
        "\n",
        "print(df1['SMQ040'].value_counts())\n",
        "# [Categorical] SMQ040 - Do you now smoke cigarettes?\n",
        "df1['SMQ040'] = df1['SMQ040'].replace(1, 'Everyday')\n",
        "df1['SMQ040'] = df1['SMQ040'].replace(2, 'Someday')\n",
        "df1['SMQ040'] = df1['SMQ040'].replace(3, 'Not')\n",
        "df1['SMQ040'] = df1['SMQ040'].replace('.', np.nan)\n",
        "\n",
        "df1['SMQ_everyday'] = df1['SMQ040']\n",
        "df1['SMQ_everyday'] = df1['SMQ_everyday'].apply(lambda x: 1 if x == 1 or x == 2 else 0)\n",
        "\n",
        "print(df1['SMQ_everyday'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwj9IxwUzLxH"
      },
      "source": [
        "## Demographic Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1KytquqzL7n",
        "outputId": "a7fda453-1674-41af-de05-20c973257b1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-110-fb176aafcd59>:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df1['RIDAGEYR_fixed'] = df1['RIDAGEYR']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       6.0\n",
              "1       3.0\n",
              "2       4.0\n",
              "3       6.0\n",
              "4       7.0\n",
              "       ... \n",
              "9249    6.0\n",
              "9250    1.0\n",
              "9251    4.0\n",
              "9252    4.0\n",
              "9253    3.0\n",
              "Name: RIDRETH3, Length: 9254, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "###demo data https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/DEMO_J.htm#DMDEDUC3 ###\n",
        "\n",
        "# Education\n",
        "## 20+ dummy conversion needed\n",
        "conversion_dict = {7: np.nan, \".\":np.nan}\n",
        "df1['DMDEDUC2'] = df1['DMDEDUC2'].replace(conversion_dict)\n",
        "## 19- dummy conversion needed\n",
        "conversion_dict = {66: np.nan, 9: np.nan, \".\":np.nan}\n",
        "df1['DMDEDUC3'] = df1['DMDEDUC3'].replace(conversion_dict)\n",
        "\n",
        "# Marital dummy conversion needed\n",
        "conversion_dict = {77: np.nan, \".\":np.nan}\n",
        "df1['DMDMARTL'] = df1['DMDMARTL'].replace(conversion_dict)\n",
        "\n",
        "# total family income\n",
        "conversion_dict = {77: np.nan, 99: np.nan, \".\":np.nan}\n",
        "df1['INDFMIN2'] = df1['INDFMIN2'].replace(conversion_dict)\n",
        "\n",
        "# Annual household income\n",
        "conversion_dict = {77: np.nan, 99: np.nan, \".\":np.nan}\n",
        "df1['INDHHIN2'] = df1['INDHHIN2'].replace(conversion_dict)\n",
        "\n",
        "# Gender 1->Female , 0->Male\n",
        "conversion_dict = {0: 1, 1: 0}\n",
        "df1['RIAGENDR'] = df1['RIAGENDR'].replace(conversion_dict)\n",
        "\n",
        "# age\n",
        "## age-year\n",
        "conversion_dict = {\".\": np.nan}\n",
        "df1['RIDAGEMN'] = df1['RIDAGEMN'].replace(conversion_dict)\n",
        "\n",
        "## age-month\n",
        "conversion_dict = {\".\": np.nan}\n",
        "df1['RIDAGEYR'] = df1['RIDAGEYR'].replace(conversion_dict)\n",
        "\n",
        "df1['RIDAGEYR'] = pd.to_numeric(df1['RIDAGEYR'], errors='coerce')\n",
        "df1['RIDAGEMN'] = pd.to_numeric(df1['RIDAGEMN'], errors='coerce')\n",
        "df1['RIDAGEYR_fixed'] = df1['RIDAGEYR']\n",
        "df1.loc[df1['RIDAGEYR'] < 2, 'RIDAGEYR_fixed'] = df1.loc[df1['RIDAGEYR'] < 2, 'RIDAGEMN'] / 12\n",
        "\n",
        "# Race dummy conversion needed\n",
        "df1['RIDRETH3'] # no precessing needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdVFxpi-zMDF"
      },
      "source": [
        "## Examination Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPB-fMLJzMLC",
        "outputId": "edd9fdaa-84ce-4d0c-b6bb-dcfec410d431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-111-47f72e904e12>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df1['Sys_AVEBP'] = df1[['BPXSY1', 'BPXSY2', 'BPXSY3']].apply(lambda row: np.nan if row.isna().any() else row.mean(), axis=1)\n",
            "<ipython-input-111-47f72e904e12>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df1['Dia_AVEBP'] = df1[['BPXDI1', 'BPXDI2', 'BPXDI3']].apply(lambda row: np.nan if row.isna().any() else row.mean(), axis=1)\n",
            "<ipython-input-111-47f72e904e12>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df1['WH_ratio'] = df1['BMXWAIST'] / df1['BMXHIP']\n",
            "<ipython-input-111-47f72e904e12>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df1['BMI_above_30'] = (df1['BMXBMI'] > 30).astype(int)\n"
          ]
        }
      ],
      "source": [
        "# examination preprocessing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#pulse is regular or irregular\n",
        "df1['BPXPULS'] = df1['BPXPULS'].apply(lambda x: 0 if x == 1 else (1 if x == 2 else x))\n",
        "\n",
        "#create average blood pressure\n",
        "df1['Sys_AVEBP'] = df1[['BPXSY1', 'BPXSY2', 'BPXSY3']].apply(lambda row: np.nan if row.isna().any() else row.mean(), axis=1)\n",
        "df1['Dia_AVEBP'] = df1[['BPXDI1', 'BPXDI2', 'BPXDI3']].apply(lambda row: np.nan if row.isna().any() else row.mean(), axis=1)\n",
        "\n",
        "#create WH ratio\n",
        "df1['WH_ratio'] = df1['BMXWAIST'] / df1['BMXHIP']\n",
        "\n",
        "#adjust value to binary\n",
        "df1['OHAROCDT'] = df1['OHAROCDT'].apply(lambda x: 0 if x == 2 else x)\n",
        "\n",
        "df1['BMI_above_30'] = (df1['BMXBMI'] > 30).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nr6xnhihzMRO"
      },
      "source": [
        "## Laboratory Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgr-teJ6dsDw",
        "outputId": "2b57bfe7-8907-4da6-b08c-6455e25c5cb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      SEQN  DMDBORN4  DMDCITZN  DMDEDUC2  DMDEDUC3  DMDFMSIZ  DMDHHSIZ  \\\n",
            "0  93703.0       1.0       1.0       NaN       NaN       5.0       5.0   \n",
            "1  93704.0       1.0       1.0       NaN       NaN       4.0       4.0   \n",
            "2  93705.0       1.0       1.0       2.0       NaN       1.0       1.0   \n",
            "3  93706.0       1.0       1.0       NaN      15.0       5.0       5.0   \n",
            "4  93707.0       1.0       1.0       NaN       6.0       7.0       7.0   \n",
            "\n",
            "   DMDHHSZA  DMDHHSZB  DMDHHSZE  ...  unhealthy_condition  exercise  \\\n",
            "0       3.0       0.0       0.0  ...                    1         0   \n",
            "1       2.0       0.0       0.0  ...                    1         0   \n",
            "2       0.0       0.0       1.0  ...                    1         1   \n",
            "3       0.0       0.0       1.0  ...                    1         1   \n",
            "4       0.0       3.0       0.0  ...                    1         0   \n",
            "\n",
            "   sleep_well  SMQ_everyday  RIDAGEYR_fixed   Sys_AVEBP  Dia_AVEBP  WH_ratio  \\\n",
            "0           0             0             2.0         NaN        NaN       NaN   \n",
            "1           0             0             2.0         NaN        NaN       NaN   \n",
            "2           1             0            66.0         NaN        NaN  0.925455   \n",
            "3           1             0            18.0  111.333333  73.333333  0.840042   \n",
            "4           0             0            13.0  128.000000  47.333333  0.772289   \n",
            "\n",
            "   BMI_above_30  smoker_con  \n",
            "0             0         NaN  \n",
            "1             0         NaN  \n",
            "2             1         0.0  \n",
            "3             0         0.0  \n",
            "4             0         0.0  \n",
            "\n",
            "[5 rows x 304 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-112-b2a6cd5e79fc>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df1[\"smoker_con\"] = df1[\"LBXCOT\"].apply(lambda x: 1 if x >= 11 else 0 if pd.notnull(x) else None)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Add the smoker indicator column, keeping null values unchanged\n",
        "df1[\"smoker_con\"] = df1[\"LBXCOT\"].apply(lambda x: 1 if x >= 11 else 0 if pd.notnull(x) else None)\n",
        "\n",
        "# Print the head of the updated DataFrame\n",
        "print(df1.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vANXlCAi1Zqd"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IB9kd_fd1Y2U",
        "outputId": "cd767764-84e0-4b3f-940e-4ac4d4df93bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       DIQ010  exercise    ALQ121  unhealthy_condition  \\\n",
            "DIQ010               1.000000  0.031200 -0.063288            -0.012803   \n",
            "exercise             0.031200  1.000000  0.026734             0.010681   \n",
            "ALQ121              -0.063288  0.026734  1.000000             0.003381   \n",
            "unhealthy_condition -0.012803  0.010681  0.003381             1.000000   \n",
            "INDFMIN2            -0.035396  0.113479  0.022136             0.034935   \n",
            "RIAGENDR            -0.029818 -0.040591 -0.136172            -0.074644   \n",
            "RIDAGEYR_fixed       0.383274  0.294224  0.025064            -0.024644   \n",
            "SLD012               0.021334 -0.023655 -0.008297            -0.044212   \n",
            "BPXPULS              0.057535 -0.001031  0.039573             0.023074   \n",
            "Sys_AVEBP            0.229772  0.076156  0.052844            -0.035282   \n",
            "BMXBMI               0.253412  0.201706 -0.097488            -0.019149   \n",
            "smoker_con          -0.010721  0.032736  0.110773            -0.015964   \n",
            "\n",
            "                     INDFMIN2  RIAGENDR  RIDAGEYR_fixed    SLD012   BPXPULS  \\\n",
            "DIQ010              -0.035396 -0.029818        0.383274  0.021334  0.057535   \n",
            "exercise             0.113479 -0.040591        0.294224 -0.023655 -0.001031   \n",
            "ALQ121               0.022136 -0.136172        0.025064 -0.008297  0.039573   \n",
            "unhealthy_condition  0.034935 -0.074644       -0.024644 -0.044212  0.023074   \n",
            "INDFMIN2             1.000000 -0.012571       -0.034657 -0.081906 -0.019541   \n",
            "RIAGENDR            -0.012571  1.000000        0.008336  0.062110 -0.031178   \n",
            "RIDAGEYR_fixed      -0.034657  0.008336        1.000000  0.002800  0.151707   \n",
            "SLD012              -0.081906  0.062110        0.002800  1.000000  0.014234   \n",
            "BPXPULS             -0.019541 -0.031178        0.151707  0.014234  1.000000   \n",
            "Sys_AVEBP           -0.085960 -0.061148        0.610353 -0.031023  0.084292   \n",
            "BMXBMI              -0.053192  0.049674        0.460684 -0.059430  0.039192   \n",
            "smoker_con          -0.172523 -0.121610        0.090181 -0.062132 -0.005082   \n",
            "\n",
            "                     Sys_AVEBP    BMXBMI  smoker_con  \n",
            "DIQ010                0.229772  0.253412   -0.010721  \n",
            "exercise              0.076156  0.201706    0.032736  \n",
            "ALQ121                0.052844 -0.097488    0.110773  \n",
            "unhealthy_condition  -0.035282 -0.019149   -0.015964  \n",
            "INDFMIN2             -0.085960 -0.053192   -0.172523  \n",
            "RIAGENDR             -0.061148  0.049674   -0.121610  \n",
            "RIDAGEYR_fixed        0.610353  0.460684    0.090181  \n",
            "SLD012               -0.031023 -0.059430   -0.062132  \n",
            "BPXPULS               0.084292  0.039192   -0.005082  \n",
            "Sys_AVEBP             1.000000  0.317525    0.063991  \n",
            "BMXBMI                0.317525  1.000000    0.064568  \n",
            "smoker_con            0.063991  0.064568    1.000000  \n",
            "DIQ010                  361\n",
            "exercise                  0\n",
            "ALQ121                 4713\n",
            "unhealthy_condition       0\n",
            "INDFMIN2                860\n",
            "RIAGENDR                  0\n",
            "RIDAGEYR_fixed            0\n",
            "SLD012                 3141\n",
            "BPXPULS                 973\n",
            "Sys_AVEBP              3177\n",
            "BMXBMI                 1249\n",
            "smoker_con             2485\n",
            "dtype: int64\n",
            "DIQ010\n",
            "0.0    2834\n",
            "1.0     613\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Assuming df1 is your DataFrame and it is already loaded\n",
        "selected_columns = ['DIQ010','exercise','ALQ121','unhealthy_condition', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'SLD012','BPXPULS','Sys_AVEBP', 'BMXBMI', 'smoker_con']\n",
        "\n",
        "# Selecting the specified columns\n",
        "df_selected = df1[selected_columns]\n",
        "\n",
        "# Creating the correlation matrix\n",
        "correlation_matrix = df_selected.corr()\n",
        "\n",
        "# Displaying the correlation matrix\n",
        "print(correlation_matrix)\n",
        "\n",
        "print(df1[['DIQ010','exercise','ALQ121','unhealthy_condition', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'SLD012','BPXPULS','Sys_AVEBP', 'BMXBMI', 'smoker_con']].isna().sum())\n",
        "\n",
        "df2 = df1[['DIQ010','exercise','ALQ121','unhealthy_condition', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'SLD012','BPXPULS','Sys_AVEBP', 'BMXBMI', 'smoker_con']].dropna()\n",
        "\n",
        "count_values = df2['DIQ010'].value_counts()\n",
        "print(count_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZcxNFpSEoT8"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kGdtCUBAmm0"
      },
      "source": [
        "## Topic 1. Diabetes\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0Pu4De0z_9T"
      },
      "source": [
        "### Hypothesis 1 DIQ010 ~ 'exercise'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c27CNe90D10"
      },
      "source": [
        "#### Method 1.Regression-Based w/o interactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs-tibcV9M3P",
        "outputId": "53b3e48b-2b65-45fe-b395-906ab82a001f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3275\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.407668\n",
            "         Iterations 7\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:                 DIQ010   No. Observations:                 2620\n",
            "Model:                          Logit   Df Residuals:                     2608\n",
            "Method:                           MLE   Df Model:                           11\n",
            "Date:                Mon, 08 Jul 2024   Pseudo R-squ.:                  0.1560\n",
            "Time:                        02:33:38   Log-Likelihood:                -1068.1\n",
            "converged:                       True   LL-Null:                       -1265.5\n",
            "Covariance Type:                  HC1   LLR p-value:                 8.064e-78\n",
            "=======================================================================================\n",
            "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
            "---------------------------------------------------------------------------------------\n",
            "const                  -6.3558      0.598    -10.630      0.000      -7.528      -5.184\n",
            "exercise               -0.2549      0.115     -2.216      0.027      -0.480      -0.029\n",
            "unhealthy_condition    -0.0970      0.210     -0.462      0.644      -0.509       0.315\n",
            "ALQ121                 -0.5557      0.189     -2.938      0.003      -0.926      -0.185\n",
            "INDFMIN2               -0.0044      0.013     -0.328      0.743      -0.031       0.022\n",
            "RIAGENDR               -0.2578      0.057     -4.543      0.000      -0.369      -0.147\n",
            "RIDAGEYR_fixed          0.0538      0.004     14.046      0.000       0.046       0.061\n",
            "SLD012                 -0.0093      0.033     -0.280      0.779      -0.074       0.056\n",
            "BPXPULS                -0.6546      0.273     -2.399      0.016      -1.189      -0.120\n",
            "Sys_AVEBP               0.0027      0.003      0.900      0.368      -0.003       0.008\n",
            "BMXBMI                  0.0713      0.008      9.437      0.000       0.056       0.086\n",
            "smoker_con             -0.1622      0.139     -1.170      0.242      -0.434       0.110\n",
            "=======================================================================================\n",
            "AUC: 0.7880724678849856\n"
          ]
        }
      ],
      "source": [
        "## Logistic\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import Ridge\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "df1_no_na = df1[['DIQ010','exercise', 'unhealthy_condition', 'ALQ121', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'SLD012','BPXPULS','Sys_AVEBP', 'BMXBMI', 'smoker_con']].dropna()\n",
        "df1_no_na = df1_no_na[df1_no_na['RIDAGEYR_fixed'] >= 21]\n",
        "\n",
        "\n",
        "X = df1_no_na[['exercise', 'unhealthy_condition', 'ALQ121','INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'SLD012','BPXPULS','Sys_AVEBP', 'BMXBMI', 'smoker_con']]\n",
        "y = df1_no_na['DIQ010']\n",
        "print(y.count())\n",
        "x_categorical_name_list = []\n",
        "X = pd.get_dummies(X, columns=x_categorical_name_list, drop_first=True)\n",
        "transformed_columns = [col for col in X.columns if any(prefix in col for prefix in x_categorical_name_list)]\n",
        "X[transformed_columns] = X[transformed_columns].astype(int)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=66)\n",
        "\n",
        "def ATE_est_reg(X_train, X_test, y_train, y_test):\n",
        "    X_columns = X.columns\n",
        "    X_train = sm.add_constant(X_train)\n",
        "    X_test = sm.add_constant(X_test)\n",
        "\n",
        "    model_ate = sm.Logit(y_train, X_train).fit(cov_type='HC1')\n",
        "    y_pred = model_ate.predict(X_train)\n",
        "    residuals = y_train - y_pred\n",
        "\n",
        "    ate_summary = model_ate.summary()\n",
        "    print(ate_summary)\n",
        "\n",
        "    # Predict probabilities on the test set\n",
        "    y_pred_prob = model_ate.predict(X_test)\n",
        "\n",
        "    # Calculate AUC\n",
        "    auc = roc_auc_score(y_test, y_pred_prob)\n",
        "    print(f'AUC: {auc}')\n",
        "    return\n",
        "\n",
        "\n",
        "ATE_est_reg(X_train, X_test, y_train, y_test)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDQ-M80erwR8",
        "outputId": "70724457-0161-42cb-ce24-0c21923db515"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features: Index(['exercise', 'unhealthy_condition', 'ALQ121', 'INDFMIN2', 'RIAGENDR',\n",
            "       'RIDAGEYR_fixed', 'SLD012', 'BPXPULS', 'Sys_AVEBP', 'BMXBMI',\n",
            "       'smoker_con'],\n",
            "      dtype='object')\n",
            "Results:\n",
            "                    Coefficient Standard Error    P-value\n",
            "exercise            -0.25536503     0.11444359 0.02591668\n",
            "unhealthy_condition -0.10041858     0.20849342 0.64181749\n",
            "ALQ121              -0.55283683     0.19108079 0.00363405\n",
            "INDFMIN2            -0.00479820     0.01309110 0.73675910\n",
            "RIAGENDR            -0.25742717     0.05654945 0.00000512\n",
            "RIDAGEYR_fixed       0.05363025     0.00423300 0.00000000\n",
            "SLD012              -0.01075097     0.03305880 0.77843010\n",
            "BPXPULS             -0.64511585     0.28373116 0.02105068\n",
            "Sys_AVEBP            0.00247554     0.00297518 0.37297091\n",
            "BMXBMI               0.07090929     0.00764946 0.00000000\n",
            "smoker_con          -0.16382055     0.13987643 0.24620467\n",
            "AUC: 0.7885932519016507\n"
          ]
        }
      ],
      "source": [
        "## Lasso (penalty = L1)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def ATE_est_reg_lasso(X_train, X_test, y_train, y_test, alpha=1.0):\n",
        "\n",
        "    # Standardize features\n",
        "    # scaler = StandardScaler()\n",
        "    # X_train_scaled = scaler.fit_transform(X_train)\n",
        "    # X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Fit Logistic Regression with Lasso (L1) regularization\n",
        "    model_ate = LogisticRegression(penalty='l1', solver='liblinear', C=1/alpha, max_iter=1000)\n",
        "    # model_ate.fit(X_train_scaled, y_train)\n",
        "    model_ate.fit(X_train, y_train)\n",
        "    coef = model_ate.coef_[0]\n",
        "\n",
        "    # Print selected features\n",
        "    selected_features = X_train.columns[model_ate.coef_[0] != 0]\n",
        "    print(\"Selected Features:\", selected_features)\n",
        "\n",
        "    # Fit the Logistic Regression model on the selected features using statsmodels\n",
        "    X_train_selected = X_train[selected_features]\n",
        "    X_train_selected_sm = sm.add_constant(X_train_selected)\n",
        "    logit_model = sm.Logit(y_train, X_train_selected_sm)\n",
        "    result = logit_model.fit(disp=0)\n",
        "\n",
        "    # Extract coefficients and standard errors from statsmodels\n",
        "    # coef = result.params[1:]  # Exclude the intercept\n",
        "    coef_std_err = result.bse[1:]  # Exclude the intercept\n",
        "\n",
        "    # Create a DataFrame to store results\n",
        "    results = pd.DataFrame(index=selected_features)\n",
        "    results['Coefficient'] = coef\n",
        "    results['Standard Error'] = coef_std_err\n",
        "    results['P-value'] = result.pvalues[1:]  # Exclude the intercept\n",
        "\n",
        "    # Print formatted table\n",
        "    print(\"Results:\")\n",
        "    print(results.to_string(formatters={'Coefficient': '{:.8f}'.format,\n",
        "                                        'Standard Error': '{:.8f}'.format,\n",
        "                                        'P-value': '{:.8f}'.format}))\n",
        "\n",
        "    # Predict probabilities on the test set\n",
        "    X_test_selected = X_test[selected_features]\n",
        "    # y_pred_prob = model_ate.predict_proba(X_test_scaled)[:, 1]\n",
        "    y_pred_prob = model_ate.predict_proba(X_test)[:, 1]\n",
        "\n",
        "\n",
        "    # Calculate AUC\n",
        "    auc = roc_auc_score(y_test, y_pred_prob)\n",
        "    print(f'AUC: {auc}')\n",
        "\n",
        "    return model_ate\n",
        "\n",
        "# Example usage:\n",
        "model_ate_lasso = ATE_est_reg_lasso(X_train, X_test, y_train, y_test, alpha=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9sUPAZWkmpY",
        "outputId": "783dd8e8-03e0-4ae1-c889-c66587e97dd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results:\n",
            "                    Feature Importance Mean\n",
            "exercise                             0.0262\n",
            "unhealthy_condition                  0.0123\n",
            "ALQ121                               0.0131\n",
            "INDFMIN2                             0.1022\n",
            "RIAGENDR                             0.0281\n",
            "RIDAGEYR_fixed                       0.2303\n",
            "SLD012                               0.1175\n",
            "BPXPULS                              0.0067\n",
            "Sys_AVEBP                            0.1909\n",
            "BMXBMI                               0.2521\n",
            "smoker_con                           0.0206\n",
            "AUC: 0.7515307893823187\n"
          ]
        }
      ],
      "source": [
        "## Random Forest - AUC\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.utils import resample\n",
        "\n",
        "\n",
        "def ATE_est_reg_rf_bootstrap(X_train, X_test, y_train, y_test, n_estimators=100, n_bootstrap=100):\n",
        "\n",
        "    # Initialize the RandomForestRegressor\n",
        "    model_ate = RandomForestRegressor(n_estimators=n_estimators, random_state=42)\n",
        "\n",
        "    # Fit the model\n",
        "    model_ate.fit(X_train, y_train)\n",
        "\n",
        "    # Bootstrap to estimate feature importances variability\n",
        "    feature_importances_bootstrap = np.zeros((n_bootstrap, X_train.shape[1]))\n",
        "\n",
        "    for i in range(n_bootstrap):\n",
        "        X_boot, y_boot = resample(X_train, y_train, random_state=i)\n",
        "        model_boot = RandomForestRegressor(n_estimators=n_estimators, random_state=42)\n",
        "        model_boot.fit(X_boot, y_boot)\n",
        "        feature_importances_bootstrap[i, :] = model_boot.feature_importances_\n",
        "\n",
        "    # Calculate mean feature importances and standard errors\n",
        "    feature_importances_mean = np.mean(feature_importances_bootstrap, axis=0)\n",
        "\n",
        "    # Create a DataFrame to store results\n",
        "    results = pd.DataFrame(index=X_train.columns)\n",
        "    results['Feature Importance Mean'] = feature_importances_mean\n",
        "\n",
        "    # Print formatted table\n",
        "    print(\"Results:\")\n",
        "    print(results.to_string(formatters={'Feature Importance Mean': '{:.4f}'.format,\n",
        "                                         }))\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = model_ate.predict(X_test)\n",
        "\n",
        "    # Calculate AUC\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    print(f'AUC: {auc}')\n",
        "\n",
        "    return model_ate\n",
        "\n",
        "# Example usage:\n",
        "model_ate_rf_bootstrap = ATE_est_reg_rf_bootstrap(X_train, X_test, y_train, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "sI4-mEqZ6H5z",
        "outputId": "0810e3a6-a4b8-48c9-8a47-fcfebf8a53c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The estimated Average Treatment Effect (ATE) : -0.029019847328244277\n",
            "The standard error of the ATE estimate : 0.004596130438427934\n"
          ]
        }
      ],
      "source": [
        "## Random Forest - ATE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from itertools import combinations\n",
        "\n",
        "\n",
        "# Define treatment and covariates\n",
        "X = df1_no_na[['exercise', 'ALQ121', 'unhealthy_condition', 'INDFMIN2', 'RIAGENDR', 'RIDAGEYR_fixed', 'SLD012', 'BPXPULS', 'Sys_AVEBP', 'BMXBMI', 'smoker_con']]\n",
        "y = df1_no_na['DIQ010']\n",
        "\n",
        "\n",
        "treatment = X['exercise']\n",
        "covariates = X.drop(columns=['exercise'])\n",
        "\n",
        "\n",
        "outcome_model_treated = RandomForestRegressor(n_estimators=100, random_state=0).fit(covariates[treatment == 1], y[treatment == 1])\n",
        "outcome_model_control = RandomForestRegressor(n_estimators=100, random_state=0).fit(covariates[treatment == 0], y[treatment == 0])\n",
        "\n",
        "# Predict outcomes\n",
        "y_hat_treated = outcome_model_treated.predict(covariates)\n",
        "y_hat_control = outcome_model_control.predict(covariates)\n",
        "\n",
        "# Calculate ATE\n",
        "ate_dr_plm = np.mean(y_hat_treated - y_hat_control)\n",
        "\n",
        "\n",
        "residuals_dr_treated =  (y - y_hat_treated)\n",
        "residuals_dr_control =  (y - y_hat_control)\n",
        "# Variance of ATE for DR PLM\n",
        "variance_ate_dr_plm = np.var(y_hat_treated - y_hat_control) / len(y)\n",
        "\n",
        "# Standard error of ATE for DR PLM\n",
        "ate_dr_plm_se = np.sqrt(variance_ate_dr_plm)\n",
        "\n",
        "print(f\"The estimated Average Treatment Effect (ATE) : {ate_dr_plm}\")\n",
        "print(f\"The standard error of the ATE estimate : {ate_dr_plm_se}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGa1SRrX0MO1"
      },
      "source": [
        "####Method 2.Regression-Based w interactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPhnP35s0Q4G",
        "outputId": "0013c9f4-47b3-46d3-8b99-682af2fa19af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Maximum number of iterations has been exceeded.\n",
            "         Current function value: 0.391750\n",
            "         Iterations: 35\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:                 DIQ010   No. Observations:                 2620\n",
            "Model:                          Logit   Df Residuals:                     2553\n",
            "Method:                           MLE   Df Model:                           66\n",
            "Date:                Mon, 08 Jul 2024   Pseudo R-squ.:                  0.1889\n",
            "Time:                        02:34:04   Log-Likelihood:                -1026.4\n",
            "converged:                      False   LL-Null:                       -1265.5\n",
            "Covariance Type:                  HC1   LLR p-value:                 8.499e-64\n",
            "======================================================================================================\n",
            "                                         coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------------------------------\n",
            "const                                 -1.9448        nan        nan        nan         nan         nan\n",
            "exercise                              -0.2319      0.146     -1.584      0.113      -0.519       0.055\n",
            "unhealthy_condition                    1.0339        nan        nan        nan         nan         nan\n",
            "ALQ121                                -1.6561   2477.501     -0.001      0.999   -4857.470    4854.158\n",
            "INDFMIN2                               0.0070      0.020      0.341      0.733      -0.033       0.047\n",
            "RIAGENDR                              -0.2254      0.094     -2.399      0.016      -0.410      -0.041\n",
            "RIDAGEYR_fixed                         0.0613      0.006     10.673      0.000       0.050       0.073\n",
            "SLD012                                 0.0699      0.052      1.338      0.181      -0.032       0.172\n",
            "BPXPULS                               -7.7404   3430.364     -0.002      0.998   -6731.131    6715.650\n",
            "Sys_AVEBP                              0.0044      0.005      0.878      0.380      -0.005       0.014\n",
            "BMXBMI                                 0.0803      0.012      6.848      0.000       0.057       0.103\n",
            "smoker_con                            -0.1818      0.216     -0.840      0.401      -0.606       0.242\n",
            "exercise:unhealthy_condition           0.1907      0.466      0.409      0.682      -0.723       1.104\n",
            "exercise:ALQ121                       -0.1590      0.458     -0.347      0.728      -1.056       0.738\n",
            "exercise:INDFMIN2                     -0.0225      0.029     -0.780      0.436      -0.079       0.034\n",
            "exercise:RIAGENDR                      0.0076      0.126      0.061      0.952      -0.239       0.254\n",
            "exercise:RIDAGEYR_fixed               -0.0167      0.008     -2.100      0.036      -0.032      -0.001\n",
            "exercise:SLD012                       -0.1436      0.077     -1.866      0.062      -0.295       0.007\n",
            "exercise:BPXPULS                       0.3366      0.793      0.424      0.671      -1.218       1.891\n",
            "exercise:Sys_AVEBP                     0.0105      0.007      1.599      0.110      -0.002       0.023\n",
            "exercise:BMXBMI                       -0.0059      0.017     -0.350      0.726      -0.039       0.027\n",
            "exercise:smoker_con                   -0.5616      0.354     -1.585      0.113      -1.256       0.133\n",
            "unhealthy_condition:ALQ121             1.1192      1.625      0.689      0.491      -2.066       4.304\n",
            "unhealthy_condition:INDFMIN2          -0.0670      0.059     -1.138      0.255      -0.182       0.048\n",
            "unhealthy_condition:RIAGENDR          -0.1503      0.235     -0.640      0.522      -0.611       0.310\n",
            "unhealthy_condition:RIDAGEYR_fixed    -0.0067      0.014     -0.479      0.632      -0.034       0.021\n",
            "unhealthy_condition:SLD012            -0.2399      0.121     -1.983      0.047      -0.477      -0.003\n",
            "unhealthy_condition:BPXPULS           24.5466        nan        nan        nan         nan         nan\n",
            "unhealthy_condition:Sys_AVEBP         -0.0026      0.011     -0.225      0.822      -0.025       0.020\n",
            "unhealthy_condition:BMXBMI             0.0020      0.031      0.065      0.948      -0.059       0.063\n",
            "unhealthy_condition:smoker_con         1.0702      0.703      1.523      0.128      -0.307       2.448\n",
            "ALQ121:INDFMIN2                        0.0365      0.046      0.785      0.433      -0.055       0.128\n",
            "ALQ121:RIAGENDR                       -0.3478      0.263     -1.324      0.186      -0.863       0.167\n",
            "ALQ121:RIDAGEYR_fixed                 -0.0025      0.014     -0.176      0.861      -0.030       0.025\n",
            "ALQ121:SLD012                         -0.1588      0.152     -1.043      0.297      -0.457       0.140\n",
            "ALQ121:BPXPULS                       -31.9568   1.28e+05     -0.000      1.000    -2.5e+05     2.5e+05\n",
            "ALQ121:Sys_AVEBP                       0.0053      0.010      0.555      0.579      -0.013       0.024\n",
            "ALQ121:BMXBMI                          0.0289      0.035      0.819      0.413      -0.040       0.098\n",
            "ALQ121:smoker_con                     -0.3465      0.485     -0.715      0.475      -1.296       0.603\n",
            "INDFMIN2:RIAGENDR                     -0.0069      0.014     -0.484      0.629      -0.035       0.021\n",
            "INDFMIN2:RIDAGEYR_fixed                0.0004      0.001      0.408      0.683      -0.001       0.002\n",
            "INDFMIN2:SLD012                        0.0117      0.008      1.448      0.148      -0.004       0.028\n",
            "INDFMIN2:BPXPULS                       0.0830      0.098      0.844      0.399      -0.110       0.276\n",
            "INDFMIN2:Sys_AVEBP                    -0.0009      0.001     -1.290      0.197      -0.002       0.000\n",
            "INDFMIN2:BMXBMI                        0.0005      0.002      0.230      0.818      -0.003       0.004\n",
            "INDFMIN2:smoker_con                   -0.0114      0.038     -0.301      0.764      -0.086       0.063\n",
            "RIAGENDR:RIDAGEYR_fixed               -0.0048      0.004     -1.178      0.239      -0.013       0.003\n",
            "RIAGENDR:SLD012                       -0.0748      0.036     -2.066      0.039      -0.146      -0.004\n",
            "RIAGENDR:BPXPULS                       0.2675      0.385      0.696      0.487      -0.486       1.021\n",
            "RIAGENDR:Sys_AVEBP                    -0.0006      0.003     -0.186      0.852      -0.007       0.006\n",
            "RIAGENDR:BMXBMI                       -0.0124      0.008     -1.525      0.127      -0.028       0.004\n",
            "RIAGENDR:smoker_con                   -0.0797      0.165     -0.484      0.629      -0.403       0.243\n",
            "RIDAGEYR_fixed:SLD012                 -0.0027      0.002     -1.153      0.249      -0.007       0.002\n",
            "RIDAGEYR_fixed:BPXPULS                 0.0627      0.048      1.306      0.192      -0.031       0.157\n",
            "RIDAGEYR_fixed:Sys_AVEBP              -0.0003      0.000     -1.497      0.134      -0.001       0.000\n",
            "RIDAGEYR_fixed:BMXBMI                  0.0014      0.001      2.627      0.009       0.000       0.002\n",
            "RIDAGEYR_fixed:smoker_con              0.0131      0.010      1.305      0.192      -0.007       0.033\n",
            "SLD012:BPXPULS                        -0.1061      0.176     -0.604      0.546      -0.450       0.238\n",
            "SLD012:Sys_AVEBP                       0.0010      0.002      0.492      0.623      -0.003       0.005\n",
            "SLD012:BMXBMI                         -0.0107      0.005     -2.358      0.018      -0.020      -0.002\n",
            "SLD012:smoker_con                      0.0051      0.089      0.057      0.954      -0.168       0.179\n",
            "BPXPULS:Sys_AVEBP                     -0.0015      0.018     -0.083      0.934      -0.036       0.033\n",
            "BPXPULS:BMXBMI                         0.1046      0.066      1.596      0.110      -0.024       0.233\n",
            "BPXPULS:smoker_con                     1.3636      0.920      1.483      0.138      -0.439       3.166\n",
            "Sys_AVEBP:BMXBMI                      -0.0011      0.000     -2.677      0.007      -0.002      -0.000\n",
            "Sys_AVEBP:smoker_con                  -0.0069      0.008     -0.909      0.363      -0.022       0.008\n",
            "BMXBMI:smoker_con                      0.0553      0.020      2.783      0.005       0.016       0.094\n",
            "======================================================================================================\n",
            "AUC: 0.7515702427169145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
          ]
        }
      ],
      "source": [
        "## Logistic\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from itertools import combinations\n",
        "\n",
        "def ATE_est_reg_interaction(X_train, X_test, y_train, y_test):\n",
        "    # Add constant term to the features\n",
        "    cols_to_subtract_mean = X_train.columns[X_train.columns != 'exercise']\n",
        "    X_train[cols_to_subtract_mean] = X_train[cols_to_subtract_mean] - X_train[cols_to_subtract_mean].mean()\n",
        "    X_test[cols_to_subtract_mean] = X_test[cols_to_subtract_mean] - X_test[cols_to_subtract_mean].mean()\n",
        "    X_train = sm.add_constant(X_train)\n",
        "    X_test = sm.add_constant(X_test)\n",
        "\n",
        "    # Create pairwise interaction terms for X_train\n",
        "    interaction_terms_train = pd.DataFrame(index=X_train.index)\n",
        "    interaction_terms_test = pd.DataFrame(index=X_test.index)\n",
        "\n",
        "    # Get the list of feature names excluding the constant term\n",
        "    feature_names = X_train.columns[1:]\n",
        "\n",
        "    # Generate interaction terms\n",
        "    for (i, j) in combinations(feature_names, 2):\n",
        "        interaction_terms_train[f'{i}:{j}'] = X_train[i] * X_train[j]\n",
        "        interaction_terms_test[f'{i}:{j}'] = X_test[i] * X_test[j]\n",
        "\n",
        "    # Combine the original features with the interaction terms\n",
        "    X_train_inter = pd.concat([X_train, interaction_terms_train], axis=1)\n",
        "    X_test_inter = pd.concat([X_test, interaction_terms_test], axis=1)\n",
        "\n",
        "    # Fit the logistic regression model\n",
        "    model_ate = sm.Logit(y_train, X_train_inter).fit(cov_type='HC1')\n",
        "    ate_summary = model_ate.summary()\n",
        "    print(ate_summary)\n",
        "\n",
        "    # Predict probabilities on the test set\n",
        "    y_pred_prob = model_ate.predict(X_test_inter)\n",
        "\n",
        "    # Calculate AUC\n",
        "    auc = roc_auc_score(y_test, y_pred_prob)\n",
        "    print(f'AUC: {auc}')\n",
        "    return\n",
        "\n",
        "ATE_est_reg_interaction(X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEty-Ysyir2_",
        "outputId": "75439d7b-cf9a-4bfa-a290-803ee61be177"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results:\n",
            "                                   Importance\n",
            "const                                  0.0000\n",
            "exercise                               0.0005\n",
            "unhealthy_condition                    0.0002\n",
            "ALQ121                                 0.0001\n",
            "INDFMIN2                               0.0033\n",
            "RIAGENDR                               0.0004\n",
            "RIDAGEYR_fixed                         0.0502\n",
            "SLD012                                 0.0041\n",
            "BPXPULS                                0.0000\n",
            "Sys_AVEBP                              0.0076\n",
            "BMXBMI                                 0.0118\n",
            "smoker_con                             0.0003\n",
            "const:exercise                         0.0007\n",
            "const:unhealthy_condition              0.0001\n",
            "const:ALQ121                           0.0003\n",
            "const:INDFMIN2                         0.0036\n",
            "const:RIAGENDR                         0.0004\n",
            "const:RIDAGEYR_fixed                   0.0560\n",
            "const:SLD012                           0.0039\n",
            "const:BPXPULS                          0.0001\n",
            "const:Sys_AVEBP                        0.0096\n",
            "const:BMXBMI                           0.0116\n",
            "const:smoker_con                       0.0004\n",
            "exercise:unhealthy_condition           0.0016\n",
            "exercise:ALQ121                        0.0012\n",
            "exercise:INDFMIN2                      0.0093\n",
            "exercise:RIAGENDR                      0.0026\n",
            "exercise:RIDAGEYR_fixed                0.0115\n",
            "exercise:SLD012                        0.0114\n",
            "exercise:BPXPULS                       0.0011\n",
            "exercise:Sys_AVEBP                     0.0132\n",
            "exercise:BMXBMI                        0.0200\n",
            "exercise:smoker_con                    0.0022\n",
            "unhealthy_condition:ALQ121             0.0009\n",
            "unhealthy_condition:INDFMIN2           0.0110\n",
            "unhealthy_condition:RIAGENDR           0.0032\n",
            "unhealthy_condition:RIDAGEYR_fixed     0.0084\n",
            "unhealthy_condition:SLD012             0.0097\n",
            "unhealthy_condition:BPXPULS            0.0003\n",
            "unhealthy_condition:Sys_AVEBP          0.0157\n",
            "unhealthy_condition:BMXBMI             0.0201\n",
            "unhealthy_condition:smoker_con         0.0017\n",
            "ALQ121:INDFMIN2                        0.0090\n",
            "ALQ121:RIAGENDR                        0.0014\n",
            "ALQ121:RIDAGEYR_fixed                  0.0112\n",
            "ALQ121:SLD012                          0.0093\n",
            "ALQ121:BPXPULS                         0.0006\n",
            "ALQ121:Sys_AVEBP                       0.0194\n",
            "ALQ121:BMXBMI                          0.0167\n",
            "ALQ121:smoker_con                      0.0016\n",
            "INDFMIN2:RIAGENDR                      0.0163\n",
            "INDFMIN2:RIDAGEYR_fixed                0.0288\n",
            "INDFMIN2:SLD012                        0.0279\n",
            "INDFMIN2:BPXPULS                       0.0073\n",
            "INDFMIN2:Sys_AVEBP                     0.0301\n",
            "INDFMIN2:BMXBMI                        0.0355\n",
            "INDFMIN2:smoker_con                    0.0119\n",
            "RIAGENDR:RIDAGEYR_fixed                0.0212\n",
            "RIAGENDR:SLD012                        0.0171\n",
            "RIAGENDR:BPXPULS                       0.0017\n",
            "RIAGENDR:Sys_AVEBP                     0.0253\n",
            "RIAGENDR:BMXBMI                        0.0298\n",
            "RIAGENDR:smoker_con                    0.0027\n",
            "RIDAGEYR_fixed:SLD012                  0.0334\n",
            "RIDAGEYR_fixed:BPXPULS                 0.0119\n",
            "RIDAGEYR_fixed:Sys_AVEBP               0.0263\n",
            "RIDAGEYR_fixed:BMXBMI                  0.0677\n",
            "RIDAGEYR_fixed:smoker_con              0.0138\n",
            "SLD012:BPXPULS                         0.0083\n",
            "SLD012:Sys_AVEBP                       0.0302\n",
            "SLD012:BMXBMI                          0.0362\n",
            "SLD012:smoker_con                      0.0160\n",
            "BPXPULS:Sys_AVEBP                      0.0136\n",
            "BPXPULS:BMXBMI                         0.0193\n",
            "BPXPULS:smoker_con                     0.0014\n",
            "Sys_AVEBP:BMXBMI                       0.0324\n",
            "Sys_AVEBP:smoker_con                   0.0267\n",
            "BMXBMI:smoker_con                      0.0274\n",
            "AUC: 0.7525565760818105\n"
          ]
        }
      ],
      "source": [
        "## Random Forest - AUC\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from itertools import combinations\n",
        "from sklearn.utils import resample\n",
        "\n",
        "def ATE_est_reg_interaction_rf_cv(X_train, X_test, y_train, y_test, n_estimators=100, cv=5, n_bootstrap=100):\n",
        "    cols_to_subtract_mean = X_train.columns[X_train.columns != 'exercise']\n",
        "    X_train[cols_to_subtract_mean] = X_train[cols_to_subtract_mean] - X_train[cols_to_subtract_mean].mean()\n",
        "    X_test[cols_to_subtract_mean] = X_test[cols_to_subtract_mean] - X_test[cols_to_subtract_mean].mean()\n",
        "    X_train = sm.add_constant(X_train)\n",
        "    X_test = sm.add_constant(X_test)\n",
        "\n",
        "    # Create pairwise interaction terms for X_train\n",
        "    interaction_terms_train = pd.DataFrame(index=X_train.index)\n",
        "    interaction_terms_test = pd.DataFrame(index=X_test.index)\n",
        "\n",
        "    # Get the list of feature names\n",
        "    feature_names = X_train.columns\n",
        "\n",
        "    # Generate interaction terms\n",
        "    for (i, j) in combinations(feature_names, 2):\n",
        "        interaction_terms_train[f'{i}:{j}'] = X_train[i] * X_train[j]\n",
        "        interaction_terms_test[f'{i}:{j}'] = X_test[i] * X_test[j]\n",
        "\n",
        "    # Combine the original features with the interaction terms\n",
        "    X_train_inter = pd.concat([X_train, interaction_terms_train], axis=1)\n",
        "    X_test_inter = pd.concat([X_test, interaction_terms_test], axis=1)\n",
        "\n",
        "    # Fit RandomForestRegressor with cross-validation and bootstrapping\n",
        "    model_ate = RandomForestRegressor(n_estimators=n_estimators)\n",
        "\n",
        "    # Fit the model on the original training data\n",
        "    model_ate.fit(X_train_inter, y_train)\n",
        "\n",
        "    # Create a DataFrame to store results\n",
        "    results = pd.DataFrame(index=X_train_inter.columns)\n",
        "    results['Importance'] = model_ate.feature_importances_\n",
        "\n",
        "    # Print formatted table\n",
        "    print(\"Results:\")\n",
        "    print(results.to_string(formatters={'Importance': '{:.4f}'.format,\n",
        "                                         }))\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = model_ate.predict(X_test_inter)\n",
        "\n",
        "    # Calculate AUC\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    print(f'AUC: {auc}')\n",
        "\n",
        "\n",
        "    return model_ate\n",
        "\n",
        "# Example usage:\n",
        "model_ate_rf_cv = ATE_est_reg_interaction_rf_cv(X_train, X_test, y_train, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpZD92Vu9-u-",
        "outputId": "1e919474-7703-4754-e1a9-62f9b547fe8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-52-8908dccd6c78>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[cols_to_subtract_mean] = X[cols_to_subtract_mean].sub(X[cols_to_subtract_mean].mean())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The estimated Average Treatment Effect (ATE): -0.0013245860668541075\n",
            "The standard error of the ATE estimate: 0.0046567928947447565\n"
          ]
        }
      ],
      "source": [
        "## Random Forest - ATE\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Assuming df1_no_na is your DataFrame\n",
        "df1_no_na = df1[['DIQ010', 'exercise', 'unhealthy_condition', 'ALQ121', 'INDFMIN2', 'RIAGENDR', 'RIDAGEYR_fixed', 'SLD012', 'BPXPULS', 'Sys_AVEBP', 'BMXBMI', 'WH_ratio', 'smoker_con']].dropna()\n",
        "df1_no_na = df1_no_na[df1_no_na['RIDAGEYR_fixed'] >= 21]\n",
        "\n",
        "X = df1_no_na[['exercise', 'unhealthy_condition', 'ALQ121', 'INDFMIN2', 'RIAGENDR', 'RIDAGEYR_fixed', 'SLD012', 'BPXPULS', 'Sys_AVEBP', 'BMXBMI', 'WH_ratio','smoker_con']]\n",
        "y = df1_no_na['DIQ010']\n",
        "\n",
        "# Identify columns to adjust mean (all numeric except 'exercise')\n",
        "cols_to_subtract_mean = X.select_dtypes(include=np.number).columns\n",
        "cols_to_subtract_mean = cols_to_subtract_mean[cols_to_subtract_mean != 'exercise']\n",
        "\n",
        "# Subtract mean from selected columns\n",
        "X[cols_to_subtract_mean] = X[cols_to_subtract_mean].sub(X[cols_to_subtract_mean].mean())\n",
        "\n",
        "# Add constant term for intercept in statsmodels\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Create interaction terms\n",
        "interaction_terms = pd.DataFrame(index=X.index)\n",
        "feature_names = X.columns\n",
        "\n",
        "for (i, j) in combinations(feature_names, 2):\n",
        "    interaction_terms[f'{i}:{j}'] = X[i] * X[j]\n",
        "\n",
        "# Combine original features with interaction terms\n",
        "X_inter = pd.concat([X, interaction_terms], axis=1)\n",
        "\n",
        "# Fit outcome models (RandomForestRegressor)\n",
        "treatment = X['exercise']\n",
        "covariates = X_inter.drop(columns=['exercise'])\n",
        "\n",
        "outcome_model_treated = RandomForestRegressor(n_estimators=100, random_state=0).fit(covariates[treatment == 1], y[treatment == 1])\n",
        "outcome_model_control = RandomForestRegressor(n_estimators=100, random_state=0).fit(covariates[treatment == 0], y[treatment == 0])\n",
        "\n",
        "# Predict outcomes\n",
        "y_hat_treated = outcome_model_treated.predict(covariates)\n",
        "y_hat_control = outcome_model_control.predict(covariates)\n",
        "\n",
        "# Calculate ATE using doubly robust PLM estimates\n",
        "ate_dr_plm = np.mean(y_hat_treated - y_hat_control)\n",
        "\n",
        "# Residuals for DR PLM\n",
        "residuals_dr_treated = (y - y_hat_treated)\n",
        "residuals_dr_control = (y - y_hat_control)\n",
        "\n",
        "# Variance of ATE for DR PLM\n",
        "variance_ate_dr_plm = np.var(y_hat_treated - y_hat_control) / len(y)\n",
        "\n",
        "# Standard error of ATE for DR PLM\n",
        "ate_dr_plm_se = np.sqrt(variance_ate_dr_plm)\n",
        "\n",
        "print(f\"The estimated Average Treatment Effect (ATE): {ate_dr_plm}\")\n",
        "print(f\"The standard error of the ATE estimate: {ate_dr_plm_se}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bRHZcCU3248"
      },
      "source": [
        "####Method 3.IPWE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLwQ4fjL0auf",
        "outputId": "4b15d637-c0fc-4a29-adae-f423464956f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The estimated Average Treatment Effect (ATE) is: -0.03555312252226375\n",
            "The standard error of the ATE estimate is: 0.014405907611051127\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Assuming df1_no_na is your DataFrame\n",
        "\n",
        "# Define treatment and covariates\n",
        "X = df1_no_na[['exercise', 'ALQ121', 'unhealthy_condition', 'INDFMIN2', 'RIAGENDR', 'RIDAGEYR_fixed', 'SLD012', 'BPXPULS', 'Sys_AVEBP', 'BMXBMI', 'smoker_con']]\n",
        "y = df1_no_na['DIQ010']\n",
        "\n",
        "# Step 1: Estimate Propensity Scores\n",
        "# Separate the treatment variable and the covariates\n",
        "treatment = X['exercise']\n",
        "covariates = X.drop(columns=['exercise'])\n",
        "\n",
        "# Fit a logistic regression model to estimate propensity scores\n",
        "log_reg = LogisticRegression(solver='liblinear')\n",
        "log_reg.fit(covariates, treatment)\n",
        "propensity_scores = log_reg.predict_proba(covariates)[:, 1]\n",
        "\n",
        "# Step 2: Calculate Weights\n",
        "weights_treatment = 1 / propensity_scores\n",
        "weights_control = 1 / (1 - propensity_scores)\n",
        "\n",
        "# Step 3: Estimate ATE using the average of weighted outcomes method\n",
        "# Filter the weights to match the corresponding treatment and control groups\n",
        "weights_treatment_filtered = weights_treatment[treatment == 1]\n",
        "weights_control_filtered = weights_control[treatment == 0]\n",
        "\n",
        "# Weighted outcomes for treatment and control groups\n",
        "weighted_outcome_treatment = np.sum(weights_treatment_filtered * y[treatment == 1]) / np.sum(weights_treatment_filtered)\n",
        "weighted_outcome_control = np.sum(weights_control_filtered * y[treatment == 0]) / np.sum(weights_control_filtered)\n",
        "\n",
        "# Calculate ATE\n",
        "ate = weighted_outcome_treatment - weighted_outcome_control\n",
        "\n",
        "# Calculate standard errors\n",
        "# Compute the weighted residuals\n",
        "residuals_treatment = weights_treatment_filtered * (y[treatment == 1] - weighted_outcome_treatment)\n",
        "residuals_control = weights_control_filtered * (y[treatment == 0] - weighted_outcome_control)\n",
        "\n",
        "# Variance of ATE\n",
        "variance_ate = (np.sum(residuals_treatment ** 2) / (np.sum(weights_treatment_filtered) ** 2)) + (np.sum(residuals_control ** 2) / (np.sum(weights_control_filtered) ** 2))\n",
        "\n",
        "# Standard error of ATE\n",
        "ate_se = np.sqrt(variance_ate)\n",
        "\n",
        "print(f\"The estimated Average Treatment Effect (ATE) is: {ate}\")\n",
        "print(f\"The standard error of the ATE estimate is: {ate_se}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c5EyqwY7_An-",
        "outputId": "b2e9d3aa-2723-4079-d48a-ae2058f3f5b6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Covariate  Mean_Treated  Mean_Control  SMD_Before  SMD_After  \\\n",
            "0               ALQ121      0.148313      0.117791    0.089958   0.011471   \n",
            "1  unhealthy_condition      0.936983      0.920245    0.065042   0.094126   \n",
            "2             INDFMIN2      9.665181      7.826994    0.422332   0.068899   \n",
            "3             RIAGENDR      0.943348      1.007362   -0.064066   0.032800   \n",
            "4       RIDAGEYR_fixed     48.226607     53.942331   -0.335919   0.083862   \n",
            "5               SLD012      7.558880      7.491411    0.041376   0.105915   \n",
            "6              BPXPULS      0.024825      0.046626   -0.117661   0.006858   \n",
            "7            Sys_AVEBP    123.196266    128.048262   -0.263712   0.111507   \n",
            "8               BMXBMI     29.126034     30.531472   -0.199102   0.100200   \n",
            "9           smoker_con      0.222788      0.296933   -0.169672   0.017341   \n",
            "\n",
            "   p-value_Before  p-value_After  \n",
            "0    1.094751e-02       0.745995  \n",
            "1    6.626820e-02       0.007812  \n",
            "2    3.234842e-32       0.052852  \n",
            "3    7.016577e-02       0.353287  \n",
            "4    3.937842e-21       0.017109  \n",
            "5    2.429382e-01       0.002772  \n",
            "6    9.171756e-04       0.845695  \n",
            "7    1.225123e-13       0.001562  \n",
            "8    2.027975e-08       0.004471  \n",
            "9    1.714908e-06       0.623172  \n",
            "      DIQ010  exercise  unhealthy_condition  ALQ121  INDFMIN2  RIAGENDR  \\\n",
            "6044     0.0         0                    1     0.0       3.0       2.0   \n",
            "8848     0.0         0                    0     0.0       1.0       2.0   \n",
            "6686     0.0         0                    0     0.0       2.0       2.0   \n",
            "3295     1.0         0                    1     0.0       2.0       2.0   \n",
            "5912     1.0         0                    1     0.0       1.0       2.0   \n",
            "...      ...       ...                  ...     ...       ...       ...   \n",
            "7906     0.0         1                    1     0.0      15.0       0.0   \n",
            "1345     0.0         0                    1     1.0      14.0       0.0   \n",
            "1713     0.0         1                    1     1.0      15.0       2.0   \n",
            "5938     0.0         1                    1     1.0      14.0       0.0   \n",
            "6715     0.0         1                    1     1.0      15.0       0.0   \n",
            "\n",
            "      RIDAGEYR_fixed  SLD012  BPXPULS   Sys_AVEBP  BMXBMI  WH_ratio  \\\n",
            "6044            80.0     3.0      1.0  158.666667    36.1  0.947279   \n",
            "8848            58.0     9.0      0.0  156.000000    44.0  0.727922   \n",
            "6686            55.0     6.0      0.0  221.333333    31.1  1.047244   \n",
            "3295            68.0     6.5      0.0  132.666667    42.7  0.893786   \n",
            "5912            63.0     6.5      0.0  116.000000    44.7  0.951673   \n",
            "...              ...     ...      ...         ...     ...       ...   \n",
            "7906            22.0     7.0      0.0  108.000000    21.3  0.863582   \n",
            "1345            23.0     7.0      0.0  108.666667    26.5  0.849952   \n",
            "1713            36.0     8.5      0.0   91.333333    19.4  0.759280   \n",
            "5938            23.0     7.5      0.0  139.333333    22.7  0.869121   \n",
            "6715            31.0     7.5      0.0  112.666667    23.2  0.847913   \n",
            "\n",
            "      smoker_con  propensity_score   weights  \n",
            "6044         0.0          0.117641  1.133326  \n",
            "8848         1.0          0.142519  1.166206  \n",
            "6686         1.0          0.144474  1.168872  \n",
            "3295         1.0          0.145669  1.170507  \n",
            "5912         1.0          0.149337  1.175554  \n",
            "...          ...               ...       ...  \n",
            "7906         0.0          0.817995  1.222501  \n",
            "1345         0.0          0.820011  5.555906  \n",
            "1713         0.0          0.820059  1.219425  \n",
            "5938         0.0          0.820066  1.219415  \n",
            "6715         0.0          0.824436  1.212950  \n",
            "\n",
            "[3201 rows x 15 columns]\n"
          ]
        }
      ],
      "source": [
        "## Check overlap assumption\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Add the propensity scores to the original DataFrame\n",
        "df1_no_na['propensity_score'] = propensity_scores\n",
        "df1_no_na['weights'] = np.where(df1_no_na['exercise'] == 1, weights_treatment, weights_control)\n",
        "\n",
        "# Plot the distribution of propensity scores\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df1_no_na[df1_no_na['exercise'] == 1]['propensity_score'], label='Treated', color='blue', kde=True, stat=\"density\", bins=25)\n",
        "sns.histplot(df1_no_na[df1_no_na['exercise'] == 0]['propensity_score'], label='Control', color='red', kde=True, stat=\"density\", bins=25)\n",
        "plt.xlabel('Propensity Score')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Distribution of Propensity Scores')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Function to calculate standardized mean difference\n",
        "def standardized_mean_difference(group1, group2):\n",
        "    mean_diff = np.mean(group1) - np.mean(group2)\n",
        "    pooled_std = np.sqrt((np.std(group1)**2 + np.std(group2)**2) / 2)\n",
        "    return mean_diff / pooled_std\n",
        "\n",
        "# Check covariate balance before and after weighting\n",
        "covariate_columns = covariates.columns\n",
        "balance_data = []\n",
        "\n",
        "for covariate in covariate_columns:\n",
        "    treated_group = df1_no_na[df1_no_na['exercise'] == 1][covariate]\n",
        "    control_group = df1_no_na[df1_no_na['exercise'] == 0][covariate]\n",
        "\n",
        "    # Calculate means before weighting\n",
        "    mean_treated_before = np.mean(treated_group)\n",
        "    mean_control_before = np.mean(control_group)\n",
        "\n",
        "    # Calculate SMD before weighting\n",
        "    smd_before = standardized_mean_difference(treated_group, control_group)\n",
        "\n",
        "    # Calculate t-test before weighting\n",
        "    t_stat_before, p_val_before = ttest_ind(treated_group, control_group)\n",
        "\n",
        "    # Calculate means after weighting\n",
        "    mean_treated_after = np.average(df1_no_na[df1_no_na['exercise'] == 1][covariate], weights=df1_no_na[df1_no_na['exercise'] == 1]['weights'])\n",
        "    mean_control_after = np.average(df1_no_na[df1_no_na['exercise'] == 0][covariate], weights=df1_no_na[df1_no_na['exercise'] == 0]['weights'])\n",
        "\n",
        "    # Calculate SMD after weighting\n",
        "    smd_after = standardized_mean_difference(\n",
        "        df1_no_na[df1_no_na['exercise'] == 1][covariate] * df1_no_na[df1_no_na['exercise'] == 1]['weights'],\n",
        "        df1_no_na[df1_no_na['exercise'] == 0][covariate] * df1_no_na[df1_no_na['exercise'] == 0]['weights']\n",
        "    )\n",
        "\n",
        "    # Calculate t-test after weighting\n",
        "    t_stat_after, p_val_after = ttest_ind(\n",
        "        df1_no_na[df1_no_na['exercise'] == 1][covariate] * df1_no_na[df1_no_na['exercise'] == 1]['weights'],\n",
        "        df1_no_na[df1_no_na['exercise'] == 0][covariate] * df1_no_na[df1_no_na['exercise'] == 0]['weights']\n",
        "    )\n",
        "\n",
        "    # Append to balance data\n",
        "    balance_data.append({\n",
        "        'Covariate': covariate,\n",
        "        'Mean_Treated': mean_treated_before,\n",
        "        'Mean_Control': mean_control_before,\n",
        "        'SMD_Before': smd_before,\n",
        "        'SMD_After': smd_after,\n",
        "        'p-value_Before': p_val_before,\n",
        "        'p-value_After': p_val_after\n",
        "    })\n",
        "\n",
        "balance_table = pd.DataFrame(balance_data)\n",
        "\n",
        "print(balance_table)\n",
        "\n",
        "print(df1_no_na.sort_values(by='propensity_score', ascending=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt_CNFU89sZs"
      },
      "source": [
        "####Method 4.AIPWE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcoIUQ3G-HX0",
        "outputId": "0058b893-2d12-400f-b617-07f24b418f70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The estimated Average Treatment Effect (ATE) using Doubly Robust method is: -0.030944577808572727\n",
            "The standard error of the ATE estimate using Doubly Robust method is: 0.015618628125673592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Assuming df1_no_na is your DataFrame\n",
        "\n",
        "# Define treatment and covariates\n",
        "X = df1_no_na[['exercise', 'ALQ121', 'unhealthy_condition', 'INDFMIN2', 'RIAGENDR', 'RIDAGEYR_fixed', 'SLD012', 'BPXPULS', 'Sys_AVEBP', 'BMXBMI', 'smoker_con']]\n",
        "y = df1_no_na['DIQ010']\n",
        "\n",
        "# Step 1: Estimate Propensity Scores\n",
        "# Separate the treatment variable and the covariates\n",
        "treatment = X['exercise']\n",
        "covariates = X.drop(columns=['exercise'])\n",
        "\n",
        "# Fit a logistic regression model to estimate propensity scores\n",
        "log_reg = LogisticRegression(solver='liblinear')\n",
        "log_reg.fit(covariates, treatment)\n",
        "propensity_scores = log_reg.predict_proba(covariates)[:, 1]\n",
        "\n",
        "# Step 2: Calculate Weights\n",
        "weights_treatment = 1 / propensity_scores\n",
        "weights_control = 1 / (1 - propensity_scores)\n",
        "\n",
        "# Filter the weights to match the corresponding treatment and control groups\n",
        "weights_treatment_filtered = weights_treatment[treatment == 1]\n",
        "weights_control_filtered = weights_control[treatment == 0]\n",
        "\n",
        "# Step 3: Estimate ATE using the average of weighted outcomes method\n",
        "# Weighted outcomes for treatment and control groups\n",
        "weighted_outcome_treatment = np.sum(weights_treatment_filtered * y[treatment == 1]) / np.sum(weights_treatment_filtered)\n",
        "weighted_outcome_control = np.sum(weights_control_filtered * y[treatment == 0]) / np.sum(weights_control_filtered)\n",
        "\n",
        "# Calculate ATE\n",
        "ate_ipw = weighted_outcome_treatment - weighted_outcome_control\n",
        "\n",
        "# Calculate standard errors for IPW\n",
        "# Compute the weighted residuals\n",
        "residuals_treatment = weights_treatment_filtered * (y[treatment == 1] - weighted_outcome_treatment)\n",
        "residuals_control = weights_control_filtered * (y[treatment == 0] - weighted_outcome_control)\n",
        "\n",
        "# Variance of ATE\n",
        "variance_ate_ipw = (np.sum(residuals_treatment ** 2) / (np.sum(weights_treatment_filtered) ** 2)) + (np.sum(residuals_control ** 2) / (np.sum(weights_control_filtered) ** 2))\n",
        "\n",
        "# Standard error of ATE\n",
        "ate_ipw_se = np.sqrt(variance_ate_ipw)\n",
        "\n",
        "# Step 4: Doubly Robust Estimation\n",
        "# Fit outcome regression models\n",
        "outcome_model_treated = LogisticRegression().fit(covariates[treatment == 1], y[treatment == 1])\n",
        "outcome_model_control = LogisticRegression().fit(covariates[treatment == 0], y[treatment == 0])\n",
        "\n",
        "# Predict outcomes\n",
        "y_hat_treated = outcome_model_treated.predict(covariates)\n",
        "y_hat_control = outcome_model_control.predict(covariates)\n",
        "\n",
        "# Calculate the doubly robust estimates\n",
        "dr_estimate_treated = y_hat_treated + (treatment / propensity_scores) * (y - y_hat_treated)\n",
        "dr_estimate_control = y_hat_control + ((1 - treatment) / (1 - propensity_scores)) * (y - y_hat_control)\n",
        "\n",
        "# Calculate ATE using doubly robust estimates\n",
        "ate_dr = np.mean(dr_estimate_treated - dr_estimate_control)\n",
        "\n",
        "# Calculate standard errors for DR\n",
        "# Residuals for DR\n",
        "residuals_dr_treated = (treatment / propensity_scores) * (y - y_hat_treated)\n",
        "residuals_dr_control = ((1 - treatment) / (1 - propensity_scores)) * (y - y_hat_control)\n",
        "\n",
        "# Variance of ATE for DR\n",
        "variance_ate_dr = np.var(dr_estimate_treated - dr_estimate_control) / len(y)\n",
        "\n",
        "# Standard error of ATE for DR\n",
        "ate_dr_se = np.sqrt(variance_ate_dr)\n",
        "\n",
        "print(f\"The estimated Average Treatment Effect (ATE) using Doubly Robust method is: {ate_dr}\")\n",
        "print(f\"The standard error of the ATE estimate using Doubly Robust method is: {ate_dr_se}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ2ELZue-Hn6"
      },
      "source": [
        "####Method 5.Double Robust PLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrGg0ypI-ORY",
        "outputId": "c0545de4-5223-4ba3-ae8e-bfeab1f79060"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The estimated Average Treatment Effect (ATE) using Doubly Robust PLM method is: -0.030098768074424184\n",
            "The standard error of the ATE estimate using Doubly Robust PLM method is: 0.009172871906457802\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Assuming df1_no_na is your DataFrame\n",
        "\n",
        "# Define treatment and covariates\n",
        "X = df1_no_na[['exercise', 'ALQ121', 'unhealthy_condition', 'INDFMIN2', 'RIAGENDR', 'RIDAGEYR_fixed', 'SLD012', 'BPXPULS', 'Sys_AVEBP', 'BMXBMI', 'smoker_con']]\n",
        "y = df1_no_na['DIQ010']\n",
        "\n",
        "# Step 1: Estimate Propensity Scores\n",
        "# Separate the treatment variable and the covariates\n",
        "treatment = X['exercise']\n",
        "covariates = X.drop(columns=['exercise'])\n",
        "\n",
        "# Fit a logistic regression model to estimate propensity scores\n",
        "log_reg = LogisticRegression(solver='liblinear')\n",
        "log_reg.fit(covariates, treatment)\n",
        "propensity_scores = log_reg.predict_proba(covariates)[:, 1]\n",
        "\n",
        "# Step 2: Outcome Regression using Partially Linear Model (PLM)\n",
        "# Fit outcome regression models using a flexible model like RandomForestRegressor\n",
        "outcome_model_treated = RandomForestRegressor(n_estimators=100, random_state=0).fit(covariates[treatment == 1], y[treatment == 1])\n",
        "outcome_model_control = RandomForestRegressor(n_estimators=100, random_state=0).fit(covariates[treatment == 0], y[treatment == 0])\n",
        "\n",
        "\n",
        "# Predict outcomes\n",
        "y_hat_treated = outcome_model_treated.predict(covariates)\n",
        "y_hat_control = outcome_model_control.predict(covariates)\n",
        "\n",
        "# Calculate the doubly robust estimates\n",
        "dr_estimate_treated = y_hat_treated + (treatment / propensity_scores) * (y - y_hat_treated)\n",
        "dr_estimate_control = y_hat_control + ((1 - treatment) / (1 - propensity_scores)) * (y - y_hat_control)\n",
        "\n",
        "# Calculate ATE using doubly robust PLM estimates\n",
        "ate_dr_plm = np.mean(dr_estimate_treated - dr_estimate_control)\n",
        "\n",
        "# Calculate standard errors for DR PLM\n",
        "# Residuals for DR PLM\n",
        "residuals_dr_treated = (treatment / propensity_scores) * (y - y_hat_treated)\n",
        "residuals_dr_control = ((1 - treatment) / (1 - propensity_scores)) * (y - y_hat_control)\n",
        "\n",
        "# Variance of ATE for DR PLM\n",
        "variance_ate_dr_plm = np.var(dr_estimate_treated - dr_estimate_control) / len(y)\n",
        "\n",
        "# Standard error of ATE for DR PLM\n",
        "ate_dr_plm_se = np.sqrt(variance_ate_dr_plm)\n",
        "\n",
        "print(f\"The estimated Average Treatment Effect (ATE) using Doubly Robust PLM method is: {ate_dr_plm}\")\n",
        "print(f\"The standard error of the ATE estimate using Doubly Robust PLM method is: {ate_dr_plm_se}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4wHd-nTPbA1"
      },
      "source": [
        "### Hypothesis 2 DIQ010 ~ 'BMI_above_30'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Swmz8qxYbDX"
      },
      "source": [
        "#### Method 1.Regression-Based w/o interactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7evD1pegPaSM"
      },
      "outputs": [],
      "source": [
        "##\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "df1_no_na = df1[['DIQ010', 'BMI_above_30','exercise', 'unhealthy_condition', 'ALQ121', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'SLD012','BPXPULS','Sys_AVEBP','smoker_con']].dropna()\n",
        "df1_no_na = df1_no_na[df1_no_na['RIDAGEYR_fixed'] >= 21]\n",
        "\n",
        "\n",
        "X = df1_no_na[['BMI_above_30','exercise', 'unhealthy_condition', 'ALQ121','INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'SLD012','BPXPULS','Sys_AVEBP', 'smoker_con']]\n",
        "y = df1_no_na['DIQ010']\n",
        "x_categorical_name_list = []\n",
        "X = pd.get_dummies(X, columns=x_categorical_name_list, drop_first=True)\n",
        "transformed_columns = [col for col in X.columns if any(prefix in col for prefix in x_categorical_name_list)]\n",
        "X[transformed_columns] = X[transformed_columns].astype(int)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=66)\n",
        "\n",
        "def ATE_est_reg(X_train, X_test, y_train, y_test):\n",
        "    X_train = sm.add_constant(X_train)\n",
        "    X_test = sm.add_constant(X_test)\n",
        "\n",
        "    model_ate = sm.Logit(y_train, X_train).fit(cov_type='HC1')\n",
        "    ate_summary = model_ate.summary()\n",
        "    print(ate_summary)\n",
        "\n",
        "    # Predict probabilities on the test set\n",
        "    y_pred_prob = model_ate.predict(X_test)\n",
        "\n",
        "    # Calculate AUC\n",
        "    auc = roc_auc_score(y_test, y_pred_prob)\n",
        "    print(f'AUC: {auc}')\n",
        "    return\n",
        "\n",
        "\n",
        "ATE_est_reg(X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "30dYLCYJLtR-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression, Lasso\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Assuming df1 is your dataframe and it is already loaded\n",
        "df1_no_na = df1[['DIQ010', 'BMI_above_30', 'exercise', 'unhealthy_condition', 'ALQ121', 'INDFMIN2', 'RIAGENDR', 'RIDAGEYR_fixed', 'SLD012', 'BPXPULS', 'Sys_AVEBP', 'smoker_con']].dropna()\n",
        "df1_no_na = df1_no_na[df1_no_na['RIDAGEYR_fixed'] >= 21]\n",
        "\n",
        "X = df1_no_na[['exercise', 'unhealthy_condition', 'ALQ121', 'INDFMIN2', 'RIAGENDR', 'RIDAGEYR_fixed', 'SLD012', 'BPXPULS', 'Sys_AVEBP', 'smoker_con']]\n",
        "y = df1_no_na['DIQ010']\n",
        "treatment = df1_no_na['BMI_above_30']\n",
        "\n",
        "# Assuming no categorical columns need one-hot encoding\n",
        "x_categorical_name_list = []\n",
        "X = pd.get_dummies(X, columns=x_categorical_name_list, drop_first=True)\n",
        "transformed_columns = [col for col in X.columns if any(prefix in col for prefix in x_categorical_name_list)]\n",
        "X[transformed_columns] = X[transformed_columns].astype(int)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test, treatment_train, treatment_test = train_test_split(X, y, treatment, test_size=0.2, random_state=66)\n",
        "\n",
        "def bootstrap_ate_auc(model, X_train, X_test, y_train, y_test, treatment_train, n_bootstraps=1000):\n",
        "    ate_values = []\n",
        "    auc_values = []\n",
        "\n",
        "    for _ in range(n_bootstraps):\n",
        "        X_resampled, y_resampled, treatment_resampled = resample(X_train, y_train, treatment_train)\n",
        "        model.fit(X_resampled, y_resampled)\n",
        "\n",
        "        if hasattr(model, 'predict_proba'):\n",
        "            y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
        "        else:\n",
        "            y_pred_prob = model.predict(X_test)\n",
        "            y_pred_prob = (y_pred_prob > 0.5).astype(int)  # Binarize the predictions\n",
        "\n",
        "        # Calculate ATE based on the treatment\n",
        "        ate = np.mean(y_pred_prob[treatment_test == 1]) - np.mean(y_pred_prob[treatment_test == 0])\n",
        "        ate_values.append(ate)\n",
        "\n",
        "        # Calculate AUC\n",
        "        auc = roc_auc_score(y_test, y_pred_prob)\n",
        "        auc_values.append(auc)\n",
        "\n",
        "    ate_mean = np.mean(ate_values)\n",
        "    ate_se = np.std(ate_values, ddof=1)\n",
        "    auc_mean = np.mean(auc_values)\n",
        "\n",
        "    return ate_mean, ate_se, auc_mean\n",
        "\n",
        "# Logistic Regression\n",
        "log_reg = LogisticRegression(max_iter=10000)\n",
        "ate_log_reg, se_log_reg, auc_log_reg = bootstrap_ate_auc(log_reg, X_train, X_test, y_train, y_test, treatment_train)\n",
        "print(f'Logistic Regression - ATE: {ate_log_reg}, SE: {se_log_reg}, AUC: {auc_log_reg}')\n",
        "\n",
        "# Lasso Regression\n",
        "lasso = Lasso(alpha=0.1)\n",
        "ate_lasso, se_lasso, auc_lasso = bootstrap_ate_auc(lasso, X_train, X_test, y_train, y_test, treatment_train)\n",
        "print(f'Lasso Regression - ATE: {ate_lasso}, SE: {se_lasso}, AUC: {auc_lasso}')\n",
        "\n",
        "# Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=66)\n",
        "ate_rf_clf, se_rf_clf, auc_rf_clf = bootstrap_ate_auc(rf_clf, X_train, X_test, y_train, y_test, treatment_train)\n",
        "print(f'Random Forest Classifier - ATE: {ate_rf_clf}, SE: {se_rf_clf}, AUC: {auc_rf_clf}')\n",
        "\n",
        "# Decision Tree Classifier\n",
        "dt_clf = DecisionTreeClassifier(random_state=66)\n",
        "ate_dt_clf, se_dt_clf, auc_dt_clf = bootstrap_ate_auc(dt_clf, X_train, X_test, y_train, y_test, treatment_train)\n",
        "print(f'Decision Tree Classifier - ATE: {ate_dt_clf}, SE: {se_dt_clf}, AUC: {auc_dt_clf}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eu7QEhawYonT"
      },
      "source": [
        "####Method 2.Regression-Based w/ interactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZqmLezl2QzdD"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from itertools import combinations\n",
        "\n",
        "def ATE_est_reg_interaction(X_train, X_test, y_train, y_test):\n",
        "    # Add constant term to the features\n",
        "    cols_to_subtract_mean = X_train.columns[X_train.columns != 'BMI_above_30']\n",
        "    X_train[cols_to_subtract_mean] = X_train[cols_to_subtract_mean] - X_train[cols_to_subtract_mean].mean()\n",
        "    X_test[cols_to_subtract_mean] = X_test[cols_to_subtract_mean] - X_test[cols_to_subtract_mean].mean()\n",
        "    X_train = sm.add_constant(X_train)\n",
        "    X_test = sm.add_constant(X_test)\n",
        "\n",
        "    # Create pairwise interaction terms for X_train\n",
        "    interaction_terms_train = pd.DataFrame(index=X_train.index)\n",
        "    interaction_terms_test = pd.DataFrame(index=X_test.index)\n",
        "\n",
        "    # Get the list of feature names excluding the constant term\n",
        "    feature_names = X_train.columns[1:]\n",
        "\n",
        "    # Generate interaction terms\n",
        "    for (i, j) in combinations(feature_names, 2):\n",
        "        interaction_terms_train[f'{i}:{j}'] = X_train[i] * X_train[j]\n",
        "        interaction_terms_test[f'{i}:{j}'] = X_test[i] * X_test[j]\n",
        "\n",
        "    # Combine the original features with the interaction terms\n",
        "    X_train_inter = pd.concat([X_train, interaction_terms_train], axis=1)\n",
        "    X_test_inter = pd.concat([X_test, interaction_terms_test], axis=1)\n",
        "\n",
        "    # Fit the logistic regression model\n",
        "    model_ate = sm.Logit(y_train, X_train_inter).fit(cov_type='HC1')\n",
        "    ate_summary = model_ate.summary()\n",
        "    print(ate_summary)\n",
        "\n",
        "    # Predict probabilities on the test set\n",
        "    y_pred_prob = model_ate.predict(X_test_inter)\n",
        "\n",
        "    # Calculate AUC\n",
        "    auc = roc_auc_score(y_test, y_pred_prob)\n",
        "    print(f'AUC: {auc}')\n",
        "    return\n",
        "\n",
        "ATE_est_reg_interaction(X_train, X_test, y_train, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mxfZW3eURAnL"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from itertools import combinations\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def ATE_est_reg_interaction_lasso_cv(X_train, X_test, y_train, y_test, alphas=np.logspace(-4, 2, 10), cv=5):\n",
        "    # Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Create pairwise interaction terms for X_train\n",
        "    interaction_terms_train = pd.DataFrame(index=X_train.index)\n",
        "    interaction_terms_test = pd.DataFrame(index=X_test.index)\n",
        "\n",
        "    # Get the list of feature names\n",
        "    feature_names = X_train.columns\n",
        "\n",
        "    # Generate interaction terms\n",
        "    for (i, j) in combinations(feature_names, 2):\n",
        "        interaction_terms_train[f'{i}:{j}'] = X_train[i] * X_train[j]\n",
        "        interaction_terms_test[f'{i}:{j}'] = X_test[i] * X_test[j]\n",
        "\n",
        "    # Combine the original features with the interaction terms\n",
        "    X_train_inter = pd.concat([X_train, interaction_terms_train], axis=1)\n",
        "    X_test_inter = pd.concat([X_test, interaction_terms_test], axis=1)\n",
        "\n",
        "    # Fit Logistic Regression with Lasso (L1) regularization and cross-validation\n",
        "    model_ate = LogisticRegressionCV(Cs=alphas, cv=cv, penalty='l1', solver='liblinear', scoring='roc_auc')\n",
        "    model_ate.fit(X_train_inter, y_train)\n",
        "\n",
        "    # Print selected features\n",
        "    selected_features = X_train_inter.columns[model_ate.coef_[0] != 0]\n",
        "    print(\"Selected Features:\", selected_features)\n",
        "\n",
        "    # Extract coefficients and standard errors\n",
        "    coef = model_ate.coef_[0]\n",
        "    coef_std_err = np.std([model_ate.coef_[i] for i in range(len(model_ate.coef_))], axis=0)\n",
        "\n",
        "    # Create a DataFrame to store results\n",
        "    results = pd.DataFrame(index=X_train_inter.columns)\n",
        "    results['Coefficient'] = coef\n",
        "    results['Standard Error'] = coef_std_err\n",
        "\n",
        "    # Calculate p-values using statsmodels Logit\n",
        "    X_train_inter_sm = sm.add_constant(X_train_inter)\n",
        "    logit_model = sm.Logit(y_train, X_train_inter_sm)\n",
        "    result = logit_model.fit(disp=0)\n",
        "    p_values = result.pvalues.drop('const')\n",
        "\n",
        "    # Add p-values to the results DataFrame\n",
        "    results['P-value'] = p_values\n",
        "\n",
        "    # Print formatted table\n",
        "    print(\"Results:\")\n",
        "    print(results.to_string(formatters={'Coefficient': '{:.4f}'.format,\n",
        "                                         'Standard Error': '{:.4f}'.format,\n",
        "                                         'P-value': '{:.4f}'.format}))\n",
        "\n",
        "    # Predict probabilities on the test set\n",
        "    y_pred_prob = model_ate.predict_proba(X_test_inter)[:, 1]\n",
        "\n",
        "    # Calculate AUC\n",
        "    auc = roc_auc_score(y_test, y_pred_prob)\n",
        "    print(f'AUC: {auc}')\n",
        "\n",
        "    return model_ate\n",
        "\n",
        "# Example usage:\n",
        "model_ate_lasso_cv = ATE_est_reg_interaction_lasso_cv(X_train, X_test, y_train, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGIwp3uFYsQI"
      },
      "source": [
        "####Method 3.IPWE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2UsSatBHROoC"
      },
      "outputs": [],
      "source": [
        "#propensity method\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Assuming df1_no_na is your DataFrame\n",
        "\n",
        "# Define treatment and covariates\n",
        "X = df1_no_na[['BMI_above_30','exercise', 'unhealthy_condition', 'ALQ121', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'SLD012','BPXPULS','Sys_AVEBP','smoker_con']]\n",
        "y = df1_no_na['DIQ010']\n",
        "\n",
        "# Step 1: Estimate Propensity Scores\n",
        "# Separate the treatment variable and the covariates\n",
        "treatment = X['BMI_above_30']\n",
        "covariates = X.drop(columns=['BMI_above_30'])\n",
        "\n",
        "# Fit a logistic regression model to estimate propensity scores\n",
        "log_reg = LogisticRegression(solver='liblinear')\n",
        "log_reg.fit(covariates, treatment)\n",
        "propensity_scores = log_reg.predict_proba(covariates)[:, 1]\n",
        "\n",
        "# Step 2: Calculate Weights\n",
        "weights_treatment = 1 / propensity_scores\n",
        "weights_control = 1 / (1 - propensity_scores)\n",
        "\n",
        "# Step 3: Estimate ATE using the average of weighted outcomes method\n",
        "# Filter the weights to match the corresponding treatment and control groups\n",
        "weights_treatment_filtered = weights_treatment[treatment == 1]\n",
        "weights_control_filtered = weights_control[treatment == 0]\n",
        "\n",
        "# Weighted outcomes for treatment and control groups\n",
        "weighted_outcome_treatment = np.sum(weights_treatment_filtered * y[treatment == 1]) / np.sum(weights_treatment_filtered)\n",
        "weighted_outcome_control = np.sum(weights_control_filtered * y[treatment == 0]) / np.sum(weights_control_filtered)\n",
        "\n",
        "# Calculate ATE\n",
        "ate = weighted_outcome_treatment - weighted_outcome_control\n",
        "\n",
        "# Calculate standard errors\n",
        "# Compute the weighted residuals\n",
        "residuals_treatment = weights_treatment_filtered * (y[treatment == 1] - weighted_outcome_treatment)\n",
        "residuals_control = weights_control_filtered * (y[treatment == 0] - weighted_outcome_control)\n",
        "\n",
        "# Variance of ATE\n",
        "variance_ate = (np.sum(residuals_treatment ** 2) / (np.sum(weights_treatment_filtered) ** 2)) + (np.sum(residuals_control ** 2) / (np.sum(weights_control_filtered) ** 2))\n",
        "\n",
        "# Standard error of ATE\n",
        "ate_se = np.sqrt(variance_ate)\n",
        "\n",
        "print(f\"The estimated Average Treatment Effect (ATE) is: {ate}\")\n",
        "print(f\"The standard error of the ATE estimate is: {ate_se}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZTvQ5lLCdDSz"
      },
      "outputs": [],
      "source": [
        "#Check Overlap Assumption and Covariate Balance\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Add the propensity scores to the original DataFrame\n",
        "df1_no_na['propensity_score'] = propensity_scores\n",
        "df1_no_na['weights'] = np.where(df1_no_na['BMI_above_30'] == 1, weights_treatment, weights_control)\n",
        "\n",
        "# Plot the distribution of propensity scores\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df1_no_na[df1_no_na['BMI_above_30'] == 1]['propensity_score'], label='Treated', color='blue', kde=True, stat=\"density\", bins=25)\n",
        "sns.histplot(df1_no_na[df1_no_na['BMI_above_30'] == 0]['propensity_score'], label='Control', color='red', kde=True, stat=\"density\", bins=25)\n",
        "plt.xlabel('Propensity Score')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Distribution of Propensity Scores')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Function to calculate standardized mean difference\n",
        "def standardized_mean_difference(group1, group2):\n",
        "    mean_diff = np.mean(group1) - np.mean(group2)\n",
        "    pooled_std = np.sqrt((np.std(group1)**2 + np.std(group2)**2) / 2)\n",
        "    return mean_diff / pooled_std\n",
        "\n",
        "# Check covariate balance before and after weighting\n",
        "covariate_columns = covariates.columns\n",
        "balance_data = []\n",
        "\n",
        "for covariate in covariate_columns:\n",
        "    treated_group = df1_no_na[df1_no_na['BMI_above_30'] == 1][covariate]\n",
        "    control_group = df1_no_na[df1_no_na['BMI_above_30'] == 0][covariate]\n",
        "\n",
        "    # Calculate means before weighting\n",
        "    mean_treated_before = np.mean(treated_group)\n",
        "    mean_control_before = np.mean(control_group)\n",
        "\n",
        "    # Calculate SMD before weighting\n",
        "    smd_before = standardized_mean_difference(treated_group, control_group)\n",
        "\n",
        "    # Calculate t-test before weighting\n",
        "    t_stat_before, p_val_before = ttest_ind(treated_group, control_group)\n",
        "\n",
        "    # Calculate means after weighting\n",
        "    mean_treated_after = np.average(df1_no_na[df1_no_na['BMI_above_30'] == 1][covariate], weights=df1_no_na[df1_no_na['BMI_above_30'] == 1]['weights'])\n",
        "    mean_control_after = np.average(df1_no_na[df1_no_na['BMI_above_30'] == 0][covariate], weights=df1_no_na[df1_no_na['BMI_above_30'] == 0]['weights'])\n",
        "\n",
        "    # Calculate SMD after weighting\n",
        "    smd_after = standardized_mean_difference(\n",
        "        df1_no_na[df1_no_na['BMI_above_30'] == 1][covariate] * df1_no_na[df1_no_na['BMI_above_30'] == 1]['weights'],\n",
        "        df1_no_na[df1_no_na['BMI_above_30'] == 0][covariate] * df1_no_na[df1_no_na['BMI_above_30'] == 0]['weights']\n",
        "    )\n",
        "\n",
        "    # Calculate t-test after weighting\n",
        "    t_stat_after, p_val_after = ttest_ind(\n",
        "        df1_no_na[df1_no_na['BMI_above_30'] == 1][covariate] * df1_no_na[df1_no_na['BMI_above_30'] == 1]['weights'],\n",
        "        df1_no_na[df1_no_na['BMI_above_30'] == 0][covariate] * df1_no_na[df1_no_na['BMI_above_30'] == 0]['weights']\n",
        "    )\n",
        "\n",
        "    # Append to balance data\n",
        "    balance_data.append({\n",
        "        'Covariate': covariate,\n",
        "        'Mean_Treated': mean_treated_before,\n",
        "        'Mean_Control': mean_control_before,\n",
        "        'SMD_Before': smd_before,\n",
        "        'SMD_After': smd_after,\n",
        "        'p-value_Before': p_val_before,\n",
        "        'p-value_After': p_val_after\n",
        "    })\n",
        "\n",
        "balance_table = pd.DataFrame(balance_data)\n",
        "\n",
        "print(balance_table)\n",
        "\n",
        "print(df1_no_na.sort_values(by='propensity_score', ascending=True))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGIemr-mSPKo"
      },
      "source": [
        "####Method 4.AIPWE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2UF9oESeR66v"
      },
      "outputs": [],
      "source": [
        "#OLS\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Assuming df1_no_na is your DataFrame\n",
        "\n",
        "# Define treatment and covariates\n",
        "X = df1_no_na[['BMI_above_30','exercise', 'unhealthy_condition', 'ALQ121', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'SLD012','BPXPULS','Sys_AVEBP','smoker_con']]\n",
        "y = df1_no_na['DIQ010']\n",
        "\n",
        "# Step 1: Estimate Propensity Scores\n",
        "# Separate the treatment variable and the covariates\n",
        "treatment = X['BMI_above_30']\n",
        "covariates = X.drop(columns=['BMI_above_30'])\n",
        "\n",
        "# Fit a logistic regression model to estimate propensity scores\n",
        "log_reg = LogisticRegression(solver='liblinear')\n",
        "log_reg.fit(covariates, treatment)\n",
        "propensity_scores = log_reg.predict_proba(covariates)[:, 1]\n",
        "\n",
        "# Step 2: Calculate Weights\n",
        "weights_treatment = 1 / propensity_scores\n",
        "weights_control = 1 / (1 - propensity_scores)\n",
        "\n",
        "# Filter the weights to match the corresponding treatment and control groups\n",
        "weights_treatment_filtered = weights_treatment[treatment == 1]\n",
        "weights_control_filtered = weights_control[treatment == 0]\n",
        "\n",
        "# Step 3: Estimate ATE using the average of weighted outcomes method\n",
        "# Weighted outcomes for treatment and control groups\n",
        "weighted_outcome_treatment = np.sum(weights_treatment_filtered * y[treatment == 1]) / np.sum(weights_treatment_filtered)\n",
        "weighted_outcome_control = np.sum(weights_control_filtered * y[treatment == 0]) / np.sum(weights_control_filtered)\n",
        "\n",
        "# Calculate ATE\n",
        "ate_ipw = weighted_outcome_treatment - weighted_outcome_control\n",
        "\n",
        "# Calculate standard errors for IPW\n",
        "# Compute the weighted residuals\n",
        "residuals_treatment = weights_treatment_filtered * (y[treatment == 1] - weighted_outcome_treatment)\n",
        "residuals_control = weights_control_filtered * (y[treatment == 0] - weighted_outcome_control)\n",
        "\n",
        "# Variance of ATE\n",
        "variance_ate_ipw = (np.sum(residuals_treatment ** 2) / (np.sum(weights_treatment_filtered) ** 2)) + (np.sum(residuals_control ** 2) / (np.sum(weights_control_filtered) ** 2))\n",
        "\n",
        "# Standard error of ATE\n",
        "ate_ipw_se = np.sqrt(variance_ate_ipw)\n",
        "\n",
        "# Step 4: Doubly Robust Estimation\n",
        "# Fit outcome regression models\n",
        "outcome_model_treated = LinearRegression().fit(covariates[treatment == 1], y[treatment == 1])\n",
        "outcome_model_control = LinearRegression().fit(covariates[treatment == 0], y[treatment == 0])\n",
        "\n",
        "# Predict outcomes\n",
        "y_hat_treated = outcome_model_treated.predict(covariates)\n",
        "y_hat_control = outcome_model_control.predict(covariates)\n",
        "\n",
        "# Calculate the doubly robust estimates\n",
        "dr_estimate_treated = y_hat_treated + (treatment / propensity_scores) * (y - y_hat_treated)\n",
        "dr_estimate_control = y_hat_control + ((1 - treatment) / (1 - propensity_scores)) * (y - y_hat_control)\n",
        "\n",
        "# Calculate ATE using doubly robust estimates\n",
        "ate_dr = np.mean(dr_estimate_treated - dr_estimate_control)\n",
        "\n",
        "# Calculate standard errors for DR\n",
        "# Residuals for DR\n",
        "residuals_dr_treated = (treatment / propensity_scores) * (y - y_hat_treated)\n",
        "residuals_dr_control = ((1 - treatment) / (1 - propensity_scores)) * (y - y_hat_control)\n",
        "\n",
        "# Variance of ATE for DR\n",
        "variance_ate_dr = np.var(dr_estimate_treated - dr_estimate_control) / len(y)\n",
        "\n",
        "# Standard error of ATE for DR\n",
        "ate_dr_se = np.sqrt(variance_ate_dr)\n",
        "\n",
        "print(f\"The estimated Average Treatment Effect (ATE) using IPW is: {ate_ipw}\")\n",
        "print(f\"The standard error of the ATE estimate using IPW is: {ate_ipw_se}\")\n",
        "print(f\"The estimated Average Treatment Effect (ATE) using Doubly Robust method is: {ate_dr}\")\n",
        "print(f\"The standard error of the ATE estimate using Doubly Robust method is: {ate_dr_se}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hyrdQTcXXuD0"
      },
      "outputs": [],
      "source": [
        "#GradientBoosting\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# Assuming df1_no_na is your DataFrame\n",
        "\n",
        "# Define treatment and covariates\n",
        "X = df1_no_na[['BMI_above_30','exercise', 'unhealthy_condition', 'ALQ121', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'SLD012','BPXPULS','Sys_AVEBP','smoker_con']]\n",
        "y = df1_no_na['DIQ010']\n",
        "\n",
        "# Step 1: Estimate Propensity Scores\n",
        "# Separate the treatment variable and the covariates\n",
        "treatment = X['BMI_above_30']\n",
        "covariates = X.drop(columns=['BMI_above_30'])\n",
        "\n",
        "# Fit a logistic regression model to estimate propensity scores\n",
        "log_reg = LogisticRegression(solver='liblinear')\n",
        "log_reg.fit(covariates, treatment)\n",
        "propensity_scores = log_reg.predict_proba(covariates)[:, 1]\n",
        "\n",
        "# Step 2: Calculate Weights\n",
        "weights_treatment = 1 / propensity_scores\n",
        "weights_control = 1 / (1 - propensity_scores)\n",
        "\n",
        "# Filter the weights to match the corresponding treatment and control groups\n",
        "weights_treatment_filtered = weights_treatment[treatment == 1]\n",
        "weights_control_filtered = weights_control[treatment == 0]\n",
        "\n",
        "# Step 3: Estimate ATE using the average of weighted outcomes method\n",
        "# Weighted outcomes for treatment and control groups\n",
        "weighted_outcome_treatment = np.sum(weights_treatment_filtered * y[treatment == 1]) / np.sum(weights_treatment_filtered)\n",
        "weighted_outcome_control = np.sum(weights_control_filtered * y[treatment == 0]) / np.sum(weights_control_filtered)\n",
        "\n",
        "# Calculate ATE\n",
        "ate_ipw = weighted_outcome_treatment - weighted_outcome_control\n",
        "\n",
        "# Calculate standard errors for IPW\n",
        "# Compute the weighted residuals\n",
        "residuals_treatment = weights_treatment_filtered * (y[treatment == 1] - weighted_outcome_treatment)\n",
        "residuals_control = weights_control_filtered * (y[treatment == 0] - weighted_outcome_control)\n",
        "\n",
        "# Variance of ATE\n",
        "variance_ate_ipw = (np.sum(residuals_treatment ** 2) / (np.sum(weights_treatment_filtered) ** 2)) + (np.sum(residuals_control ** 2) / (np.sum(weights_control_filtered) ** 2))\n",
        "\n",
        "# Standard error of ATE\n",
        "ate_ipw_se = np.sqrt(variance_ate_ipw)\n",
        "\n",
        "# Step 4: Doubly Robust Estimation\n",
        "# Fit outcome regression models using Gradient Boosting Regressor\n",
        "outcome_model_treated = GradientBoostingRegressor().fit(covariates[treatment == 1], y[treatment == 1])\n",
        "outcome_model_control = GradientBoostingRegressor().fit(covariates[treatment == 0], y[treatment == 0])\n",
        "\n",
        "# Predict outcomes\n",
        "y_hat_treated = outcome_model_treated.predict(covariates)\n",
        "y_hat_control = outcome_model_control.predict(covariates)\n",
        "\n",
        "# Calculate the doubly robust estimates\n",
        "dr_estimate_treated = y_hat_treated + (treatment / propensity_scores) * (y - y_hat_treated)\n",
        "dr_estimate_control = y_hat_control + ((1 - treatment) / (1 - propensity_scores)) * (y - y_hat_control)\n",
        "\n",
        "# Calculate ATE using doubly robust estimates\n",
        "ate_dr = np.mean(dr_estimate_treated - dr_estimate_control)\n",
        "\n",
        "# Calculate standard errors for DR\n",
        "# Residuals for DR\n",
        "residuals_dr_treated = (treatment / propensity_scores) * (y - y_hat_treated)\n",
        "residuals_dr_control = ((1 - treatment) / (1 - propensity_scores)) * (y - y_hat_control)\n",
        "\n",
        "# Variance of ATE for DR\n",
        "variance_ate_dr = np.var(dr_estimate_treated - dr_estimate_control) / len(y)\n",
        "\n",
        "# Standard error of ATE for DR\n",
        "ate_dr_se = np.sqrt(variance_ate_dr)\n",
        "\n",
        "print(f\"The estimated Average Treatment Effect (ATE) using IPW is: {ate_ipw}\")\n",
        "print(f\"The standard error of the ATE estimate using IPW is: {ate_ipw_se}\")\n",
        "print(f\"The estimated Average Treatment Effect (ATE) using Doubly Robust method is: {ate_dr}\")\n",
        "print(f\"The standard error of the ATE estimate using Doubly Robust method is: {ate_dr_se}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkuM0Q2SX5jA"
      },
      "source": [
        "####Method 5.Double Robust PLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kjve8mMCYAYZ"
      },
      "outputs": [],
      "source": [
        "#Random Forest\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Assuming df1_no_na is your DataFrame\n",
        "\n",
        "# Define treatment and covariates\n",
        "X = df1_no_na[['BMI_above_30', 'exercise', 'unhealthy_condition', 'ALQ121', 'INDFMIN2', 'RIAGENDR', 'RIDAGEYR_fixed', 'SLD012', 'BPXPULS', 'Sys_AVEBP', 'smoker_con']]\n",
        "y = df1_no_na['DIQ010']\n",
        "\n",
        "# Step 1: Estimate Propensity Scores\n",
        "# Separate the treatment variable and the covariates\n",
        "treatment = X['BMI_above_30']\n",
        "covariates = X.drop(columns=['BMI_above_30'])\n",
        "\n",
        "# Fit a logistic regression model to estimate propensity scores\n",
        "log_reg = LogisticRegression(solver='liblinear')\n",
        "log_reg.fit(covariates, treatment)\n",
        "propensity_scores = log_reg.predict_proba(covariates)[:, 1]\n",
        "\n",
        "# Step 2: Outcome Regression using Random Forest Regressor\n",
        "# Fit outcome regression models using Random Forest Regressor\n",
        "outcome_model_treated = RandomForestRegressor().fit(covariates[treatment == 1], y[treatment == 1])\n",
        "outcome_model_control = RandomForestRegressor().fit(covariates[treatment == 0], y[treatment == 0])\n",
        "\n",
        "# Predict outcomes\n",
        "y_hat_treated = outcome_model_treated.predict(covariates)\n",
        "y_hat_control = outcome_model_control.predict(covariates)\n",
        "\n",
        "# Calculate the doubly robust estimates\n",
        "dr_estimate_treated = y_hat_treated + (treatment / propensity_scores) * (y - y_hat_treated)\n",
        "dr_estimate_control = y_hat_control + ((1 - treatment) / (1 - propensity_scores)) * (y - y_hat_control)\n",
        "\n",
        "# Calculate ATE using doubly robust Random Forest estimates\n",
        "ate_dr_rf = np.mean(dr_estimate_treated - dr_estimate_control)\n",
        "\n",
        "# Calculate standard errors for DR Random Forest\n",
        "# Residuals for DR Random Forest\n",
        "residuals_dr_treated = (treatment / propensity_scores) * (y - y_hat_treated)\n",
        "residuals_dr_control = ((1 - treatment) / (1 - propensity_scores)) * (y - y_hat_control)\n",
        "\n",
        "# Variance of ATE for DR Random Forest\n",
        "variance_ate_dr_rf = np.var(dr_estimate_treated - dr_estimate_control) / len(y)\n",
        "\n",
        "# Standard error of ATE for DR Random Forest\n",
        "ate_dr_rf_se = np.sqrt(variance_ate_dr_rf)\n",
        "\n",
        "print(f\"The estimated Average Treatment Effect (ATE) using Doubly Robust Random Forest method is: {ate_dr_rf}\")\n",
        "print(f\"The standard error of the ATE estimate using Doubly Robust Random Forest method is: {ate_dr_rf_se}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36meOApPS2OG"
      },
      "source": [
        "## Topic 2. Hypertension\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzJOmYD82QBM"
      },
      "source": [
        "###Hypothesis 1 LBDHDD ~ 'BMI_above_30'\n",
        "\n",
        "LBDHDD ~ 'BMI_above_30', 'unhealthy_condition', 'ALQ121', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'SLD012','BPXPULS','Sys_AVEBP', 'exercise', 'WH_ratio','smoker_con'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNo-IeYe2pHg"
      },
      "source": [
        "####Method 1.Regression-based w/o interactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5fg5AUv4NZV",
        "outputId": "e10edfb0-2f86-492c-883b-bdaf1d3e02eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of observations in training dataset: 2695\n",
            "Number of observations in test dataset: 674\n",
            "Total number of observations: 3369\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                 LBDHDD   R-squared:                       0.268\n",
            "Model:                            OLS   Adj. R-squared:                  0.265\n",
            "Method:                 Least Squares   F-statistic:                     88.48\n",
            "Date:                Mon, 08 Jul 2024   Prob (F-statistic):          3.91e-184\n",
            "Time:                        02:56:49   Log-Likelihood:                -10802.\n",
            "No. Observations:                2695   AIC:                         2.163e+04\n",
            "Df Residuals:                    2682   BIC:                         2.171e+04\n",
            "Df Model:                          12                                         \n",
            "Covariance Type:                  HC1                                         \n",
            "=======================================================================================\n",
            "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
            "---------------------------------------------------------------------------------------\n",
            "const                  89.8413      4.416     20.343      0.000      81.185      98.497\n",
            "BMI_above_30           -4.6324      0.582     -7.956      0.000      -5.774      -3.491\n",
            "unhealthy_condition    -0.1771      1.117     -0.158      0.874      -2.367       2.013\n",
            "ALQ121                  8.9487      0.980      9.134      0.000       7.028      10.869\n",
            "INDFMIN2                0.0424      0.059      0.721      0.471      -0.073       0.158\n",
            "RIAGENDR                3.6002      0.316     11.396      0.000       2.981       4.219\n",
            "RIDAGEYR_fixed          0.1548      0.017      9.343      0.000       0.122       0.187\n",
            "SLD012                  0.0636      0.174      0.365      0.715      -0.278       0.405\n",
            "BPXPULS                 1.3362      1.524      0.877      0.381      -1.651       4.324\n",
            "Sys_AVEBP               0.0199      0.016      1.235      0.217      -0.012       0.052\n",
            "exercise                1.3803      0.529      2.611      0.009       0.344       2.416\n",
            "WH_ratio              -54.1234      4.226    -12.808      0.000     -62.405     -45.841\n",
            "smoker_con             -0.5349      0.640     -0.836      0.403      -1.790       0.720\n",
            "==============================================================================\n",
            "Omnibus:                      699.195   Durbin-Watson:                   1.982\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3191.390\n",
            "Skew:                           1.175   Prob(JB):                         0.00\n",
            "Kurtosis:                       7.785   Cond. No.                     3.18e+03\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors are heteroscedasticity robust (HC1)\n",
            "[2] The condition number is large, 3.18e+03. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n",
            "R-squared: 0.225344286449096, MSE: 185.88922774937632\n"
          ]
        }
      ],
      "source": [
        "##OLS\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "# Assuming df1 is already defined and cleaned\n",
        "df1_no_na = df1[['LBDHDD', 'BMI_above_30', 'unhealthy_condition', 'ALQ121', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'SLD012','BPXPULS','Sys_AVEBP', 'exercise', 'WH_ratio','smoker_con']].dropna()\n",
        "\n",
        "X = df1_no_na[['BMI_above_30', 'unhealthy_condition', 'ALQ121', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'SLD012','BPXPULS','Sys_AVEBP', 'exercise', 'WH_ratio','smoker_con']]\n",
        "y = df1_no_na['LBDHDD']\n",
        "x_categorical_name_list = []\n",
        "X = pd.get_dummies(X, columns=x_categorical_name_list, drop_first=True)\n",
        "transformed_columns = [col for col in X.columns if any(prefix in col for prefix in x_categorical_name_list)]\n",
        "X[transformed_columns] = X[transformed_columns].astype(int)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=66)\n",
        "\n",
        "# Calculate the number of observations in training and test datasets\n",
        "num_train_obs = len(X_train)\n",
        "num_test_obs = len(X_test)\n",
        "total_obs = num_train_obs + num_test_obs\n",
        "\n",
        "print(f'Number of observations in training dataset: {num_train_obs}')\n",
        "print(f'Number of observations in test dataset: {num_test_obs}')\n",
        "print(f'Total number of observations: {total_obs}')\n",
        "\n",
        "def ATE_est_reg(X_train, X_test, y_train, y_test):\n",
        "    X_train = sm.add_constant(X_train)\n",
        "    X_test = sm.add_constant(X_test)\n",
        "\n",
        "    model_ate = sm.OLS(y_train, X_train).fit(cov_type='HC1')  # Fit OLS model\n",
        "    ate_summary = model_ate.summary()\n",
        "    print(ate_summary)\n",
        "\n",
        "    # Predict probabilities on the test set\n",
        "    y_pred = model_ate.predict(X_test)\n",
        "\n",
        "    # Calculate R-squared and MSE\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f'R-squared: {r2}, MSE: {mse}')\n",
        "    return\n",
        "\n",
        "ATE_est_reg(X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlP-0ivP4YlP",
        "outputId": "5881e930-52e1-4c0c-c534-48c31e0c370f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Feature  Mean Coefficient  Standard Error    Z-Score  \\\n",
            "0          BMI_above_30         -4.085781        0.544460  -7.504283   \n",
            "1   unhealthy_condition          0.000000        0.000000        NaN   \n",
            "2                ALQ121          0.459034        0.679475   0.675571   \n",
            "3              INDFMIN2          0.089334        0.057099   1.564533   \n",
            "4              RIAGENDR          4.145636        0.272856  15.193467   \n",
            "5        RIDAGEYR_fixed          0.076568        0.015072   5.080044   \n",
            "6                SLD012          0.009570        0.036235   0.264111   \n",
            "7               BPXPULS          0.000000        0.000000        NaN   \n",
            "8             Sys_AVEBP         -0.006684        0.014901  -0.448574   \n",
            "9              exercise          0.000148        0.004686   0.031639   \n",
            "10             WH_ratio          0.000000        0.000000        NaN   \n",
            "11           smoker_con          0.000000        0.000000        NaN   \n",
            "\n",
            "         P-Value  Significant  \n",
            "0   6.176578e-14         True  \n",
            "1            NaN        False  \n",
            "2   4.993130e-01        False  \n",
            "3   1.176925e-01        False  \n",
            "4   3.906963e-52         True  \n",
            "5   3.773471e-07         True  \n",
            "6   7.916941e-01        False  \n",
            "7            NaN        False  \n",
            "8   6.537393e-01        False  \n",
            "9   9.747603e-01        False  \n",
            "10           NaN        False  \n",
            "11           NaN        False  \n",
            "R-squared: 0.13759793920362473, MSE: 206.9451632339565\n"
          ]
        }
      ],
      "source": [
        "##Lasso\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.utils import resample\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Assuming df1 is your dataframe\n",
        "df1_no_na = df1[['LBDHDD', 'BMI_above_30', 'unhealthy_condition', 'ALQ121', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'SLD012','BPXPULS','Sys_AVEBP', 'exercise', 'WH_ratio','smoker_con']].dropna()\n",
        "\n",
        "X = df1_no_na[['BMI_above_30', 'unhealthy_condition', 'ALQ121', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'SLD012','BPXPULS','Sys_AVEBP', 'exercise', 'WH_ratio','smoker_con']]\n",
        "y = df1_no_na['LBDHDD']\n",
        "x_categorical_name_list = []\n",
        "X = pd.get_dummies(X, columns=x_categorical_name_list, drop_first=True)\n",
        "transformed_columns = [col for col in X.columns if any(prefix in col for prefix in x_categorical_name_list)]\n",
        "X[transformed_columns] = X[transformed_columns].astype(int)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=66)\n",
        "\n",
        "def bootstrap_lasso(X_train, y_train, n_iterations=1000, alpha=1.0):\n",
        "    coefficients = np.zeros((n_iterations, X_train.shape[1]))\n",
        "\n",
        "    for i in range(n_iterations):\n",
        "        # Bootstrap sample\n",
        "        X_resampled, y_resampled = resample(X_train, y_train, random_state=i)\n",
        "\n",
        "        model_lasso = Lasso(alpha=alpha, random_state=66)\n",
        "        model_lasso.fit(X_resampled, y_resampled)\n",
        "\n",
        "        # Store coefficients\n",
        "        coefficients[i, :] = model_lasso.coef_\n",
        "\n",
        "    # Calculate mean and standard error of coefficients\n",
        "    mean_coefficients = np.mean(coefficients, axis=0)\n",
        "    std_coefficients = np.std(coefficients, axis=0)\n",
        "\n",
        "    return mean_coefficients, std_coefficients\n",
        "\n",
        "mean_coefficients, std_coefficients = bootstrap_lasso(X_train, y_train)\n",
        "\n",
        "# Create a summary table\n",
        "summary_table = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Mean Coefficient': mean_coefficients,\n",
        "    'Standard Error': std_coefficients\n",
        "})\n",
        "\n",
        "# Calculate z-scores and p-values\n",
        "summary_table['Z-Score'] = summary_table['Mean Coefficient'] / summary_table['Standard Error']\n",
        "summary_table['P-Value'] = norm.sf(abs(summary_table['Z-Score'])) * 2  # Two-tailed test\n",
        "\n",
        "# Mark significant features\n",
        "alpha = 0.05  # Significance level\n",
        "summary_table['Significant'] = summary_table['P-Value'] < alpha\n",
        "\n",
        "print(summary_table)\n",
        "\n",
        "# Fit final model and evaluate\n",
        "model_lasso = Lasso(alpha=1.0, random_state=66)\n",
        "model_lasso.fit(X_train, y_train)\n",
        "y_pred = model_lasso.predict(X_test)\n",
        "\n",
        "# Calculate R-squared and MSE\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'R-squared: {r2}, MSE: {mse}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c80dKs254eZ0",
        "outputId": "bc2a821f-fe6f-4b3d-b5eb-a6ac6291035f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R-squared: 0.21585690260180068, MSE: 188.16585519287833\n",
            "BMI_above_30: 0.04683387089244997\n",
            "unhealthy_condition: 0.013052845360605464\n",
            "ALQ121: 0.04512761560097355\n",
            "INDFMIN2: 0.08502083470130889\n",
            "RIAGENDR: 0.07425331717145878\n",
            "RIDAGEYR_fixed: 0.15563438907095203\n",
            "SLD012: 0.10877742169065394\n",
            "BPXPULS: 0.008612495760827649\n",
            "Sys_AVEBP: 0.14954264485092608\n",
            "exercise: 0.019388341115730446\n",
            "WH_ratio: 0.2716627708311699\n",
            "smoker_con: 0.022093452952943418\n"
          ]
        }
      ],
      "source": [
        "##Random Forest\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "# Assuming df1 is your dataframe\n",
        "df1_no_na = df1[['LBDHDD', 'BMI_above_30', 'unhealthy_condition', 'ALQ121', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'SLD012','BPXPULS','Sys_AVEBP', 'exercise', 'WH_ratio','smoker_con']].dropna()\n",
        "\n",
        "X = df1_no_na[['BMI_above_30', 'unhealthy_condition', 'ALQ121', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'SLD012','BPXPULS','Sys_AVEBP', 'exercise', 'WH_ratio','smoker_con']]\n",
        "y = df1_no_na['LBDHDD']\n",
        "x_categorical_name_list = []\n",
        "X = pd.get_dummies(X, columns=x_categorical_name_list, drop_first=True)\n",
        "transformed_columns = [col for col in X.columns if any(prefix in col for prefix in x_categorical_name_list)]\n",
        "X[transformed_columns] = X[transformed_columns].astype(int)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=66)\n",
        "\n",
        "def ATE_est_rf(X_train, X_test, y_train, y_test):\n",
        "    model_rf = RandomForestRegressor(n_estimators=100, random_state=66)\n",
        "    model_rf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = model_rf.predict(X_test)\n",
        "\n",
        "    # Calculate R-squared and MSE\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f'R-squared: {r2}, MSE: {mse}')\n",
        "\n",
        "    # Feature importance\n",
        "    feature_importances = model_rf.feature_importances_\n",
        "    for feature, importance in zip(X_train.columns, feature_importances):\n",
        "        print(f'{feature}: {importance}')\n",
        "\n",
        "    return\n",
        "\n",
        "ATE_est_rf(X_train, X_test, y_train, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxxIbUOV4jP3",
        "outputId": "9e1bb210-63fb-46c3-d552-a59def67e9b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R-squared: 0.22412618215024127, MSE: 186.18152852696224\n",
            "BMI_above_30: 0.10232193535648453\n",
            "unhealthy_condition: 0.00436900416333798\n",
            "ALQ121: 0.10613257718476135\n",
            "INDFMIN2: 0.024819286535453573\n",
            "RIAGENDR: 0.1539211822652936\n",
            "RIDAGEYR_fixed: 0.13343311437852243\n",
            "SLD012: 0.06128470359497054\n",
            "BPXPULS: 0.0011117492584692998\n",
            "Sys_AVEBP: 0.07272005681931058\n",
            "exercise: 0.003937923317167971\n",
            "WH_ratio: 0.32411925454313134\n",
            "smoker_con: 0.011829212583096856\n"
          ]
        }
      ],
      "source": [
        "##Gradient Boosting\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "# Assuming df1 is your dataframe\n",
        "df1_no_na = df1[['LBDHDD', 'BMI_above_30', 'unhealthy_condition', 'ALQ121', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'SLD012','BPXPULS','Sys_AVEBP', 'exercise', 'WH_ratio','smoker_con']].dropna()\n",
        "\n",
        "X = df1_no_na[['BMI_above_30', 'unhealthy_condition', 'ALQ121', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'SLD012','BPXPULS','Sys_AVEBP', 'exercise', 'WH_ratio','smoker_con']]\n",
        "y = df1_no_na['LBDHDD']\n",
        "x_categorical_name_list = []\n",
        "X = pd.get_dummies(X, columns=x_categorical_name_list, drop_first=True)\n",
        "transformed_columns = [col for col in X.columns if any(prefix in col for prefix in x_categorical_name_list)]\n",
        "X[transformed_columns] = X[transformed_columns].astype(int)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=66)\n",
        "\n",
        "def ATE_est_gb(X_train, X_test, y_train, y_test):\n",
        "    model_gb = GradientBoostingRegressor(n_estimators=100, random_state=66)\n",
        "    model_gb.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = model_gb.predict(X_test)\n",
        "\n",
        "    # Calculate R-squared and MSE\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f'R-squared: {r2}, MSE: {mse}')\n",
        "\n",
        "    # Feature importance\n",
        "    feature_importances = model_gb.feature_importances_\n",
        "    for feature, importance in zip(X_train.columns, feature_importances):\n",
        "        print(f'{feature}: {importance}')\n",
        "\n",
        "    return\n",
        "\n",
        "ATE_est_gb(X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRoqojBF4mdj",
        "outputId": "fe7fd948-6907-4e20-a134-90aecc7655fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R-squared: 0.14039846368042497, MSE: 206.2731391035214\n"
          ]
        }
      ],
      "source": [
        "##ANN\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "# Assuming df1 is your dataframe\n",
        "df1_no_na = df1[['LBDHDD', 'BMI_above_30', 'unhealthy_condition', 'ALQ121', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'SLD012','BPXPULS','Sys_AVEBP', 'exercise', 'WH_ratio','smoker_con']].dropna()\n",
        "\n",
        "X = df1_no_na[['BMI_above_30', 'unhealthy_condition', 'ALQ121', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'SLD012','BPXPULS','Sys_AVEBP', 'exercise', 'WH_ratio','smoker_con']]\n",
        "y = df1_no_na['LBDHDD']\n",
        "x_categorical_name_list = []\n",
        "X = pd.get_dummies(X, columns=x_categorical_name_list, drop_first=True)\n",
        "transformed_columns = [col for col in X.columns if any(prefix in col for prefix in x_categorical_name_list)]\n",
        "X[transformed_columns] = X[transformed_columns].astype(int)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=66)\n",
        "\n",
        "def ATE_est_nn(X_train, X_test, y_train, y_test):\n",
        "    model_nn = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=66)\n",
        "    model_nn.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = model_nn.predict(X_test)\n",
        "\n",
        "    # Calculate R-squared and MSE\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f'R-squared: {r2}, MSE: {mse}')\n",
        "\n",
        "    return\n",
        "\n",
        "ATE_est_nn(X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvbJgsco5Pm-"
      },
      "source": [
        "####Method 2.Regression-based w/ interactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHv3B7XkW5j2",
        "outputId": "65a897f0-30a8-434e-e448-f878b5c1e384"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                 LBDHDD   R-squared:                       0.295\n",
            "Model:                            OLS   Adj. R-squared:                  0.274\n",
            "Method:                 Least Squares   F-statistic:                     16.82\n",
            "Date:                Mon, 08 Jul 2024   Prob (F-statistic):          1.06e-175\n",
            "Time:                        02:57:20   Log-Likelihood:                -10752.\n",
            "No. Observations:                2695   AIC:                         2.166e+04\n",
            "Df Residuals:                    2616   BIC:                         2.213e+04\n",
            "Df Model:                          78                                         \n",
            "Covariance Type:                  HC1                                         \n",
            "======================================================================================================\n",
            "                                         coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------------------------------\n",
            "const                                 54.8327      0.497    110.287      0.000      53.858      55.807\n",
            "BMI_above_30                          -4.8644      0.621     -7.832      0.000      -6.082      -3.647\n",
            "unhealthy_condition                   -1.0324      1.651     -0.625      0.532      -4.267       2.203\n",
            "ALQ121                                 8.9259      1.491      5.986      0.000       6.003      11.848\n",
            "INDFMIN2                              -0.0164      0.085     -0.192      0.848      -0.184       0.151\n",
            "RIAGENDR                               3.6302      0.464      7.820      0.000       2.720       4.540\n",
            "RIDAGEYR_fixed                         0.1830      0.027      6.830      0.000       0.130       0.236\n",
            "SLD012                                 0.4420      0.249      1.773      0.076      -0.047       0.931\n",
            "BPXPULS                               -2.7740      2.978     -0.932      0.352      -8.610       3.062\n",
            "Sys_AVEBP                              0.0380      0.025      1.539      0.124      -0.010       0.086\n",
            "exercise                               1.6080      0.781      2.060      0.039       0.078       3.138\n",
            "WH_ratio                             -65.8874      6.340    -10.392      0.000     -78.314     -53.461\n",
            "smoker_con                            -0.4375      0.993     -0.441      0.659      -2.383       1.508\n",
            "BMI_above_30:unhealthy_condition       1.7182      2.338      0.735      0.462      -2.865       6.301\n",
            "BMI_above_30:ALQ121                   -1.4836      2.777     -0.534      0.593      -6.927       3.960\n",
            "BMI_above_30:INDFMIN2                  0.0498      0.135      0.368      0.713      -0.216       0.315\n",
            "BMI_above_30:RIAGENDR                 -0.0748      0.752     -0.099      0.921      -1.549       1.399\n",
            "BMI_above_30:RIDAGEYR_fixed           -0.0301      0.039     -0.772      0.440      -0.106       0.046\n",
            "BMI_above_30:SLD012                   -0.9520      0.373     -2.555      0.011      -1.682      -0.222\n",
            "BMI_above_30:BPXPULS                   5.0382      4.509      1.117      0.264      -3.800      13.876\n",
            "BMI_above_30:Sys_AVEBP                -0.0455      0.036     -1.275      0.202      -0.115       0.024\n",
            "BMI_above_30:exercise                 -0.2208      1.232     -0.179      0.858      -2.635       2.193\n",
            "BMI_above_30:WH_ratio                 24.8531      8.840      2.811      0.005       7.527      42.179\n",
            "BMI_above_30:smoker_con               -2.6600      1.497     -1.777      0.076      -5.594       0.274\n",
            "unhealthy_condition:ALQ121            -6.8614      5.418     -1.266      0.205     -17.481       3.758\n",
            "unhealthy_condition:INDFMIN2          -0.0744      0.272     -0.274      0.784      -0.607       0.458\n",
            "unhealthy_condition:RIAGENDR          -0.7146      1.332     -0.536      0.592      -3.325       1.896\n",
            "unhealthy_condition:RIDAGEYR_fixed     0.0087      0.066      0.131      0.896      -0.121       0.139\n",
            "unhealthy_condition:SLD012            -0.0348      0.641     -0.054      0.957      -1.290       1.221\n",
            "unhealthy_condition:BPXPULS           -5.0803      5.447     -0.933      0.351     -15.756       5.596\n",
            "unhealthy_condition:Sys_AVEBP          0.0221      0.061      0.364      0.716      -0.097       0.141\n",
            "unhealthy_condition:exercise          -0.2786      2.197     -0.127      0.899      -4.585       4.028\n",
            "unhealthy_condition:WH_ratio          -6.7979     15.931     -0.427      0.670     -38.022      24.426\n",
            "unhealthy_condition:smoker_con        -2.2327      2.657     -0.840      0.401      -7.440       2.974\n",
            "ALQ121:INDFMIN2                        0.3661      0.211      1.739      0.082      -0.047       0.779\n",
            "ALQ121:RIAGENDR                        1.6881      1.450      1.164      0.244      -1.154       4.530\n",
            "ALQ121:RIDAGEYR_fixed                 -0.0643      0.067     -0.954      0.340      -0.197       0.068\n",
            "ALQ121:SLD012                         -0.4051      0.774     -0.523      0.601      -1.923       1.112\n",
            "ALQ121:BPXPULS                         7.3684      4.147      1.777      0.076      -0.760      15.497\n",
            "ALQ121:Sys_AVEBP                       0.0753      0.055      1.360      0.174      -0.033       0.184\n",
            "ALQ121:exercise                        1.9496      2.362      0.825      0.409      -2.679       6.578\n",
            "ALQ121:WH_ratio                        5.2977     16.929      0.313      0.754     -27.882      38.477\n",
            "ALQ121:smoker_con                      2.7115      2.601      1.043      0.297      -2.386       7.809\n",
            "INDFMIN2:RIAGENDR                     -0.0893      0.074     -1.205      0.228      -0.234       0.056\n",
            "INDFMIN2:RIDAGEYR_fixed                0.0019      0.004      0.488      0.626      -0.006       0.009\n",
            "INDFMIN2:SLD012                        0.0198      0.038      0.520      0.603      -0.055       0.094\n",
            "INDFMIN2:BPXPULS                       0.0171      0.416      0.041      0.967      -0.799       0.833\n",
            "INDFMIN2:Sys_AVEBP                    -0.0030      0.004     -0.805      0.421      -0.010       0.004\n",
            "INDFMIN2:exercise                     -0.0419      0.120     -0.349      0.727      -0.277       0.193\n",
            "INDFMIN2:WH_ratio                     -0.7767      1.013     -0.766      0.443      -2.763       1.209\n",
            "INDFMIN2:smoker_con                   -0.4057      0.148     -2.749      0.006      -0.695      -0.116\n",
            "RIAGENDR:RIDAGEYR_fixed                0.0147      0.020      0.732      0.464      -0.025       0.054\n",
            "RIAGENDR:SLD012                        0.2383      0.208      1.143      0.253      -0.170       0.647\n",
            "RIAGENDR:BPXPULS                       0.1922      2.595      0.074      0.941      -4.893       5.278\n",
            "RIAGENDR:Sys_AVEBP                    -0.0253      0.020     -1.254      0.210      -0.065       0.014\n",
            "RIAGENDR:exercise                      0.0063      0.662      0.010      0.992      -1.290       1.303\n",
            "RIAGENDR:WH_ratio                      4.0325      4.470      0.902      0.367      -4.728      12.793\n",
            "RIAGENDR:smoker_con                   -2.1488      0.785     -2.737      0.006      -3.687      -0.610\n",
            "RIDAGEYR_fixed:SLD012                 -0.0008      0.010     -0.083      0.934      -0.021       0.019\n",
            "RIDAGEYR_fixed:BPXPULS                 0.1427      0.092      1.546      0.122      -0.038       0.324\n",
            "RIDAGEYR_fixed:Sys_AVEBP              -0.0016      0.001     -1.516      0.130      -0.004       0.000\n",
            "RIDAGEYR_fixed:exercise               -0.0249      0.034     -0.731      0.465      -0.092       0.042\n",
            "RIDAGEYR_fixed:WH_ratio               -0.4067      0.246     -1.655      0.098      -0.889       0.075\n",
            "RIDAGEYR_fixed:smoker_con             -0.0191      0.041     -0.466      0.641      -0.100       0.061\n",
            "SLD012:BPXPULS                         1.1163      0.881      1.268      0.205      -0.610       2.842\n",
            "SLD012:Sys_AVEBP                      -0.0130      0.010     -1.353      0.176      -0.032       0.006\n",
            "SLD012:exercise                       -0.2134      0.349     -0.612      0.540      -0.897       0.470\n",
            "SLD012:WH_ratio                        3.3153      2.615      1.268      0.205      -1.811       8.441\n",
            "SLD012:smoker_con                      0.4868      0.377      1.293      0.196      -0.251       1.225\n",
            "BPXPULS:Sys_AVEBP                      0.0343      0.088      0.390      0.696      -0.138       0.206\n",
            "BPXPULS:exercise                       2.5628      3.671      0.698      0.485      -4.633       9.759\n",
            "BPXPULS:WH_ratio                      -3.9808     27.052     -0.147      0.883     -57.002      49.041\n",
            "BPXPULS:smoker_con                     3.8707      3.227      1.200      0.230      -2.454      10.195\n",
            "Sys_AVEBP:exercise                    -0.0063      0.033     -0.188      0.851      -0.072       0.059\n",
            "Sys_AVEBP:WH_ratio                     0.1737      0.256      0.679      0.497      -0.328       0.675\n",
            "Sys_AVEBP:smoker_con                   0.0187      0.042      0.442      0.659      -0.064       0.102\n",
            "exercise:WH_ratio                     -6.0938      8.793     -0.693      0.488     -23.328      11.140\n",
            "exercise:smoker_con                   -2.4453      1.326     -1.844      0.065      -5.045       0.154\n",
            "WH_ratio:smoker_con                   -9.4281      9.664     -0.976      0.329     -28.370       9.514\n",
            "==============================================================================\n",
            "Omnibus:                      656.993   Durbin-Watson:                   1.982\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2996.796\n",
            "Skew:                           1.100   Prob(JB):                         0.00\n",
            "Kurtosis:                       7.674   Cond. No.                     3.67e+04\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors are heteroscedasticity robust (HC1)\n",
            "[2] The condition number is large, 3.67e+04. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n",
            "R-squared: 0.23199553003765838, MSE: 184.29317093003988\n"
          ]
        }
      ],
      "source": [
        "#interaction\n",
        "\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from itertools import combinations\n",
        "\n",
        "def ATE_est_reg_interaction(X_train, X_test, y_train, y_test):\n",
        "    # Add constant term to the features\n",
        "    cols_to_subtract_mean = X_train.columns[X_train.columns != 'BMI_above_30']\n",
        "    X_train[cols_to_subtract_mean] = X_train[cols_to_subtract_mean] - X_train[cols_to_subtract_mean].mean()\n",
        "    X_test[cols_to_subtract_mean] = X_test[cols_to_subtract_mean] - X_test[cols_to_subtract_mean].mean()\n",
        "    X_train = sm.add_constant(X_train)\n",
        "    X_test = sm.add_constant(X_test)\n",
        "\n",
        "    # Create pairwise interaction terms for X_train\n",
        "    interaction_terms_train = pd.DataFrame(index=X_train.index)\n",
        "    interaction_terms_test = pd.DataFrame(index=X_test.index)\n",
        "\n",
        "    # Get the list of feature names excluding the constant term\n",
        "    feature_names = X_train.columns[1:]\n",
        "\n",
        "    # Generate interaction terms\n",
        "    for (i, j) in combinations(feature_names, 2):\n",
        "        interaction_terms_train[f'{i}:{j}'] = X_train[i] * X_train[j]\n",
        "        interaction_terms_test[f'{i}:{j}'] = X_test[i] * X_test[j]\n",
        "\n",
        "    # Combine the original features with the interaction terms\n",
        "    X_train_inter = pd.concat([X_train, interaction_terms_train], axis=1)\n",
        "    X_test_inter = pd.concat([X_test, interaction_terms_test], axis=1)\n",
        "\n",
        "    # Fit the logistic regression model\n",
        "    model_ate = sm.OLS(y_train, X_train_inter).fit(cov_type='HC1')  # Fit OLS model\n",
        "    ate_summary = model_ate.summary()\n",
        "    print(ate_summary)\n",
        "\n",
        "    # Predict probabilities on the test set\n",
        "    y_pred = model_ate.predict(X_test_inter)\n",
        "\n",
        "    # Calculate R-squared and MSE\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f'R-squared: {r2}, MSE: {mse}')\n",
        "    return\n",
        "\n",
        "ATE_est_reg_interaction(X_train, X_test, y_train, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxdwrpuY5XYs"
      },
      "source": [
        "####Method 3.Propensity score methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d11jK9I0Xk4A",
        "outputId": "ce6add94-4629-4aa9-d1a3-bb97fef1278d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The estimated Average Treatment Effect (ATE) is: -5.873591943212382\n",
            "The standard error of the ATE estimate is: 0.555550296140585\n"
          ]
        }
      ],
      "source": [
        "#propensity method\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Assuming df1_no_na is your DataFrame\n",
        "\n",
        "# Define treatment and covariates\n",
        "X = df1_no_na[['BMI_above_30', 'unhealthy_condition', 'ALQ121', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'SLD012','BPXPULS','Sys_AVEBP', 'exercise', 'WH_ratio','smoker_con']]\n",
        "y = df1_no_na['LBDHDD']\n",
        "\n",
        "# Step 1: Estimate Propensity Scores\n",
        "# Separate the treatment variable and the covariates\n",
        "treatment = X['BMI_above_30']\n",
        "covariates = X.drop(columns=['BMI_above_30'])\n",
        "\n",
        "# Fit a logistic regression model to estimate propensity scores\n",
        "log_reg = LogisticRegression(solver='liblinear')\n",
        "log_reg.fit(covariates, treatment)\n",
        "propensity_scores = log_reg.predict_proba(covariates)[:, 1]\n",
        "\n",
        "# Step 2: Calculate Weights\n",
        "weights_treatment = 1 / propensity_scores\n",
        "weights_control = 1 / (1 - propensity_scores)\n",
        "\n",
        "# Step 3: Estimate ATE using the average of weighted outcomes method\n",
        "# Filter the weights to match the corresponding treatment and control groups\n",
        "weights_treatment_filtered = weights_treatment[treatment == 1]\n",
        "weights_control_filtered = weights_control[treatment == 0]\n",
        "\n",
        "# Weighted outcomes for treatment and control groups\n",
        "weighted_outcome_treatment = np.sum(weights_treatment_filtered * y[treatment == 1]) / np.sum(weights_treatment_filtered)\n",
        "weighted_outcome_control = np.sum(weights_control_filtered * y[treatment == 0]) / np.sum(weights_control_filtered)\n",
        "\n",
        "# Calculate ATE\n",
        "ate = weighted_outcome_treatment - weighted_outcome_control\n",
        "\n",
        "# Calculate standard errors\n",
        "# Compute the weighted residuals\n",
        "residuals_treatment = weights_treatment_filtered * (y[treatment == 1] - weighted_outcome_treatment)\n",
        "residuals_control = weights_control_filtered * (y[treatment == 0] - weighted_outcome_control)\n",
        "\n",
        "# Variance of ATE\n",
        "variance_ate = (np.sum(residuals_treatment ** 2) / (np.sum(weights_treatment_filtered) ** 2)) + (np.sum(residuals_control ** 2) / (np.sum(weights_control_filtered) ** 2))\n",
        "\n",
        "# Standard error of ATE\n",
        "ate_se = np.sqrt(variance_ate)\n",
        "\n",
        "print(f\"The estimated Average Treatment Effect (ATE) is: {ate}\")\n",
        "print(f\"The standard error of the ATE estimate is: {ate_se}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t12OS0MqYQJz"
      },
      "source": [
        "Check Propensity Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aBlxlnO9YV8M",
        "outputId": "fcd74ddc-c8af-46b9-96f0-edca2d15fe67"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Covariate  Mean_Treated  Mean_Control  SMD_Before  SMD_After  \\\n",
            "0   unhealthy_condition      0.934201      0.925478    0.034156   0.690963   \n",
            "1                ALQ121      0.093999      0.149547   -0.170476   0.080333   \n",
            "2              INDFMIN2      8.582068      8.726083   -0.032245   0.478738   \n",
            "3              RIAGENDR      1.036876      0.933535    0.103491   0.304079   \n",
            "4        RIDAGEYR_fixed     49.586406     49.438570    0.008176   0.570984   \n",
            "5                SLD012      7.456255      7.629909   -0.105691   0.688142   \n",
            "6               BPXPULS      0.041215      0.029204    0.065199   0.069631   \n",
            "7             Sys_AVEBP    127.434081    123.141994    0.234341   0.829743   \n",
            "8              exercise      0.438901      0.546828   -0.217144   0.237317   \n",
            "9              WH_ratio      0.970177      0.915960    0.702117   0.963850   \n",
            "10           smoker_con      0.237166      0.276939   -0.091106   0.149448   \n",
            "\n",
            "    p-value_Before  p-value_After  \n",
            "0     3.321282e-01   2.249935e-88  \n",
            "1     1.808247e-06   1.626597e-02  \n",
            "2     3.594738e-01   1.272440e-44  \n",
            "3     3.153442e-03   6.283960e-19  \n",
            "4     8.171945e-01   2.783574e-62  \n",
            "5     2.493911e-03   2.571194e-91  \n",
            "6     5.896766e-02   4.259689e-02  \n",
            "7     3.524333e-11  5.882214e-122  \n",
            "8     6.470747e-10   1.438294e-12  \n",
            "9     7.260294e-84  3.529286e-158  \n",
            "10    9.670924e-03   9.386387e-06  \n",
            "      LBDHDD  BMI_above_30  unhealthy_condition  ALQ121  INDFMIN2  RIAGENDR  \\\n",
            "4450    67.0             0                    1     1.0       6.0       0.0   \n",
            "1722    66.0             0                    1     1.0       1.0       0.0   \n",
            "5213    75.0             0                    1     0.0       6.0       0.0   \n",
            "4554    61.0             0                    1     0.0      10.0       0.0   \n",
            "2629    42.0             0                    1     0.0       8.0       0.0   \n",
            "...      ...           ...                  ...     ...       ...       ...   \n",
            "4059    45.0             1                    1     0.0      15.0       2.0   \n",
            "6686    50.0             1                    0     0.0       2.0       2.0   \n",
            "6169    44.0             1                    1     0.0       6.0       2.0   \n",
            "1332    35.0             1                    1     0.0      12.0       0.0   \n",
            "6869    33.0             1                    1     0.0       2.0       0.0   \n",
            "\n",
            "      RIDAGEYR_fixed  SLD012  BPXPULS   Sys_AVEBP  exercise  WH_ratio  \\\n",
            "4450            55.0    10.5      0.0  132.666667         1  0.836802   \n",
            "1722            22.0    12.0      0.0  105.333333         1  0.835443   \n",
            "5213            67.0     9.0      0.0  118.666667         1  0.827051   \n",
            "4554            71.0    10.5      0.0  110.000000         1  0.898420   \n",
            "2629            49.0     8.0      0.0  110.000000         1  0.819491   \n",
            "...              ...     ...      ...         ...       ...       ...   \n",
            "4059            50.0     7.5      0.0  139.333333         0  1.082883   \n",
            "6686            55.0     6.0      0.0  221.333333         0  1.047244   \n",
            "6169            31.0     8.5      0.0  116.000000         0  1.093190   \n",
            "1332            42.0     6.5      0.0  133.333333         0  1.176422   \n",
            "6869            41.0     7.0      0.0  150.666667         0  1.238372   \n",
            "\n",
            "      smoker_con  propensity_score   weights  \n",
            "4450         1.0          0.054769  1.057942  \n",
            "1722         1.0          0.073304  1.079103  \n",
            "5213         0.0          0.081577  1.088823  \n",
            "4554         1.0          0.083364  1.090945  \n",
            "2629         1.0          0.087138  1.095456  \n",
            "...          ...               ...       ...  \n",
            "4059         0.0          0.848664  1.178323  \n",
            "6686         1.0          0.866797  1.153672  \n",
            "6169         0.0          0.870883  1.148260  \n",
            "1332         0.0          0.877974  1.138986  \n",
            "6869         1.0          0.911891  1.096622  \n",
            "\n",
            "[3369 rows x 15 columns]\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Add the propensity scores to the original DataFrame\n",
        "df1_no_na['propensity_score'] = propensity_scores\n",
        "df1_no_na['weights'] = np.where(df1_no_na['BMI_above_30'] == 1, weights_treatment, weights_control)\n",
        "\n",
        "# Plot the distribution of propensity scores\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df1_no_na[df1_no_na['BMI_above_30'] == 1]['propensity_score'], label='Treated', color='blue', kde=True, stat=\"density\", bins=25)\n",
        "sns.histplot(df1_no_na[df1_no_na['BMI_above_30'] == 0]['propensity_score'], label='Control', color='red', kde=True, stat=\"density\", bins=25)\n",
        "plt.xlabel('Propensity Score')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Distribution of Propensity Scores')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Function to calculate standardized mean difference\n",
        "def standardized_mean_difference(group1, group2):\n",
        "    mean_diff = np.mean(group1) - np.mean(group2)\n",
        "    pooled_std = np.sqrt((np.std(group1)**2 + np.std(group2)**2) / 2)\n",
        "    return mean_diff / pooled_std\n",
        "\n",
        "# Check covariate balance before and after weighting\n",
        "covariate_columns = covariates.columns\n",
        "balance_data = []\n",
        "\n",
        "for covariate in covariate_columns:\n",
        "    treated_group = df1_no_na[df1_no_na['BMI_above_30'] == 1][covariate]\n",
        "    control_group = df1_no_na[df1_no_na['BMI_above_30'] == 0][covariate]\n",
        "\n",
        "    # Calculate means before weighting\n",
        "    mean_treated_before = np.mean(treated_group)\n",
        "    mean_control_before = np.mean(control_group)\n",
        "\n",
        "    # Calculate SMD before weighting\n",
        "    smd_before = standardized_mean_difference(treated_group, control_group)\n",
        "\n",
        "    # Calculate t-test before weighting\n",
        "    t_stat_before, p_val_before = ttest_ind(treated_group, control_group)\n",
        "\n",
        "    # Calculate means after weighting\n",
        "    mean_treated_after = np.average(df1_no_na[df1_no_na['BMI_above_30'] == 1][covariate], weights=df1_no_na[df1_no_na['BMI_above_30'] == 1]['weights'])\n",
        "    mean_control_after = np.average(df1_no_na[df1_no_na['BMI_above_30'] == 0][covariate], weights=df1_no_na[df1_no_na['BMI_above_30'] == 0]['weights'])\n",
        "\n",
        "    # Calculate SMD after weighting\n",
        "    smd_after = standardized_mean_difference(\n",
        "        df1_no_na[df1_no_na['BMI_above_30'] == 1][covariate] * df1_no_na[df1_no_na['BMI_above_30'] == 1]['weights'],\n",
        "        df1_no_na[df1_no_na['BMI_above_30'] == 0][covariate] * df1_no_na[df1_no_na['BMI_above_30'] == 0]['weights']\n",
        "    )\n",
        "\n",
        "    # Calculate t-test after weighting\n",
        "    t_stat_after, p_val_after = ttest_ind(\n",
        "        df1_no_na[df1_no_na['BMI_above_30'] == 1][covariate] * df1_no_na[df1_no_na['BMI_above_30'] == 1]['weights'],\n",
        "        df1_no_na[df1_no_na['BMI_above_30'] == 0][covariate] * df1_no_na[df1_no_na['BMI_above_30'] == 0]['weights']\n",
        "    )\n",
        "\n",
        "    # Append to balance data\n",
        "    balance_data.append({\n",
        "        'Covariate': covariate,\n",
        "        'Mean_Treated': mean_treated_before,\n",
        "        'Mean_Control': mean_control_before,\n",
        "        'SMD_Before': smd_before,\n",
        "        'SMD_After': smd_after,\n",
        "        'p-value_Before': p_val_before,\n",
        "        'p-value_After': p_val_after\n",
        "    })\n",
        "\n",
        "balance_table = pd.DataFrame(balance_data)\n",
        "\n",
        "print(balance_table)\n",
        "\n",
        "print(df1_no_na.sort_values(by='propensity_score', ascending=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpqSXnfbZEqT",
        "outputId": "0ff60795-246b-4e23-ccf3-3fee6bdd5a7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The estimated Average Treatment Effect (ATE) using IPW is: -5.873591943212382\n",
            "The standard error of the ATE estimate using IPW is: 0.555550296140585\n",
            "The estimated Average Treatment Effect (ATE) using Doubly Robust method is: -4.766905641134155\n",
            "The standard error of the ATE estimate using Doubly Robust method is: 0.4618685358128632\n"
          ]
        }
      ],
      "source": [
        "##IPWE\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Define treatment and covariates\n",
        "X = df1_no_na[['BMI_above_30', 'unhealthy_condition', 'ALQ121', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'SLD012','BPXPULS','Sys_AVEBP', 'exercise', 'WH_ratio','smoker_con']]\n",
        "y = df1_no_na['LBDHDD']\n",
        "\n",
        "# Step 1: Estimate Propensity Scores\n",
        "# Separate the treatment variable and the covariates\n",
        "treatment = X['BMI_above_30']\n",
        "covariates = X.drop(columns=['BMI_above_30'])\n",
        "\n",
        "# Fit a logistic regression model to estimate propensity scores\n",
        "log_reg = LogisticRegression(solver='liblinear')\n",
        "log_reg.fit(covariates, treatment)\n",
        "propensity_scores = log_reg.predict_proba(covariates)[:, 1]\n",
        "\n",
        "# Step 2: Calculate Weights\n",
        "weights_treatment = 1 / propensity_scores\n",
        "weights_control = 1 / (1 - propensity_scores)\n",
        "\n",
        "# Filter the weights to match the corresponding treatment and control groups\n",
        "weights_treatment_filtered = weights_treatment[treatment == 1]\n",
        "weights_control_filtered = weights_control[treatment == 0]\n",
        "\n",
        "# Step 3: Estimate ATE using the average of weighted outcomes method\n",
        "# Weighted outcomes for treatment and control groups\n",
        "weighted_outcome_treatment = np.sum(weights_treatment_filtered * y[treatment == 1]) / np.sum(weights_treatment_filtered)\n",
        "weighted_outcome_control = np.sum(weights_control_filtered * y[treatment == 0]) / np.sum(weights_control_filtered)\n",
        "\n",
        "# Calculate ATE\n",
        "ate_ipw = weighted_outcome_treatment - weighted_outcome_control\n",
        "\n",
        "# Calculate standard errors for IPW\n",
        "# Compute the weighted residuals\n",
        "residuals_treatment = weights_treatment_filtered * (y[treatment == 1] - weighted_outcome_treatment)\n",
        "residuals_control = weights_control_filtered * (y[treatment == 0] - weighted_outcome_control)\n",
        "\n",
        "# Variance of ATE\n",
        "variance_ate_ipw = (np.sum(residuals_treatment ** 2) / (np.sum(weights_treatment_filtered) ** 2)) + (np.sum(residuals_control ** 2) / (np.sum(weights_control_filtered) ** 2))\n",
        "\n",
        "# Standard error of ATE\n",
        "ate_ipw_se = np.sqrt(variance_ate_ipw)\n",
        "\n",
        "# Step 4: Doubly Robust Estimation\n",
        "# Fit outcome regression models\n",
        "outcome_model_treated = LinearRegression().fit(covariates[treatment == 1], y[treatment == 1])\n",
        "outcome_model_control = LinearRegression().fit(covariates[treatment == 0], y[treatment == 0])\n",
        "\n",
        "# Predict outcomes\n",
        "y_hat_treated = outcome_model_treated.predict(covariates)\n",
        "y_hat_control = outcome_model_control.predict(covariates)\n",
        "\n",
        "# Calculate the doubly robust estimates\n",
        "dr_estimate_treated = y_hat_treated + (treatment / propensity_scores) * (y - y_hat_treated)\n",
        "dr_estimate_control = y_hat_control + ((1 - treatment) / (1 - propensity_scores)) * (y - y_hat_control)\n",
        "\n",
        "# Calculate ATE using doubly robust estimates\n",
        "ate_dr = np.mean(dr_estimate_treated - dr_estimate_control)\n",
        "\n",
        "# Calculate standard errors for DR\n",
        "# Residuals for DR\n",
        "residuals_dr_treated = (treatment / propensity_scores) * (y - y_hat_treated)\n",
        "residuals_dr_control = ((1 - treatment) / (1 - propensity_scores)) * (y - y_hat_control)\n",
        "\n",
        "# Variance of ATE for DR\n",
        "variance_ate_dr = np.var(dr_estimate_treated - dr_estimate_control) / len(y)\n",
        "\n",
        "# Standard error of ATE for DR\n",
        "ate_dr_se = np.sqrt(variance_ate_dr)\n",
        "\n",
        "print(f\"The estimated Average Treatment Effect (ATE) using IPW is: {ate_ipw}\")\n",
        "print(f\"The standard error of the ATE estimate using IPW is: {ate_ipw_se}\")\n",
        "print(f\"The estimated Average Treatment Effect (ATE) using Doubly Robust method is: {ate_dr}\")\n",
        "print(f\"The standard error of the ATE estimate using Doubly Robust method is: {ate_dr_se}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8bcJlw857H-"
      },
      "source": [
        "####Method 4.AIPWE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9VPd2fb6De1",
        "outputId": "aa9e8663-20e1-402f-83a4-f1f6a1882323"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AIPWE Estimate of ATE: -4.615438142306754\n",
            "Standard Error of AIPWE Estimate: 0.42824889638690017\n",
            "T-statistic: -10.777466518295357\n"
          ]
        }
      ],
      "source": [
        "##AIPWE\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming df1_no_na is your DataFrame\n",
        "\n",
        "# Define treatment and covariates\n",
        "X = df1_no_na[['BMI_above_30', 'unhealthy_condition', 'ALQ121', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'SLD012','BPXPULS','Sys_AVEBP', 'exercise', 'WH_ratio','smoker_con']]\n",
        "y = df1_no_na['LBDHDD']\n",
        "\n",
        "# Step 1: Estimate Propensity Scores\n",
        "# Separate the treatment variable and the covariates\n",
        "treatment = X['BMI_above_30']\n",
        "covariates = X.drop(columns=['BMI_above_30'])\n",
        "\n",
        "# Fit a logistic regression model to estimate propensity scores\n",
        "log_reg = LogisticRegression(solver='liblinear')\n",
        "log_reg.fit(covariates, treatment)\n",
        "propensity_scores = log_reg.predict_proba(covariates)[:, 1]\n",
        "\n",
        "# Step 2: Calculate Weights\n",
        "weights_treatment = 1 / propensity_scores\n",
        "weights_control = 1 / (1 - propensity_scores)\n",
        "\n",
        "# Step 3: Outcome Regression Models\n",
        "# Train-test split\n",
        "X_train, X_test, T_train, T_test, y_train, y_test = train_test_split(covariates, treatment, y, test_size=0.2, random_state=66)\n",
        "\n",
        "# Outcome regression model for treated and control groups\n",
        "outcome_model_treated = GradientBoostingRegressor(n_estimators=100, random_state=66)\n",
        "outcome_model_control = GradientBoostingRegressor(n_estimators=100, random_state=66)\n",
        "\n",
        "# Fit models on treated and control groups\n",
        "outcome_model_treated.fit(X_train[T_train == 1], y_train[T_train == 1])\n",
        "outcome_model_control.fit(X_train[T_train == 0], y_train[T_train == 0])\n",
        "\n",
        "# Predict potential outcomes\n",
        "y_pred_treated = outcome_model_treated.predict(covariates)\n",
        "y_pred_control = outcome_model_control.predict(covariates)\n",
        "\n",
        "# Step 4: Calculate AIPWE\n",
        "aipwe = (treatment * (y - y_pred_treated) / propensity_scores) - ((1 - treatment) * (y - y_pred_control) / (1 - propensity_scores)) + (y_pred_treated - y_pred_control)\n",
        "ate_aipwe = np.mean(aipwe)\n",
        "\n",
        "# Calculate standard errors for AIPWE\n",
        "n = len(aipwe)\n",
        "se_aipwe = np.sqrt(np.var(aipwe) / n)\n",
        "\n",
        "# Calculate t-statistic\n",
        "t_statistic = ate_aipwe / se_aipwe\n",
        "\n",
        "print(f\"AIPWE Estimate of ATE: {ate_aipwe}\")\n",
        "print(f\"Standard Error of AIPWE Estimate: {se_aipwe}\")\n",
        "print(f\"T-statistic: {t_statistic}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZmUfrFT620X"
      },
      "source": [
        "####Method 5.Doubly Robust PLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJX6l1Qc673K",
        "outputId": "d83b00b9-c31b-401d-a3de-78c9fcd6b7cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The estimated Average Treatment Effect (ATE) using Doubly Robust PLM method is: -4.593955411721423\n",
            "The standard error of the ATE estimate using Doubly Robust PLM method is: 0.32254193303488715\n",
            "The t-statistic is: -14.24297104099183\n"
          ]
        }
      ],
      "source": [
        "##PLM\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Assuming df1_no_na is your DataFrame\n",
        "\n",
        "# Define treatment and covariates\n",
        "X = df1_no_na[[ 'BMI_above_30', 'unhealthy_condition', 'ALQ121', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'SLD012','BPXPULS','Sys_AVEBP', 'exercise', 'WH_ratio','smoker_con']]\n",
        "y = df1_no_na['LBDHDD']\n",
        "\n",
        "# Step 1: Estimate Propensity Scores\n",
        "# Separate the treatment variable and the covariates\n",
        "treatment = X['BMI_above_30']\n",
        "covariates = X.drop(columns=['BMI_above_30'])\n",
        "\n",
        "# Fit a logistic regression model to estimate propensity scores\n",
        "log_reg = LogisticRegression(solver='liblinear')\n",
        "log_reg.fit(covariates, treatment)\n",
        "propensity_scores = log_reg.predict_proba(covariates)[:, 1]\n",
        "\n",
        "# Step 2: Outcome Regression using Partially Linear Model (PLM)\n",
        "# Fit outcome regression models using a flexible model like RandomForestRegressor\n",
        "outcome_model_treated = RandomForestRegressor(n_estimators=100, random_state=0).fit(covariates[treatment == 1], y[treatment == 1])\n",
        "outcome_model_control = RandomForestRegressor(n_estimators=100, random_state=0).fit(covariates[treatment == 0], y[treatment == 0])\n",
        "\n",
        "# Predict outcomes\n",
        "y_hat_treated = outcome_model_treated.predict(covariates)\n",
        "y_hat_control = outcome_model_control.predict(covariates)\n",
        "\n",
        "# Calculate the doubly robust estimates\n",
        "dr_estimate_treated = y_hat_treated + (treatment / propensity_scores) * (y - y_hat_treated)\n",
        "dr_estimate_control = y_hat_control + ((1 - treatment) / (1 - propensity_scores)) * (y - y_hat_control)\n",
        "\n",
        "# Calculate ATE using doubly robust PLM estimates\n",
        "ate_dr_plm = np.mean(dr_estimate_treated - dr_estimate_control)\n",
        "\n",
        "# Calculate standard errors for DR PLM\n",
        "# Residuals for DR PLM\n",
        "residuals_dr_treated = (treatment / propensity_scores) * (y - y_hat_treated)\n",
        "residuals_dr_control = ((1 - treatment) / (1 - propensity_scores)) * (y - y_hat_control)\n",
        "\n",
        "# Variance of ATE for DR PLM\n",
        "variance_ate_dr_plm = np.var(dr_estimate_treated - dr_estimate_control) / len(y)\n",
        "\n",
        "# Standard error of ATE for DR PLM\n",
        "ate_dr_plm_se = np.sqrt(variance_ate_dr_plm)\n",
        "\n",
        "# Calculate t-statistic\n",
        "t_statistic = ate_dr_plm / ate_dr_plm_se\n",
        "\n",
        "print(f\"The estimated Average Treatment Effect (ATE) using Doubly Robust PLM method is: {ate_dr_plm}\")\n",
        "print(f\"The standard error of the ATE estimate using Doubly Robust PLM method is: {ate_dr_plm_se}\")\n",
        "print(f\"The t-statistic is: {t_statistic}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkTSICmRbcjd"
      },
      "source": [
        "### Hypothesis 2.LBDHDD ~ smoker_con"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8I_kPJiqYUJ"
      },
      "source": [
        "EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pW2SOasVbbsO"
      },
      "outputs": [],
      "source": [
        "#EDA\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df1_no_na = df1[['LBDHDD', 'smoker_con','ALQ121', 'BMXBMI','unhealthy_condition', 'SLD012', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'BPXPULS', 'exercise']].dropna()\n",
        "\n",
        "print(f\"Observed units: {len(df1_no_na)}\")\n",
        "\n",
        "# Creating the histogram for LBDHDD\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(df1_no_na['LBDHDD'], bins=20, edgecolor='black')\n",
        "plt.title('Distribution of LBDHDD')\n",
        "plt.xlabel('LBDHDD')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Creating the pie chart for smoker_con\n",
        "smoker_counts = df1_no_na['smoker_con'].value_counts()\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(smoker_counts, labels=[\"Not Smoker\", 'Smoker'], autopct='%1.1f%%', startangle=140)\n",
        "plt.title('Proportion of Smokers')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtxXeKKvqrQY"
      },
      "source": [
        "####Method 1.Regression-based w/o interactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sQsa1_FZcILG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "import statsmodels.api as sm\n",
        "\n",
        "X = df1_no_na[['smoker_con','ALQ121', 'BMXBMI','unhealthy_condition', 'SLD012', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'BPXPULS', 'exercise']]\n",
        "y = df1_no_na['LBDHDD']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=66)\n",
        "\n",
        "#OLS\n",
        "X_train = sm.add_constant(X_train)\n",
        "X_test = sm.add_constant(X_test)\n",
        "model_ate = sm.OLS(y_train, X_train).fit(cov_type='HC1')  # Fit OLS model\n",
        "# Predict probabilities on the test set\n",
        "y_pred = model_ate.predict(X_test)\n",
        "# Calculate MSE\n",
        "test_mse_ols = mean_squared_error(y_test, y_pred)\n",
        "print(f'OLS Test MSE: {test_mse_ols}')\n",
        "\n",
        "\n",
        "# Function to print the results of the grid search\n",
        "def print_best_params_and_mse(model_name, grid_search, X_test, y_test):\n",
        "    print(f\"{model_name} Best Parameters: {grid_search.best_params_}\")\n",
        "    y_pred = grid_search.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f\"{model_name} Test MSE: {mse}\")\n",
        "    return mse\n",
        "\n",
        "# Standardize the variables for lasso\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Lasso Regression Parameter Tuning\n",
        "lasso = Lasso()\n",
        "lasso_params = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
        "lasso_grid = GridSearchCV(lasso, lasso_params, cv=5)\n",
        "lasso_grid.fit(X_train_scaled, y_train)\n",
        "test_mse_lasso = print_best_params_and_mse('Lasso', lasso_grid, X_test_scaled, y_test)\n",
        "\n",
        "# Random Forest Parameter Tuning\n",
        "rf = RandomForestRegressor(random_state=66)\n",
        "rf_params = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "rf_grid = GridSearchCV(rf, rf_params, cv=5)\n",
        "rf_grid.fit(X_train, y_train)\n",
        "test_mse_rf = print_best_params_and_mse('Random Forest', rf_grid, X_test, y_test)\n",
        "\n",
        "# Gradient Boosting Parameter Tuning\n",
        "gbr = GradientBoostingRegressor(random_state=66)\n",
        "gbr_params = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "gbr_grid = GridSearchCV(gbr, gbr_params, cv=5)\n",
        "gbr_grid.fit(X_train, y_train)\n",
        "test_mse_gbr = print_best_params_and_mse('Gradient Boosting', gbr_grid, X_test, y_test)\n",
        "\n",
        "print(f\"Lasso Best MSE: {test_mse_lasso}\")\n",
        "print(f\"Random Forest Best MSE: {test_mse_rf}\")\n",
        "print(f\"Gradient Boosting Best MSE: {test_mse_gbr}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zMv0bIhZqyiS"
      },
      "outputs": [],
      "source": [
        "#Estimate ATE and its standard error using Gradient Boosting and bootstrap\n",
        "\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Define the function to calculate ATE\n",
        "def calculate_ate(X, y, random_state=66):\n",
        "    gbr = GradientBoostingRegressor(learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=50, random_state=random_state)\n",
        "    gbr.fit(X, y)\n",
        "\n",
        "    X_smoker = X.copy()\n",
        "    X_smoker['smoker_con'] = 1\n",
        "    X_not_smoker = X.copy()\n",
        "    X_not_smoker['smoker_con'] = 0\n",
        "\n",
        "    y_pred_smoker = gbr.predict(X_smoker)\n",
        "    y_pred_not_smoker = gbr.predict(X_not_smoker)\n",
        "\n",
        "    ate = y_pred_smoker.mean() - y_pred_not_smoker.mean()\n",
        "\n",
        "    return ate\n",
        "\n",
        "ate = calculate_ate(X, y, random_state=66)\n",
        "\n",
        "# Bootstrap to estimate the standard error of ATE\n",
        "n_iterations = 100\n",
        "ate_bootstrap = []\n",
        "\n",
        "for i in range(n_iterations):\n",
        "    X_resampled, y_resampled = resample(X, y, random_state=i)\n",
        "    ate_bootstrap.append(calculate_ate(X_resampled, y_resampled))\n",
        "\n",
        "ate_bootstrap = np.array(ate_bootstrap)\n",
        "ate_std_error = np.std(ate_bootstrap)\n",
        "\n",
        "print(f\"ATE estimate by Gradient Boosting: {ate:.4f}\")\n",
        "print(f\"Standard error of ATE estimate: {ate_std_error:.4f}\")\n",
        "print(f\"t-statistic of ATE estimate: {ate/ate_std_error:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiZZfiZGqvld"
      },
      "source": [
        "####Method 2.Regression-based with interactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Fc6HqJHleegC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from itertools import combinations\n",
        "\n",
        "X = df1_no_na[['smoker_con','ALQ121', 'BMXBMI','unhealthy_condition', 'SLD012', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'BPXPULS', 'exercise']]\n",
        "y = df1_no_na['LBDHDD']\n",
        "\n",
        "# Create pairwise interaction terms for X\n",
        "interaction_terms = pd.DataFrame(index=X.index)\n",
        "# Get the list of feature names\n",
        "feature_names = X.columns\n",
        "# Generate interaction terms\n",
        "for (i, j) in combinations(feature_names, 2):\n",
        "    interaction_terms[f'{i}:{j}'] = X[i] * X[j]\n",
        "\n",
        "# Combine the original features with the interaction terms\n",
        "X_inter = pd.concat([X, interaction_terms], axis=1)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_inter, y, test_size=0.2, random_state=66)\n",
        "\n",
        "#OLS\n",
        "X_train = sm.add_constant(X_train)\n",
        "X_test = sm.add_constant(X_test)\n",
        "model_ate = sm.OLS(y_train, X_train).fit(cov_type='HC1')  # Fit OLS model\n",
        "# Predict probabilities on the test set\n",
        "y_pred = model_ate.predict(X_test)\n",
        "# Calculate MSE\n",
        "test_mse_ols = mean_squared_error(y_test, y_pred)\n",
        "print(f'OLS Test MSE: {test_mse_ols}')\n",
        "\n",
        "\n",
        "# Function to print the results of the grid search\n",
        "def print_best_params_and_mse(model_name, grid_search, X_test, y_test):\n",
        "    print(f\"{model_name} Best Parameters: {grid_search.best_params_}\")\n",
        "    y_pred = grid_search.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f\"{model_name} Test MSE: {mse}\")\n",
        "    return mse\n",
        "\n",
        "# Standardize the variables for lasso\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Lasso Regression Parameter Tuning\n",
        "lasso = Lasso()\n",
        "lasso_params = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
        "lasso_grid = GridSearchCV(lasso, lasso_params, cv=5)\n",
        "lasso_grid.fit(X_train_scaled, y_train)\n",
        "test_mse_lasso = print_best_params_and_mse('Lasso', lasso_grid, X_test_scaled, y_test)\n",
        "\n",
        "# Random Forest Parameter Tuning\n",
        "rf = RandomForestRegressor(random_state=66)\n",
        "rf_params = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "rf_grid = GridSearchCV(rf, rf_params, cv=5)\n",
        "rf_grid.fit(X_train, y_train)\n",
        "test_mse_rf = print_best_params_and_mse('Random Forest', rf_grid, X_test, y_test)\n",
        "\n",
        "# Gradient Boosting Parameter Tuning\n",
        "gbr = GradientBoostingRegressor(random_state=66)\n",
        "gbr_params = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "gbr_grid = GridSearchCV(gbr, gbr_params, cv=5)\n",
        "gbr_grid.fit(X_train, y_train)\n",
        "test_mse_gbr = print_best_params_and_mse('Gradient Boosting', gbr_grid, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kvslrlvfketm"
      },
      "outputs": [],
      "source": [
        "#Estimate ATE and its standard error using Gradient Boosting and bootstrap(with interactions)\n",
        "\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Define the function to calculate ATE\n",
        "def calculate_ate(X, y, random_state=66):\n",
        "\n",
        "    def add_interaction_terms(X):\n",
        "        # Create pairwise interaction terms for X\n",
        "        interaction_terms = pd.DataFrame(index=X.index)\n",
        "        # Get the list of feature names excluding the constant term\n",
        "        feature_names = X.columns\n",
        "        # Generate interaction terms\n",
        "        for (i, j) in combinations(feature_names, 2):\n",
        "            interaction_terms[f'{i}:{j}'] = X[i] * X[j]\n",
        "\n",
        "        # Combine the original features with the interaction terms\n",
        "        X_inter = pd.concat([X, interaction_terms], axis=1)\n",
        "        return X_inter\n",
        "\n",
        "    X_inter = add_interaction_terms(X)\n",
        "\n",
        "    gbr = GradientBoostingRegressor(learning_rate=0.1, max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=50, random_state=random_state)\n",
        "    gbr.fit(X_inter, y)\n",
        "\n",
        "    X_smoker = X.copy()\n",
        "    X_smoker['smoker_con'] = 1\n",
        "    X_smoker_inter = add_interaction_terms(X_smoker)\n",
        "\n",
        "    X_not_smoker = X.copy()\n",
        "    X_not_smoker['smoker_con'] = 0\n",
        "    X_not_smoker_inter = add_interaction_terms(X_not_smoker)\n",
        "\n",
        "\n",
        "    y_pred_smoker = gbr.predict(X_smoker_inter)\n",
        "    y_pred_not_smoker = gbr.predict(X_not_smoker_inter)\n",
        "\n",
        "    ate = y_pred_smoker.mean() - y_pred_not_smoker.mean()\n",
        "\n",
        "    return ate\n",
        "\n",
        "ate = calculate_ate(X, y, random_state=66)\n",
        "\n",
        "# Bootstrap to estimate the standard error of ATE\n",
        "n_iterations = 100\n",
        "ate_bootstrap = []\n",
        "\n",
        "for i in range(n_iterations):\n",
        "    X_resampled, y_resampled = resample(X, y, random_state=i)\n",
        "    ate_bootstrap.append(calculate_ate(X_resampled, y_resampled))\n",
        "\n",
        "ate_bootstrap = np.array(ate_bootstrap)\n",
        "ate_std_error = np.std(ate_bootstrap)\n",
        "\n",
        "print(f\"ATE estimate by Gradient Boosting(w/ interactions): {ate:.4f}\")\n",
        "print(f\"Standard error of ATE estimate: {ate_std_error:.4f}\")\n",
        "print(f\"t-statistic of ATE estimate: {ate/ate_std_error:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebV1OPagq8un"
      },
      "source": [
        "####Method 3.Propensity score method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hpnSdCxHq_g3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Define treatment and covariates\n",
        "X = df1_no_na[['smoker_con','ALQ121', 'BMXBMI','unhealthy_condition', 'SLD012', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'BPXPULS', 'exercise']]\n",
        "y = df1_no_na['LBDHDD']\n",
        "\n",
        "# Step 1: Estimate Propensity Scores\n",
        "# Separate the treatment variable and the covariates\n",
        "treatment = X['smoker_con']\n",
        "covariates = X.drop(columns=['smoker_con'])\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(covariates, treatment, test_size=0.2, random_state=66)\n",
        "\n",
        "#OLS\n",
        "log_reg = LogisticRegression(solver='liblinear')\n",
        "log_reg.fit(X_train, y_train)\n",
        "y_pred = log_reg.predict_proba(X_test)[:, 1]\n",
        "# Calculate AUC for Logistic Regression (Lasso)\n",
        "auc_log_reg = roc_auc_score(y_test, y_pred)\n",
        "print(f\"AUC for Logistic Regression (OLS): {auc_log_reg:.4f}\")\n",
        "\n",
        "\n",
        "# Function to print the results of the grid search\n",
        "def print_best_params_and_auc(model_name, grid_search, X_test, y_test):\n",
        "    print(f\"{model_name} Best Parameters: {grid_search.best_params_}\")\n",
        "    y_pred = grid_search.predict(X_test)\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    print(f\"{model_name} Test AUC: {auc}\")\n",
        "    return auc\n",
        "\n",
        "# Standardize the variables for lasso\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Lasso Regression Parameter Tuning\n",
        "lasso = LogisticRegression(penalty='l1', solver='liblinear')\n",
        "lasso_params = {'C': [0.01, 0.1, 1, 10, 100]}\n",
        "lasso_grid = GridSearchCV(lasso, lasso_params, cv=5)\n",
        "lasso_grid.fit(X_train_scaled, y_train)\n",
        "test_auc_lasso = print_best_params_and_auc('Lasso', lasso_grid, X_test_scaled, y_test)\n",
        "\n",
        "# Random Forest Parameter Tuning\n",
        "rf = RandomForestClassifier(random_state=66)\n",
        "rf_params = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "rf_grid = GridSearchCV(rf, rf_params, cv=5)\n",
        "rf_grid.fit(X_train, y_train)\n",
        "test_auc_rf = print_best_params_and_auc('Random Forest', rf_grid, X_test, y_test)\n",
        "\n",
        "# Gradient Boosting Parameter Tuning\n",
        "gbr = GradientBoostingClassifier(random_state=66)\n",
        "gbr_params = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "gbr_grid = GridSearchCV(gbr, gbr_params, cv=5)\n",
        "gbr_grid.fit(X_train, y_train)\n",
        "test_auc_gbr = print_best_params_and_auc('Gradient Boosting', gbr_grid, X_test, y_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "W4s2nnw6rBl-"
      },
      "outputs": [],
      "source": [
        "# check overlap assumption\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "X = df1_no_na[['smoker_con','ALQ121', 'BMXBMI','unhealthy_condition', 'SLD012', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'BPXPULS', 'exercise']]\n",
        "y = df1_no_na['LBDHDD']\n",
        "treatment = X['smoker_con']\n",
        "covariates = X.drop(columns=['smoker_con'])\n",
        "\n",
        "log_reg = LogisticRegression(solver='liblinear')\n",
        "log_reg.fit(covariates, treatment)\n",
        "propensity_scores = log_reg.predict_proba(covariates)[:, 1]\n",
        "\n",
        "# Add the propensity scores to the original DataFrame\n",
        "X['propensity_score'] = propensity_scores\n",
        "weights_treatment = 1 / propensity_scores\n",
        "weights_control = 1 / (1 - propensity_scores)\n",
        "X['weights'] = np.where(X['smoker_con'] == 1, weights_treatment, weights_control)\n",
        "\n",
        "# Plot the distribution of propensity scores\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(X[X['smoker_con'] == 1]['propensity_score'], label='Treated', color='blue', kde=False, stat=\"density\", bins=25)\n",
        "sns.histplot(X[X['smoker_con'] == 0]['propensity_score'], label='Control', color='red', kde=False, stat=\"density\", bins=25)\n",
        "plt.xlabel('Propensity Score')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Distribution of Propensity Scores')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot the distribution of propensity scores\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(X['propensity_score'], label='All', color='green', kde=False, stat=\"density\", bins=25)\n",
        "plt.xlabel('Propensity Score')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Distribution of Propensity Scores')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EEAFqrBXrDP7"
      },
      "outputs": [],
      "source": [
        "## trim propensity score < 0.05\n",
        "\n",
        "y = y[X['propensity_score'] >= 0.05]\n",
        "X = X[X['propensity_score'] >= 0.05]\n",
        "\n",
        "\n",
        "# Plot the distribution of propensity scores\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(X[X['smoker_con'] == 1]['propensity_score'], label='Treated', color='blue', kde=False, stat=\"density\", bins=25)\n",
        "sns.histplot(X[X['smoker_con'] == 0]['propensity_score'], label='Control', color='red', kde=False, stat=\"density\", bins=25)\n",
        "plt.xlabel('Propensity Score')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Distribution of Propensity Scores')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot the distribution of propensity scores\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(X['propensity_score'], label='All', color='green', kde=False, stat=\"density\", bins=25)\n",
        "plt.xlabel('Propensity Score')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Distribution of Propensity Scores')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(X.sort_values(by='propensity_score', ascending=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tNpUHuqTrGj-"
      },
      "outputs": [],
      "source": [
        "# estimate ATE using IPWE\n",
        "# Estimate ATE using the average of weighted outcomes method\n",
        "# Filter the weights to match the corresponding treatment and control groups\n",
        "weights_treatment_filtered = X[X['smoker_con'] == 1]['weights']\n",
        "weights_control_filtered = X[X['smoker_con'] == 0]['weights']\n",
        "\n",
        "# Weighted outcomes for treatment and control groups\n",
        "weighted_outcome_treatment = np.sum(weights_treatment_filtered * y[treatment == 1]) / np.sum(weights_treatment_filtered)\n",
        "weighted_outcome_control = np.sum(weights_control_filtered * y[treatment == 0]) / np.sum(weights_control_filtered)\n",
        "\n",
        "# Calculate ATE\n",
        "ate = weighted_outcome_treatment - weighted_outcome_control\n",
        "\n",
        "# Calculate standard errors\n",
        "# Compute the weighted residuals\n",
        "residuals_treatment = weights_treatment_filtered * (y[treatment == 1] - weighted_outcome_treatment)\n",
        "residuals_control = weights_control_filtered * (y[treatment == 0] - weighted_outcome_control)\n",
        "\n",
        "# Variance of ATE\n",
        "variance_ate = (np.sum(residuals_treatment ** 2) / (np.sum(weights_treatment_filtered) ** 2)) + (np.sum(residuals_control ** 2) / (np.sum(weights_control_filtered) ** 2))\n",
        "\n",
        "# Standard error of ATE\n",
        "ate_se = np.sqrt(variance_ate)\n",
        "\n",
        "print(f\"The estimated Average Treatment Effect (ATE) is: {ate:.4f}\")\n",
        "print(f\"The standard error of the ATE estimate is: {ate_se:.4f}\")\n",
        "print(f\"t-statistic of ATE estimate: {ate/ate_se:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hQpf3FCrH7Y"
      },
      "source": [
        "####Method 4.AIPWE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Fykhwg50rJ5o"
      },
      "outputs": [],
      "source": [
        "# Separate the covariates and outcomes\n",
        "covariates_with_treatment = X.drop(columns=['propensity_score', 'weights'])\n",
        "outcomes = y\n",
        "\n",
        "# Step 1: Split the data into treatment and control groups\n",
        "treatment = X['smoker_con']\n",
        "propensity_scores = X['propensity_score']\n",
        "\n",
        "# Step 2: Fit the outcome model including the treatment variable\n",
        "gbr = GradientBoostingRegressor(\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    min_samples_leaf=4,\n",
        "    min_samples_split=10,\n",
        "    n_estimators=50,\n",
        "    random_state=66\n",
        ")\n",
        "gbr.fit(covariates_with_treatment, outcomes)\n",
        "\n",
        "# Step 3: Predict potential outcomes for all units with treatment and control\n",
        "covariates_treated = covariates_with_treatment.copy()\n",
        "covariates_control = covariates_with_treatment.copy()\n",
        "covariates_treated['smoker_con'] = 1\n",
        "covariates_control['smoker_con'] = 0\n",
        "\n",
        "pred_treatment_all = gbr.predict(covariates_treated)\n",
        "pred_control_all = gbr.predict(covariates_control)\n",
        "\n",
        "# Step 4: Calculate AIPWE\n",
        "# Calculate the AIPWE components\n",
        "term1 = (treatment * (outcomes - pred_treatment_all) / propensity_scores)\n",
        "term2 = ((1 - treatment) * (outcomes - pred_control_all) / (1 - propensity_scores))\n",
        "term3 = pred_treatment_all - pred_control_all\n",
        "\n",
        "# Calculate the ATE\n",
        "AIPWE = np.mean(term1 - term2 + term3)\n",
        "\n",
        "# Step 5: Bootstrap to estimate standard error of ATE\n",
        "n_bootstraps = 100\n",
        "ate_bootstrap = np.zeros(n_bootstraps)\n",
        "\n",
        "for i in range(n_bootstraps):\n",
        "    # Resample the data with replacement\n",
        "    X_resampled, y_resampled = resample(X, y, replace=True, n_samples=len(X), random_state=i)\n",
        "\n",
        "    # Separate the covariates and outcomes for the resampled data\n",
        "    covariates_with_treatment_resampled = X_resampled.drop(columns=['propensity_score', 'weights'])\n",
        "    outcomes_resampled = y_resampled\n",
        "\n",
        "    # Fit the outcome model on the resampled data\n",
        "    gbr_resampled = GradientBoostingRegressor(\n",
        "        learning_rate=0.1,\n",
        "        max_depth=3,\n",
        "        min_samples_leaf=4,\n",
        "        min_samples_split=10,\n",
        "        n_estimators=50,\n",
        "        random_state=66\n",
        "    )\n",
        "    gbr_resampled.fit(covariates_with_treatment_resampled, outcomes_resampled)\n",
        "\n",
        "    # Predict potential outcomes for all units with treatment and control\n",
        "    covariates_treated_resampled = covariates_with_treatment_resampled.copy()\n",
        "    covariates_control_resampled = covariates_with_treatment_resampled.copy()\n",
        "    covariates_treated_resampled['smoker_con'] = 1\n",
        "    covariates_control_resampled['smoker_con'] = 0\n",
        "\n",
        "    pred_treatment_all_resampled = gbr_resampled.predict(covariates_treated_resampled)\n",
        "    pred_control_all_resampled = gbr_resampled.predict(covariates_control_resampled)\n",
        "\n",
        "    # Calculate the AIPWE for the resampled data\n",
        "    propensity_scores_resampled = X_resampled['propensity_score']\n",
        "    treatment_resampled = X_resampled['smoker_con']\n",
        "\n",
        "    term1_resampled = (treatment_resampled * (outcomes_resampled - pred_treatment_all_resampled) / propensity_scores_resampled)\n",
        "    term2_resampled = ((1 - treatment_resampled) * (outcomes_resampled - pred_control_all_resampled) / (1 - propensity_scores_resampled))\n",
        "    term3_resampled = pred_treatment_all_resampled - pred_control_all_resampled\n",
        "\n",
        "    ate_bootstrap[i] = np.mean(term1_resampled - term2_resampled + term3_resampled)\n",
        "\n",
        "# Calculate the standard error of the ATE\n",
        "ate_standard_error = np.std(ate_bootstrap)\n",
        "\n",
        "print(f\"The estimated ATE using Doubly Robust method: {AIPWE:.4f}\")\n",
        "print(f\"The standard error of the ATE estimate: {ate_standard_error:.4f}\")\n",
        "print(f\"The t-statistic of the ATE estimate: {AIPWE/ate_standard_error:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCiIi2urrNYe"
      },
      "source": [
        "####Method 5.Doubly Robust PLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KjlfKueSrOi5"
      },
      "outputs": [],
      "source": [
        "X = df1_no_na[['smoker_con','ALQ121', 'BMXBMI','unhealthy_condition', 'SLD012', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'BPXPULS', 'exercise']]\n",
        "y = df1_no_na['LBDHDD']\n",
        "treatment = X['smoker_con']\n",
        "covariates = X.drop(columns=['smoker_con'])\n",
        "\n",
        "\n",
        "# get the outcome regression residual\n",
        "gbr = GradientBoostingRegressor(\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    min_samples_leaf=4,\n",
        "    min_samples_split=10,\n",
        "    n_estimators=50,\n",
        "    random_state=66\n",
        ")\n",
        "gbr.fit(covariates, y)\n",
        "y_hat = gbr.predict(covariates)\n",
        "y_residual = y - y_hat\n",
        "\n",
        "# get the treatment regression residual\n",
        "log_reg = LogisticRegression(solver='liblinear')\n",
        "log_reg.fit(covariates, treatment)\n",
        "propensity_scores = log_reg.predict_proba(covariates)[:, 1]\n",
        "t_residual = treatment - propensity_scores\n",
        "\n",
        "# remove units with propensity score < 5%\n",
        "y_residual = y_residual[propensity_scores >= 0.05]\n",
        "t_residual = t_residual[propensity_scores >= 0.05]\n",
        "\n",
        "\n",
        "# Residual-on-residual regression\n",
        "t_residual = sm.add_constant(t_residual)\n",
        "plm_model = sm.OLS(y_residual, t_residual).fit()\n",
        "print(plm_model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAT13a4NamiF"
      },
      "source": [
        "### Hypothesis 3.LBDHDD ~ sleep_well"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JK826cufQ7jl"
      },
      "source": [
        "#### Method 1. Regression-based w/o interactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm9ReNYqarDD",
        "outputId": "4cf7db2c-f018-4883-90d5-572b9d77f048"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LBDHDD\n",
            "48.0     186\n",
            "41.0     174\n",
            "54.0     156\n",
            "45.0     113\n",
            "44.0     111\n",
            "        ... \n",
            "11.0       1\n",
            "21.0       1\n",
            "98.0       1\n",
            "115.0      1\n",
            "126.0      1\n",
            "Name: count, Length: 101, dtype: int64\n",
            "sleep_well\n",
            "1    2838\n",
            "0    1001\n",
            "Name: count, dtype: int64\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                 LBDHDD   R-squared:                       0.246\n",
            "Model:                            OLS   Adj. R-squared:                  0.244\n",
            "Method:                 Least Squares   F-statistic:                     105.6\n",
            "Date:                Mon, 08 Jul 2024   Prob (F-statistic):          1.69e-172\n",
            "Time:                        02:14:17   Log-Likelihood:                -12341.\n",
            "No. Observations:                3071   AIC:                         2.470e+04\n",
            "Df Residuals:                    3061   BIC:                         2.476e+04\n",
            "Df Model:                           9                                         \n",
            "Covariance Type:                  HC1                                         \n",
            "=======================================================================================\n",
            "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
            "---------------------------------------------------------------------------------------\n",
            "const                  59.5763      1.963     30.349      0.000      55.729      63.424\n",
            "sleep_well             -0.9243      0.578     -1.600      0.110      -2.056       0.208\n",
            "BMXBMI                 -0.5613      0.035    -16.007      0.000      -0.630      -0.493\n",
            "unhealthy_condition    -1.7888      1.225     -1.460      0.144      -4.190       0.613\n",
            "ALQ121                  9.0710      0.905     10.019      0.000       7.296      10.846\n",
            "INDFMIN2                0.0568      0.054      1.053      0.292      -0.049       0.163\n",
            "RIAGENDR                5.9242      0.247     23.978      0.000       5.440       6.408\n",
            "RIDAGEYR_fixed          0.0840      0.013      6.493      0.000       0.059       0.109\n",
            "BPXPULS                 0.2762      1.364      0.203      0.840      -2.397       2.949\n",
            "exercise                2.1536      0.500      4.305      0.000       1.173       3.134\n",
            "==============================================================================\n",
            "Omnibus:                      856.288   Durbin-Watson:                   1.977\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4382.994\n",
            "Skew:                           1.235   Prob(JB):                         0.00\n",
            "Kurtosis:                       8.306   Cond. No.                         457.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors are heteroscedasticity robust (HC1)\n",
            "R-squared: 0.21547127511826403, MSE: 193.4146127374474\n"
          ]
        }
      ],
      "source": [
        "##\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, r2_score, mean_squared_error\n",
        "\n",
        "df1_no_na = df1[['LBDHDD','sleep_well', 'BMXBMI','unhealthy_condition', 'ALQ121', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'BPXPULS', 'exercise']].dropna()\n",
        "print(df1_no_na['LBDHDD'].value_counts())\n",
        "print(df1_no_na['sleep_well'].value_counts())\n",
        "\n",
        "\n",
        "X = df1_no_na[['sleep_well', 'BMXBMI','unhealthy_condition', 'ALQ121', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'BPXPULS', 'exercise']]\n",
        "y = df1_no_na['LBDHDD']\n",
        "x_categorical_name_list = []\n",
        "X = pd.get_dummies(X, columns=x_categorical_name_list, drop_first=True)\n",
        "transformed_columns = [col for col in X.columns if any(prefix in col for prefix in x_categorical_name_list)]\n",
        "X[transformed_columns] = X[transformed_columns].astype(int)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=66)\n",
        "\n",
        "def ATE_est_reg(X_train, X_test, y_train, y_test):\n",
        "    X_train = sm.add_constant(X_train)\n",
        "    X_test = sm.add_constant(X_test)\n",
        "\n",
        "    model_ate = sm.OLS(y_train, X_train).fit(cov_type='HC1')  # Fit OLS model\n",
        "    ate_summary = model_ate.summary()\n",
        "    print(ate_summary)\n",
        "    # Predict probabilities on the test set\n",
        "    y_pred = model_ate.predict(X_test)\n",
        "\n",
        "    # Calculate R-squared and MSE\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f'R-squared: {r2}, MSE: {mse}')\n",
        "    return\n",
        "\n",
        "\n",
        "ATE_est_reg(X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWIjc2bZRLg0"
      },
      "source": [
        "#### Method 2. Regression-based w/ interactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjbL1JeIb4wK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cf6cba0-c2d5-4e7b-fc88-dd6fb064f72b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                 LBDHDD   R-squared:                       0.266\n",
            "Model:                            OLS   Adj. R-squared:                  0.255\n",
            "Method:                 Least Squares   F-statistic:                     25.93\n",
            "Date:                Mon, 08 Jul 2024   Prob (F-statistic):          6.83e-179\n",
            "Time:                        02:14:23   Log-Likelihood:                -12299.\n",
            "No. Observations:                3071   AIC:                         2.469e+04\n",
            "Df Residuals:                    3025   BIC:                         2.497e+04\n",
            "Df Model:                          45                                         \n",
            "Covariance Type:                  HC1                                         \n",
            "======================================================================================================\n",
            "                                         coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------------------------------\n",
            "const                                 53.5772      0.559     95.928      0.000      52.482      54.672\n",
            "sleep_well                            -0.8480      0.608     -1.395      0.163      -2.040       0.344\n",
            "BMXBMI                                -0.4056      0.063     -6.448      0.000      -0.529      -0.282\n",
            "unhealthy_condition                    0.8047      2.231      0.361      0.718      -3.568       5.178\n",
            "ALQ121                                12.7070      2.467      5.150      0.000       7.871      17.543\n",
            "INDFMIN2                              -0.0198      0.114     -0.173      0.862      -0.243       0.204\n",
            "RIAGENDR                               6.0894      0.541     11.253      0.000       5.029       7.150\n",
            "RIDAGEYR_fixed                         0.1039      0.029      3.641      0.000       0.048       0.160\n",
            "BPXPULS                               -3.0014      3.501     -0.857      0.391      -9.862       3.859\n",
            "exercise                               3.0975      1.059      2.924      0.003       1.021       5.174\n",
            "sleep_well:BMXBMI                     -0.2921      0.075     -3.920      0.000      -0.438      -0.146\n",
            "sleep_well:unhealthy_condition        -3.3984      2.676     -1.270      0.204      -8.644       1.847\n",
            "sleep_well:ALQ121                     -4.9774      2.544     -1.956      0.050      -9.964       0.009\n",
            "sleep_well:INDFMIN2                    0.1105      0.129      0.854      0.393      -0.143       0.364\n",
            "sleep_well:RIAGENDR                   -0.2998      0.599     -0.501      0.616      -1.473       0.873\n",
            "sleep_well:RIDAGEYR_fixed             -0.0234      0.032     -0.729      0.466      -0.086       0.040\n",
            "sleep_well:BPXPULS                     2.9712      3.416      0.870      0.384      -3.725       9.667\n",
            "sleep_well:exercise                   -1.1886      1.200     -0.990      0.322      -3.541       1.164\n",
            "BMXBMI:unhealthy_condition             0.1974      0.173      1.139      0.255      -0.142       0.537\n",
            "BMXBMI:ALQ121                         -0.3177      0.139     -2.289      0.022      -0.590      -0.046\n",
            "BMXBMI:INDFMIN2                       -0.0037      0.007     -0.498      0.619      -0.018       0.011\n",
            "BMXBMI:RIAGENDR                        0.0684      0.035      1.926      0.054      -0.001       0.138\n",
            "BMXBMI:RIDAGEYR_fixed                 -0.0007      0.002     -0.374      0.708      -0.004       0.003\n",
            "BMXBMI:BPXPULS                         0.2681      0.206      1.302      0.193      -0.136       0.672\n",
            "BMXBMI:exercise                       -0.1838      0.067     -2.726      0.006      -0.316      -0.052\n",
            "unhealthy_condition:ALQ121            -1.8998      4.729     -0.402      0.688     -11.169       7.369\n",
            "unhealthy_condition:INDFMIN2           0.2231      0.260      0.857      0.391      -0.287       0.733\n",
            "unhealthy_condition:RIAGENDR          -0.0718      1.238     -0.058      0.954      -2.499       2.355\n",
            "unhealthy_condition:RIDAGEYR_fixed     0.0581      0.060      0.974      0.330      -0.059       0.175\n",
            "unhealthy_condition:BPXPULS           -1.8021      5.461     -0.330      0.741     -12.506       8.902\n",
            "unhealthy_condition:exercise           2.0788      2.393      0.869      0.385      -2.612       6.770\n",
            "ALQ121:INDFMIN2                       -0.1735      0.184     -0.943      0.346      -0.534       0.187\n",
            "ALQ121:RIAGENDR                        1.6025      1.112      1.441      0.150      -0.577       3.782\n",
            "ALQ121:RIDAGEYR_fixed                 -0.0172      0.048     -0.357      0.721      -0.112       0.077\n",
            "ALQ121:BPXPULS                         4.1188      3.997      1.030      0.303      -3.716      11.953\n",
            "ALQ121:exercise                        2.2743      1.897      1.199      0.231      -1.444       5.993\n",
            "INDFMIN2:RIAGENDR                     -0.0324      0.055     -0.592      0.554      -0.140       0.075\n",
            "INDFMIN2:RIDAGEYR_fixed                0.0024      0.003      0.795      0.427      -0.003       0.008\n",
            "INDFMIN2:BPXPULS                      -0.3000      0.336     -0.893      0.372      -0.958       0.358\n",
            "INDFMIN2:exercise                      0.0365      0.112      0.326      0.744      -0.183       0.256\n",
            "RIAGENDR:RIDAGEYR_fixed                0.0447      0.013      3.420      0.001       0.019       0.070\n",
            "RIAGENDR:BPXPULS                       0.8605      1.596      0.539      0.590      -2.269       3.990\n",
            "RIAGENDR:exercise                      1.1274      0.514      2.193      0.028       0.120       2.135\n",
            "RIDAGEYR_fixed:BPXPULS                 0.0701      0.083      0.839      0.401      -0.094       0.234\n",
            "RIDAGEYR_fixed:exercise               -0.0404      0.027     -1.511      0.131      -0.093       0.012\n",
            "BPXPULS:exercise                       2.2585      2.905      0.777      0.437      -3.435       7.953\n",
            "==============================================================================\n",
            "Omnibus:                      806.030   Durbin-Watson:                   1.980\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3883.547\n",
            "Skew:                           1.175   Prob(JB):                         0.00\n",
            "Kurtosis:                       7.982   Cond. No.                     3.63e+03\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors are heteroscedasticity robust (HC1)\n",
            "[2] The condition number is large, 3.63e+03. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n",
            "R-squared: 0.20832334669034436, MSE: 195.17683477586857\n"
          ]
        }
      ],
      "source": [
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from itertools import combinations\n",
        "\n",
        "def ATE_est_reg_interaction(X_train, X_test, y_train, y_test):\n",
        "    # Add constant term to the features\n",
        "    cols_to_subtract_mean = X_train.columns[X_train.columns != 'sleep_well']\n",
        "    X_train[cols_to_subtract_mean] = X_train[cols_to_subtract_mean] - X_train[cols_to_subtract_mean].mean()\n",
        "    X_test[cols_to_subtract_mean] = X_test[cols_to_subtract_mean] - X_test[cols_to_subtract_mean].mean()\n",
        "    X_train = sm.add_constant(X_train)\n",
        "    X_test = sm.add_constant(X_test)\n",
        "\n",
        "    # Create pairwise interaction terms for X_train\n",
        "    interaction_terms_train = pd.DataFrame(index=X_train.index)\n",
        "    interaction_terms_test = pd.DataFrame(index=X_test.index)\n",
        "\n",
        "    # Get the list of feature names excluding the constant term\n",
        "    feature_names = X_train.columns[1:]\n",
        "\n",
        "    # Generate interaction terms\n",
        "    for (i, j) in combinations(feature_names, 2):\n",
        "        interaction_terms_train[f'{i}:{j}'] = X_train[i] * X_train[j]\n",
        "        interaction_terms_test[f'{i}:{j}'] = X_test[i] * X_test[j]\n",
        "\n",
        "    # Combine the original features with the interaction terms\n",
        "    X_train_inter = pd.concat([X_train, interaction_terms_train], axis=1)\n",
        "    X_test_inter = pd.concat([X_test, interaction_terms_test], axis=1)\n",
        "\n",
        "    # Fit the logistic regression model\n",
        "    model_ate = sm.OLS(y_train, X_train_inter).fit(cov_type='HC1')  # Fit OLS model\n",
        "    ate_summary = model_ate.summary()\n",
        "    print(ate_summary)\n",
        "\n",
        "    # Predict probabilities on the test set\n",
        "    y_pred = model_ate.predict(X_test_inter)\n",
        "\n",
        "    # Calculate R-squared and MSE\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f'R-squared: {r2}, MSE: {mse}')\n",
        "    return\n",
        "\n",
        "ATE_est_reg_interaction(X_train, X_test, y_train, y_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoiwHbFmRetx"
      },
      "source": [
        "#### Method 3. IPWE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1USy0xvGdGZH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c824aa9d-1141-4138-8c68-5b96596f5916"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The estimated Average Treatment Effect (ATE) is: -0.5613166604889699\n",
            "The standard error of the ATE estimate is: 0.6066065700382592\n"
          ]
        }
      ],
      "source": [
        "#propensity method\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Assuming df1_no_na is your DataFrame\n",
        "\n",
        "# Define treatment and covariates\n",
        "X = df1_no_na[['sleep_well', 'BMXBMI','unhealthy_condition', 'ALQ121', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'BPXPULS', 'exercise']]\n",
        "y = df1_no_na['LBDHDD']\n",
        "\n",
        "# Step 1: Estimate Propensity Scores\n",
        "# Separate the treatment variable and the covariates\n",
        "treatment = X['sleep_well']\n",
        "covariates = X.drop(columns=['sleep_well'])\n",
        "\n",
        "# Fit a logistic regression model to estimate propensity scores\n",
        "log_reg = LogisticRegression(solver='liblinear')\n",
        "log_reg.fit(covariates, treatment)\n",
        "propensity_scores = log_reg.predict_proba(covariates)[:, 1]\n",
        "\n",
        "# Step 2: Calculate Weights\n",
        "weights_treatment = 1 / propensity_scores\n",
        "weights_control = 1 / (1 - propensity_scores)\n",
        "\n",
        "# Step 3: Estimate ATE using the average of weighted outcomes method\n",
        "# Filter the weights to match the corresponding treatment and control groups\n",
        "weights_treatment_filtered = weights_treatment[treatment == 1]\n",
        "weights_control_filtered = weights_control[treatment == 0]\n",
        "\n",
        "# Weighted outcomes for treatment and control groups\n",
        "weighted_outcome_treatment = np.sum(weights_treatment_filtered * y[treatment == 1]) / np.sum(weights_treatment_filtered)\n",
        "weighted_outcome_control = np.sum(weights_control_filtered * y[treatment == 0]) / np.sum(weights_control_filtered)\n",
        "\n",
        "# Calculate ATE\n",
        "ate = weighted_outcome_treatment - weighted_outcome_control\n",
        "\n",
        "# Calculate standard errors\n",
        "# Compute the weighted residuals\n",
        "residuals_treatment = weights_treatment_filtered * (y[treatment == 1] - weighted_outcome_treatment)\n",
        "residuals_control = weights_control_filtered * (y[treatment == 0] - weighted_outcome_control)\n",
        "\n",
        "# Variance of ATE\n",
        "variance_ate = (np.sum(residuals_treatment ** 2) / (np.sum(weights_treatment_filtered) ** 2)) + (np.sum(residuals_control ** 2) / (np.sum(weights_control_filtered) ** 2))\n",
        "\n",
        "# Standard error of ATE\n",
        "ate_se = np.sqrt(variance_ate)\n",
        "\n",
        "print(f\"The estimated Average Treatment Effect (ATE) is: {ate}\")\n",
        "print(f\"The standard error of the ATE estimate is: {ate_se}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PLRIkhhSAYL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d78248ea-918f-4edf-b66c-d58ebcf4fbd9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Covariate  Mean_Treated  Mean_Control  SMD_Before  SMD_After  \\\n",
            "0               BMXBMI     29.563108     30.866134   -0.171075  -3.661326   \n",
            "1  unhealthy_condition      0.927061      0.937063   -0.039754  -2.521619   \n",
            "2               ALQ121      0.125793      0.127872   -0.006248  -0.320579   \n",
            "3             INDFMIN2      8.532770      8.818182   -0.063668  -1.601791   \n",
            "4             RIAGENDR      1.028189      0.859141    0.169927  -0.738216   \n",
            "5       RIDAGEYR_fixed     50.207893     49.519481    0.038891  -1.993229   \n",
            "6              BPXPULS      0.038055      0.032967    0.027495  -0.157565   \n",
            "7             exercise      0.508809      0.445554    0.126896  -0.753133   \n",
            "\n",
            "   p-value_Before  p-value_After  \n",
            "0        0.000002   0.000000e+00  \n",
            "1        0.287443   0.000000e+00  \n",
            "2        0.864853   9.021035e-28  \n",
            "3        0.083019   0.000000e+00  \n",
            "4        0.000004  1.453032e-137  \n",
            "5        0.304585   0.000000e+00  \n",
            "6        0.461961   4.232389e-08  \n",
            "7        0.000575  2.691748e-141  \n",
            "      LBDHDD  sleep_well  BMXBMI  unhealthy_condition  ALQ121  INDFMIN2  \\\n",
            "8857    41.0           1    68.2                    1     0.0       8.0   \n",
            "2259    38.0           1    57.7                    1     0.0      14.0   \n",
            "825     41.0           1    60.6                    1     0.0       7.0   \n",
            "9075    51.0           0    84.4                    1     0.0       4.0   \n",
            "8747    29.0           1    56.1                    1     0.0       8.0   \n",
            "...      ...         ...     ...                  ...     ...       ...   \n",
            "2533    67.0           1    20.8                    1     0.0       3.0   \n",
            "4978    81.0           1    30.1                    1     0.0       2.0   \n",
            "6000    57.0           1    25.2                    1     0.0       4.0   \n",
            "4601    80.0           1    20.7                    1     1.0       7.0   \n",
            "4440    90.0           1    19.9                    1     0.0       5.0   \n",
            "\n",
            "      RIAGENDR  RIDAGEYR_fixed  BPXPULS  exercise  propensity_score   weights  \n",
            "8857       0.0            33.0      0.0         0          0.447461  2.234833  \n",
            "2259       0.0            32.0      0.0         0          0.475145  2.104619  \n",
            "825        0.0            34.0      0.0         0          0.495944  2.016358  \n",
            "9075       2.0            67.0      0.0         0          0.510445  2.042671  \n",
            "8747       0.0            39.0      0.0         0          0.521510  1.917509  \n",
            "...        ...             ...      ...       ...               ...       ...  \n",
            "2533       2.0            78.0      0.0         1          0.863086  1.158633  \n",
            "4978       2.0            80.0      1.0         1          0.864349  1.156941  \n",
            "6000       2.0            80.0      1.0         1          0.872346  1.146335  \n",
            "4601       2.0            79.0      1.0         1          0.875134  1.142682  \n",
            "4440       2.0            80.0      1.0         1          0.882961  1.132553  \n",
            "\n",
            "[3839 rows x 12 columns]\n"
          ]
        }
      ],
      "source": [
        "# Check Overlap Assumption and Covariate Balance\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Add the propensity scores to the original DataFrame\n",
        "df1_no_na['propensity_score'] = propensity_scores\n",
        "df1_no_na['weights'] = np.where(df1_no_na['sleep_well'] == 1, weights_treatment, weights_control)\n",
        "\n",
        "# Plot the distribution of propensity scores\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df1_no_na[df1_no_na['sleep_well'] == 1]['propensity_score'], label='Treated', color='blue', kde=True, stat=\"density\", bins=25)\n",
        "sns.histplot(df1_no_na[df1_no_na['sleep_well'] == 0]['propensity_score'], label='Control', color='red', kde=True, stat=\"density\", bins=25)\n",
        "plt.xlabel('Propensity Score')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Distribution of Propensity Scores')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Function to calculate standardized mean difference\n",
        "def standardized_mean_difference(group1, group2):\n",
        "    mean_diff = np.mean(group1) - np.mean(group2)\n",
        "    pooled_std = np.sqrt((np.std(group1)**2 + np.std(group2)**2) / 2)\n",
        "    return mean_diff / pooled_std\n",
        "\n",
        "# Check covariate balance before and after weighting\n",
        "covariate_columns = covariates.columns\n",
        "balance_data = []\n",
        "\n",
        "for covariate in covariate_columns:\n",
        "    treated_group = df1_no_na[df1_no_na['sleep_well'] == 1][covariate]\n",
        "    control_group = df1_no_na[df1_no_na['sleep_well'] == 0][covariate]\n",
        "\n",
        "    # Calculate means before weighting\n",
        "    mean_treated_before = np.mean(treated_group)\n",
        "    mean_control_before = np.mean(control_group)\n",
        "\n",
        "    # Calculate SMD before weighting\n",
        "    smd_before = standardized_mean_difference(treated_group, control_group)\n",
        "\n",
        "    # Calculate t-test before weighting\n",
        "    t_stat_before, p_val_before = ttest_ind(treated_group, control_group)\n",
        "\n",
        "    # Calculate means after weighting\n",
        "    mean_treated_after = np.average(df1_no_na[df1_no_na['sleep_well'] == 1][covariate], weights=df1_no_na[df1_no_na['sleep_well'] == 1]['weights'])\n",
        "    mean_control_after = np.average(df1_no_na[df1_no_na['sleep_well'] == 0][covariate], weights=df1_no_na[df1_no_na['sleep_well'] == 0]['weights'])\n",
        "\n",
        "    # Calculate SMD after weighting\n",
        "    smd_after = standardized_mean_difference(\n",
        "        df1_no_na[df1_no_na['sleep_well'] == 1][covariate] * df1_no_na[df1_no_na['sleep_well'] == 1]['weights'],\n",
        "        df1_no_na[df1_no_na['sleep_well'] == 0][covariate] * df1_no_na[df1_no_na['sleep_well'] == 0]['weights']\n",
        "    )\n",
        "\n",
        "    # Calculate t-test after weighting\n",
        "    t_stat_after, p_val_after = ttest_ind(\n",
        "        df1_no_na[df1_no_na['sleep_well'] == 1][covariate] * df1_no_na[df1_no_na['sleep_well'] == 1]['weights'],\n",
        "        df1_no_na[df1_no_na['sleep_well'] == 0][covariate] * df1_no_na[df1_no_na['sleep_well'] == 0]['weights']\n",
        "    )\n",
        "\n",
        "    # Append to balance data\n",
        "    balance_data.append({\n",
        "        'Covariate': covariate,\n",
        "        'Mean_Treated': mean_treated_before,\n",
        "        'Mean_Control': mean_control_before,\n",
        "        'SMD_Before': smd_before,\n",
        "        'SMD_After': smd_after,\n",
        "        'p-value_Before': p_val_before,\n",
        "        'p-value_After': p_val_after\n",
        "    })\n",
        "\n",
        "balance_table = pd.DataFrame(balance_data)\n",
        "\n",
        "print(balance_table)\n",
        "\n",
        "print(df1_no_na.sort_values(by='propensity_score', ascending=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiCOmZkOSZev"
      },
      "source": [
        "#### Method 4. AIPW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkrZpNaRdXmN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "969c2239-c79c-4431-871a-e7fd3829d4d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The estimated Average Treatment Effect (ATE) using IPW is: -0.5613166604889699\n",
            "The standard error of the ATE estimate using IPW is: 0.6066065700382592\n",
            "The estimated Average Treatment Effect (ATE) using Doubly Robust method is: -0.5759417793855983\n",
            "The standard error of the ATE estimate using Doubly Robust method is: 0.5385420243291216\n"
          ]
        }
      ],
      "source": [
        "# doubly\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Assuming df1_no_na is your DataFrame\n",
        "\n",
        "# Define treatment and covariates\n",
        "X = df1_no_na[['sleep_well', 'BMXBMI','unhealthy_condition', 'ALQ121', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'BPXPULS', 'exercise']]\n",
        "y = df1_no_na['LBDHDD']\n",
        "\n",
        "# Step 1: Estimate Propensity Scores\n",
        "# Separate the treatment variable and the covariates\n",
        "treatment = X['sleep_well']\n",
        "covariates = X.drop(columns=['sleep_well'])\n",
        "\n",
        "# Fit a logistic regression model to estimate propensity scores\n",
        "log_reg = LogisticRegression(solver='liblinear')\n",
        "log_reg.fit(covariates, treatment)\n",
        "propensity_scores = log_reg.predict_proba(covariates)[:, 1]\n",
        "\n",
        "# Step 2: Calculate Weights\n",
        "weights_treatment = 1 / propensity_scores\n",
        "weights_control = 1 / (1 - propensity_scores)\n",
        "\n",
        "# Filter the weights to match the corresponding treatment and control groups\n",
        "weights_treatment_filtered = weights_treatment[treatment == 1]\n",
        "weights_control_filtered = weights_control[treatment == 0]\n",
        "\n",
        "# Step 3: Estimate ATE using the average of weighted outcomes method\n",
        "# Weighted outcomes for treatment and control groups\n",
        "weighted_outcome_treatment = np.sum(weights_treatment_filtered * y[treatment == 1]) / np.sum(weights_treatment_filtered)\n",
        "weighted_outcome_control = np.sum(weights_control_filtered * y[treatment == 0]) / np.sum(weights_control_filtered)\n",
        "\n",
        "# Calculate ATE\n",
        "ate_ipw = weighted_outcome_treatment - weighted_outcome_control\n",
        "\n",
        "# Calculate standard errors for IPW\n",
        "# Compute the weighted residuals\n",
        "residuals_treatment = weights_treatment_filtered * (y[treatment == 1] - weighted_outcome_treatment)\n",
        "residuals_control = weights_control_filtered * (y[treatment == 0] - weighted_outcome_control)\n",
        "\n",
        "# Variance of ATE\n",
        "variance_ate_ipw = (np.sum(residuals_treatment ** 2) / (np.sum(weights_treatment_filtered) ** 2)) + (np.sum(residuals_control ** 2) / (np.sum(weights_control_filtered) ** 2))\n",
        "\n",
        "# Standard error of ATE\n",
        "ate_ipw_se = np.sqrt(variance_ate_ipw)\n",
        "\n",
        "# Step 4: Doubly Robust Estimation\n",
        "# Fit outcome regression models\n",
        "outcome_model_treated = LinearRegression().fit(covariates[treatment == 1], y[treatment == 1])\n",
        "outcome_model_control = LinearRegression().fit(covariates[treatment == 0], y[treatment == 0])\n",
        "\n",
        "# Predict outcomes\n",
        "y_hat_treated = outcome_model_treated.predict(covariates)\n",
        "y_hat_control = outcome_model_control.predict(covariates)\n",
        "\n",
        "# Calculate the doubly robust estimates\n",
        "dr_estimate_treated = y_hat_treated + (treatment / propensity_scores) * (y - y_hat_treated)\n",
        "dr_estimate_control = y_hat_control + ((1 - treatment) / (1 - propensity_scores)) * (y - y_hat_control)\n",
        "\n",
        "# Calculate ATE using doubly robust estimates\n",
        "ate_dr = np.mean(dr_estimate_treated - dr_estimate_control)\n",
        "\n",
        "# Calculate standard errors for DR\n",
        "# Residuals for DR\n",
        "residuals_dr_treated = (treatment / propensity_scores) * (y - y_hat_treated)\n",
        "residuals_dr_control = ((1 - treatment) / (1 - propensity_scores)) * (y - y_hat_control)\n",
        "\n",
        "# Variance of ATE for DR\n",
        "variance_ate_dr = np.var(dr_estimate_treated - dr_estimate_control) / len(y)\n",
        "\n",
        "# Standard error of ATE for DR\n",
        "ate_dr_se = np.sqrt(variance_ate_dr)\n",
        "\n",
        "print(f\"The estimated Average Treatment Effect (ATE) using IPW is: {ate_ipw}\")\n",
        "print(f\"The standard error of the ATE estimate using IPW is: {ate_ipw_se}\")\n",
        "print(f\"The estimated Average Treatment Effect (ATE) using Doubly Robust method is: {ate_dr}\")\n",
        "print(f\"The standard error of the ATE estimate using Doubly Robust method is: {ate_dr_se}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqiHRSePSd3R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b167ab6f-4891-4932-f4ec-f336cb48e283"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The estimated Average Treatment Effect (ATE) using IPW is: -0.5613166604889699\n",
            "The standard error of the ATE estimate using IPW is: 0.6066065700382592\n",
            "The estimated Average Treatment Effect (ATE) using Doubly Robust method is: -0.5759417793855983\n",
            "The standard error of the ATE estimate using Doubly Robust method is: 0.5385420243291216\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Assuming df1_no_na is your DataFrame\n",
        "\n",
        "# Define treatment and covariates\n",
        "#X = df1_no_na[['sleep_well', 'BMXBMI','unhealthy_condition', 'ALQ121', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'BPXPULS', 'exercise']]\n",
        "#y = df1_no_na['LBDHDD']\n",
        "X = df1_no_na[['sleep_well', 'BMXBMI','unhealthy_condition', 'ALQ121', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'BPXPULS', 'exercise']]\n",
        "y = df1_no_na['LBDHDD']\n",
        "\n",
        "# Step 1: Estimate Propensity Scores\n",
        "# Separate the treatment variable and the covariates\n",
        "treatment = X['sleep_well']\n",
        "covariates = X.drop(columns=['sleep_well'])\n",
        "\n",
        "# Fit a logistic regression model to estimate propensity scores\n",
        "log_reg = LogisticRegression(solver='liblinear')\n",
        "log_reg.fit(covariates, treatment)\n",
        "propensity_scores = log_reg.predict_proba(covariates)[:, 1]\n",
        "\n",
        "# Step 2: Calculate Weights\n",
        "weights_treatment = 1 / propensity_scores\n",
        "weights_control = 1 / (1 - propensity_scores)\n",
        "\n",
        "# Filter the weights to match the corresponding treatment and control groups\n",
        "weights_treatment_filtered = weights_treatment[treatment == 1]\n",
        "weights_control_filtered = weights_control[treatment == 0]\n",
        "\n",
        "# Step 3: Estimate ATE using the average of weighted outcomes method\n",
        "# Weighted outcomes for treatment and control groups\n",
        "weighted_outcome_treatment = np.sum(weights_treatment_filtered * y[treatment == 1]) / np.sum(weights_treatment_filtered)\n",
        "weighted_outcome_control = np.sum(weights_control_filtered * y[treatment == 0]) / np.sum(weights_control_filtered)\n",
        "\n",
        "# Calculate ATE\n",
        "ate_ipw = weighted_outcome_treatment - weighted_outcome_control\n",
        "\n",
        "# Calculate standard errors for IPW\n",
        "# Compute the weighted residuals\n",
        "residuals_treatment = weights_treatment_filtered * (y[treatment == 1] - weighted_outcome_treatment)\n",
        "residuals_control = weights_control_filtered * (y[treatment == 0] - weighted_outcome_control)\n",
        "\n",
        "# Variance of ATE\n",
        "variance_ate_ipw = (np.sum(residuals_treatment ** 2) / (np.sum(weights_treatment_filtered) ** 2)) + (np.sum(residuals_control ** 2) / (np.sum(weights_control_filtered) ** 2))\n",
        "\n",
        "# Standard error of ATE\n",
        "ate_ipw_se = np.sqrt(variance_ate_ipw)\n",
        "\n",
        "# Step 4: Doubly Robust Estimation\n",
        "# Fit outcome regression models\n",
        "outcome_model_treated = LinearRegression().fit(covariates[treatment == 1], y[treatment == 1])\n",
        "outcome_model_control = LinearRegression().fit(covariates[treatment == 0], y[treatment == 0])\n",
        "\n",
        "# Predict outcomes\n",
        "y_hat_treated = outcome_model_treated.predict(covariates)\n",
        "y_hat_control = outcome_model_control.predict(covariates)\n",
        "\n",
        "# Calculate the doubly robust estimates\n",
        "dr_estimate_treated = y_hat_treated + (treatment / propensity_scores) * (y - y_hat_treated)\n",
        "dr_estimate_control = y_hat_control + ((1 - treatment) / (1 - propensity_scores)) * (y - y_hat_control)\n",
        "\n",
        "# Calculate ATE using doubly robust estimates\n",
        "ate_dr = np.mean(dr_estimate_treated - dr_estimate_control)\n",
        "\n",
        "# Calculate standard errors for DR\n",
        "# Residuals for DR\n",
        "residuals_dr_treated = (treatment / propensity_scores) * (y - y_hat_treated)\n",
        "residuals_dr_control = ((1 - treatment) / (1 - propensity_scores)) * (y - y_hat_control)\n",
        "\n",
        "# Variance of ATE for DR\n",
        "variance_ate_dr = np.var(dr_estimate_treated - dr_estimate_control) / len(y)\n",
        "\n",
        "# Standard error of ATE for DR\n",
        "ate_dr_se = np.sqrt(variance_ate_dr)\n",
        "\n",
        "print(f\"The estimated Average Treatment Effect (ATE) using IPW is: {ate_ipw}\")\n",
        "print(f\"The standard error of the ATE estimate using IPW is: {ate_ipw_se}\")\n",
        "print(f\"The estimated Average Treatment Effect (ATE) using Doubly Robust method is: {ate_dr}\")\n",
        "print(f\"The standard error of the ATE estimate using Doubly Robust method is: {ate_dr_se}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW4YcinFSidF"
      },
      "source": [
        "#### Method 5. Doubly Robust PLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEVqcQVZSoH8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e74fa2d4-22f9-428d-9cdd-066b14d57a04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The estimated Average Treatment Effect (ATE) using Doubly Robust PLM method is: -0.36478361355361993\n",
            "The standard error of the ATE estimate using Doubly Robust PLM method is: 0.3389687927252287\n"
          ]
        }
      ],
      "source": [
        "#PLM\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Assuming df1_no_na is your DataFrame\n",
        "\n",
        "# Define treatment and covariates\n",
        "#X = df1_no_na[['sleep_well', 'BMXBMI','unhealthy_condition', 'ALQ121', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'BPXPULS', 'exercise']]\n",
        "#y = df1_no_na['LBDHDD']\n",
        "X = df1_no_na[['sleep_well', 'BMXBMI','unhealthy_condition', 'ALQ121', 'INDFMIN2','RIAGENDR','RIDAGEYR_fixed', 'BPXPULS', 'exercise']]\n",
        "y = df1_no_na['LBDHDD']\n",
        "\n",
        "# Step 1: Estimate Propensity Scores\n",
        "# Separate the treatment variable and the covariates\n",
        "treatment = X['sleep_well']\n",
        "covariates = X.drop(columns=['sleep_well'])\n",
        "\n",
        "# Fit a logistic regression model to estimate propensity scores\n",
        "log_reg = LogisticRegression(solver='liblinear')\n",
        "log_reg.fit(covariates, treatment)\n",
        "propensity_scores = log_reg.predict_proba(covariates)[:, 1]\n",
        "\n",
        "# Step 2: Outcome Regression using Partially Linear Model (PLM)\n",
        "# Fit outcome regression models using a flexible model like RandomForestRegressor\n",
        "outcome_model_treated = RandomForestRegressor(n_estimators=100, random_state=0).fit(covariates[treatment == 1], y[treatment == 1])\n",
        "outcome_model_control = RandomForestRegressor(n_estimators=100, random_state=0).fit(covariates[treatment == 0], y[treatment == 0])\n",
        "\n",
        "# Predict outcomes\n",
        "y_hat_treated = outcome_model_treated.predict(covariates)\n",
        "y_hat_control = outcome_model_control.predict(covariates)\n",
        "\n",
        "# Calculate the doubly robust estimates\n",
        "dr_estimate_treated = y_hat_treated + (treatment / propensity_scores) * (y - y_hat_treated)\n",
        "dr_estimate_control = y_hat_control + ((1 - treatment) / (1 - propensity_scores)) * (y - y_hat_control)\n",
        "\n",
        "# Calculate ATE using doubly robust PLM estimates\n",
        "ate_dr_plm = np.mean(dr_estimate_treated - dr_estimate_control)\n",
        "\n",
        "# Calculate standard errors for DR PLM\n",
        "# Residuals for DR PLM\n",
        "residuals_dr_treated = (treatment / propensity_scores) * (y - y_hat_treated)\n",
        "residuals_dr_control = ((1 - treatment) / (1 - propensity_scores)) * (y - y_hat_control)\n",
        "\n",
        "# Variance of ATE for DR PLM\n",
        "variance_ate_dr_plm = np.var(dr_estimate_treated - dr_estimate_control) / len(y)\n",
        "\n",
        "# Standard error of ATE for DR PLM\n",
        "ate_dr_plm_se = np.sqrt(variance_ate_dr_plm)\n",
        "\n",
        "print(f\"The estimated Average Treatment Effect (ATE) using Doubly Robust PLM method is: {ate_dr_plm}\")\n",
        "print(f\"The standard error of the ATE estimate using Doubly Robust PLM method is: {ate_dr_plm_se}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "rytgRFLngk8E",
        "Pn71MZLF_964",
        "3sYubQNHxzVE",
        "DBnf1t0SEe3f",
        "LK0qqVJyEe3i",
        "lt_CNFU89sZs",
        "ZJ2ELZue-Hn6"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}